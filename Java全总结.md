# 计算机基础

## 数据结构与算法

###树

####二叉树

L、D、R分别表示遍历左子树、访问根结点和遍历右子树

- 先序遍历：DLR
- 中序遍历：LDR
- 后序遍历：LRD

> 仅有前序和后序遍历，不能确定一个二叉树，必须有中序遍历的结果

#####二叉树的性质 

- `性质1`：在二叉树中第 i 层的结点数最多为 2^{i-1}2*i*−1 （i ≥ 1）
- `性质2`：高度为k的二叉树其结点总数最多为 2^{k}－12*k*－1 （k ≥ 1）
- `性质3`：对任意的非空二叉树 T ，如果叶结点的个数为 n_0*n*0 ，而其度为 2 的结点数为 n_2*n*2，则： n_0 = n_2 + 1*n*0=*n*2+1

#####满二叉树

深度为k，且有 2^k-12*k*−1 个节点称之为 **满二叉树**；

- `性质4`：第i层上的节点数为 2^{i-1}2*i*−1 ；

#####完全二叉树

深度为k，有n个节点的二叉树，当且仅当其每一个节点都与深度为k的满二叉树中，序号为1至n的节点对应时，称之为`完全二叉树`。

- `性质5`：对于具有n个结点的完全二叉树的高度为 \log_{2}^{n}+1log2*n*+1

求完全二叉树的叶子结点个数：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/tree.jpg)

#####二叉树的构造

```C
//n 表示当前结点字符
Node* tree(vector<char> data, int n) {

    Node* node;

    if (n >= data.size())
        return NULL;
    if (data[n] == '#')
        return NULL;

    node = new Node;
    node->data = data[n];

    node->left = tree(data, n + 1);
    node->right = tree(data, n + 2);
    return node;
}
```

####霍夫曼树

霍夫曼树又称最优二叉树，**是一种带权路径长度最短的二叉树**。所谓树的带权路径长度，就是树中所有的叶结点的权值乘上其到根结点的路径长度（若根结点为0层，叶结点到根结点的路径长度为叶结点的层数）。**树的路径长度是从树根到每一结点的路径长度之和**，记为 WPL=W1\times L1+W2\times L2+W3\times L3+...+Wn\times Ln*W**P**L*=*W*1×*L*1+*W*2×*L*2+*W*3×*L*3+...+*W**n*×*L**n* ，N个权值Wi（i=1,2,…n）构成一棵有N个叶结点的二叉树，相应的叶结点的路径长度为Li（i=1,2,…n）。**可以证明霍夫曼树的WPL是最小的**。

#####霍夫曼树构造

1. 根据给定的n个权值`(W1,W2...Wn)`，使对应节点构成n个二叉树的森林`T=(T1,T2...Tn)`，其中每个二叉树`Ti(1 <= i <= n)`中都有一个带权值为Wi的根节点，其左、右子树均为空。
2. 在森林T中选取两个节点权值最小的子树，分别作为左、右子树构造一个新的二叉树，且置新的二叉树的根节点的权值为其左右子树上根节点权值之和。
3. 在森林T中，用新得到的二叉树替代选取的两个二叉树。
4. 重复2和3，直到T只包含一个树为止。这个数就是霍夫曼树。

> 定理：对于具有n个叶子节点的霍夫曼树，共有`2n-1`个节点。这是由于霍夫曼树只有度为0和度为2的结点，根据二叉树的性质 `n0 = n2 + 1`，因此度为2的结点个数为`n-1`个，总共有`2n-1`个节点。

##### 霍夫曼编码

对于一个霍夫曼树，所有左链接取'0’、右链接取'1’。从树根至树叶依序记录所有字母的编码。

##### 带权路径

- `结点的权`：若将树中结点赋给一个有着某种含义的数值，则这个数值称为该结点的权。
- `结点的带权路径`：从根结点到该结点之间的路径长度与该结点的权的乘积。
- `树的带权路径`：所有叶子结点的带权路径长度之和，记为`WPL`。

#### 二叉排序树

二叉查找树，也称二叉搜索树、有序二叉树，排序二叉树，是指一棵空树或者具有下列性质的二叉树：

- 任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值；
- 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值；
- 任意节点的左、右子树也分别为二叉查找树；
- 没有键值相等的节点。

二分查找的时间复杂度是O(log(n))，最坏情况下的时间复杂度是O(n)（相当于顺序查找）

#### 平衡二叉树

平衡树是计算机科学中的一类改进的二叉查找树。一般的二叉查找树的查询复杂度是跟目标结点到树根的距离（即深度）有关，因此当结点的深度普遍较大时，查询的均摊复杂度会上升，为了更高效的查询，平衡树应运而生了。**平衡指所有叶子的深度趋于平衡，更广义的是指在树上所有可能查找的均摊复杂度偏低。**

##### AVL树

AVL树是最先发明的 **自平衡二叉查找树**。在AVL树中任何节点的两个子树的高度最大差别为一，所以它也被称为高度平衡树。

- 它的左子树和右子树都是平衡二叉树。
- 左子树和右子树的深度之差的绝对值不超过1。

增加和删除可能需要通过一次或多次树旋转来重新平衡这个树。

- 右旋：左结点转到根节点位置。
- 左旋：右节点转到根节点位置。

> 高度为`k`的AVL树，节点数N最多`2^k -1`，即满二叉树；

##### 红黑树

红黑树是一种自平衡二叉查找树，每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求：

- 节点是红色或黑色。
- 根是黑色。
- 所有叶子都是黑色（叶子是NIL节点）。
- 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。）
- 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点。

> 如果一条路径上的顶点除了起点和终点可以相同外，其它顶点均不相同，则称此路径为一条简单路径；起点和终点相同的简单路径称为回路（或环）。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/red_black_tree.png)

> 红黑树相对于AVL树来说，牺牲了部分平衡性以换取插入/删除操作时少量的旋转操作，整体来说性能要优于AVL树。

这些约束确保了红黑树的关键特性：**从根到叶子的最长的可能路径不多于最短的可能路径的两倍长**。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限 **允许红黑树在最坏情况下都是高效的**，而不同于普通的二叉查找树。

在很多树数据结构的表示中，一个节点有可能只有一个子节点，而叶子节点包含数据。用这种范例表示红黑树是可能的，但是这会改变一些性质并使算法复杂。为此，本文中我们使用"nil叶子"或"空（null）叶子”，如上图所示，它不包含数据而只充当树在此结束的指示。**这些节点在绘图中经常被省略，导致了这些树好像同上述原则相矛盾，而实际上不是这样**。与此有关的结论是所有节点都有两个子节点，尽管其中的一个或两个可能是空叶子。

因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的只读操作与普通二叉查找树上的只读操作相同。然而，在红黑树上进行插入操作和删除操作会导致不再符合红黑树的性质。**恢复红黑树的性质需要少量（O(log n)）的颜色变更（实际是非常快速的）和不超过三次树旋转（对于插入操作是两次）**。虽然插入和删除很复杂，但操作时间仍可以保持为O(log n)次。

#### B树

B树是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，复杂度均为 O(n)*O*(*n*) 。总的来说，B树是一个泛化的二叉查找树，一个节点可以拥有两个以上的子节点。但其与自平衡二叉查找树不同，B树更适合大数据块的存储系统，例如：磁盘。

在B树中，内部（非叶子）节点可以拥有可变数量的子节点（数量范围预先定义好）。当数据被插入或从一个节点中移除，它的子节点数量发生变化。为了维持在预先设定的数量范围内，内部节点可能会被 **合并** 或者 **分离**。因为子节点数量有一定的允许范围，所以B树不需要像其他自平衡查找树那样频繁地重新保持平衡，但是由于节点 **没有被完全填充**，可能浪费了一些空间。子节点数量的上界和下界依特定的实现而设置。例如，在一个2-3 B树（通常简称2-3树），每一个内部节点只能有 2 或 3 个子节点。

根据 Knuth 的定义，一个 m 阶的B树是一个有以下属性的树：

- 每一个节点最多有 m 个子节点
- 每一个非叶子节点（除根节点）最少有 m\div 2*m*÷2 个子节点
- 如果根节点不是叶子节点，那么它至少有两个子节点
- 有 k 个子节点的非叶子节点拥有 k − 1 个键
- 所有的叶子节点都在同一层

每一个内部节点的键将节点的子树分开。例如，如果一个内部节点有 3 个子节点（子树），那么它就必须有两个键： a1 和 a2 。左边子树的所有值都必须小于 a1 ，中间子树的所有值都必须在 a1 和a2 之间，右边子树的所有值都必须大于 a2 。

B树内的节点可分为三类：

- 内部节点：内部节点是除叶子节点和根节点之外的所有节点。它们通常被表示为一组有序的元素和指向子节点的指针。
- 根节点：根节点拥有的子节点数量的上限和内部节点相同，但是没有下限。
- 叶子节点：叶子节点对元素的数量有相同的限制，但是没有子节点，也没有指向子节点的指针。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/b.png)

B树的查找

在B树中的查找给定关键字的方法 **类似于二叉排序树上的查找，不同的是在每个节点上确定向下查找的路径不一定是二路的，而是n+1路的**。因为节点内的关键字序列key[1..n]有序，故既可以使用顺序查找，也可以使用二分查找。在一棵B树上查找关键字为k的方法为：将k与根节点中的key[i]进行比较：

1. 若k=key[i]，则查找成功；
2. 若k<key[1]，则沿指针ptr[0]所指的子树继续查找；
3. 若key[i]<k<key[i+1]，则沿着指针ptr[i]所指的子树继续查找；
4. 若k>key[n]，则沿着指针ptr[n]所指的子树继续查找。

##### B树的插入

将关键字k插入到B树的过程分两步完成：

1. 利用B树的查找算法查找出该关键字的插入节点(注意B树的插入节点一定属于最低非叶子节点层)。
2. 判断该节点是否还有空位，即判断该节点是否满足n < m-1，若满足：直接把关键字k插入到该节点合适位置上；若不满足：分裂节点，取一新节点，把原节点上的关键字和k按升序排列后，从中间位置(m/2)处把关键字(不包括中间位置的关键字)分成两部分，左部分所含关键字放在旧节点中，右部分关键字放在新节点中，中间位置的关键字连同新节点的存储位置插入到双亲节点。如果双亲节点的关键字个数也超出max则再分裂。

##### B树的删除

首先查找B树中需删除的元素，如果该元素在B树中存在，则将该元素在其结点中进行删除；如果删除该元素后，首先判断该元素是否有左右孩子结点，如果有，则上移孩子结点中的某相近元素到父节点中，然后是移动之后的情况；如果没有，直接删除后，然后是移动之后的情况。

删除元素，移动相应元素之后，如果某结点中元素数目（即关键字数）小于Min(m/2)-1，则需要看其某相邻兄弟结点是否丰满，如果丰满，则向父节点借一个元素来满足条件；如果其相邻兄弟都刚脱贫，即借了之后其结点数目小于Min(m/2)-1，则该结点与其相邻的某一兄弟结点进行“合并”成一个结点，

B+树

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/b+.png)

B+ 树是 B 树的变体，也是一种多路搜索树。m阶的 B+ 树和 B 树的主要差异如下：

- 在B+树中，**具有n个关键字的节点含有n个子树**，即每个关键字对应一个子树，而在B树中，具有n个关键字的节点含有(n+1)个子树。
- 在B+树中，每个节点(除根节点外)中的关键字个数n的取值范围是[m/2] <= n <= m，根节点n的取值范围2 <=n <=m；而在B树中，除根节点外，其他所有非叶子节点的关键字个数：[m/2]-1 <= n <= m-1，根节点关键字个数为1 <= n <= m-1
- **B+树中所有叶子节点包含了全部关键字**，即其他非叶子节点中的关键字包含在叶子节点中，而在B树中，关键字是不重复的。
- **B+树中所有非叶子节点仅起到索引的作用**，即节点中每个索引项值含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。而在B树中，每个关键字对应一个记录的存储地址。
- **在 B+ 树所有叶子节点链接成一个不定长的线性表**。

##### B+树的查找

在B+树中可以采用两种查找方式：

- 直接从最小关键字开始顺序查找。
- 从B+树的根节点开始随机查找。这种查找方式与B树的查找方式类似，只是在分支节点上的关键字与查找值相等时，查找并不会结束，要继续查到叶子节点为止，此时若查找成功，则按所给指针取出对应元素。

在B+树中，不管查找是否成功，**每次查找都是经历一条树从根节点到叶子节点的路径**。

##### B+树的插入

1. 首先，查找要插入其中的节点的位置。接着把值插入这个节点中。
2. 如果没有节点处于违规状态则处理结束。
3. 如果某个节点有过多元素，则把它分裂为两个节点，每个都有最小数目的元素。在树上递归向上继续这个处理直到到达根节点，如果根节点被分裂，则创建一个新根节点。为了使它工作，元素的最小和最大数目典型的必须选择为使最小数不小于最大数的一半。

##### B+树的删除

1. 首先，查找要删除的值。接着从包含它的节点中删除这个值。
2. 如果没有节点处于违规状态则处理结束。
3. 如果节点处于违规状态则有两种可能情况：
   - 它的兄弟节点，可以把一个或多个它的子节点转移到当前节点，而把它返回为合法状态。如果是这样，在更改父节点和两个兄弟节点的分离值之后处理结束。
   - 它的兄弟节点由于处在低边界上而没有额外的子节点。在这种情况下把两个兄弟节点合并到一个单一的节点中，而且我们递归到父节点上，因为它被删除了一个子节点。持续这个处理直到当前节点是合法状态或者到达根节点，在其上根节点的子节点被合并而且合并后的节点成为新的根节点。

##### B+树的优势所在

为什么说B+树比B树更适合实际应用中操作系统的文件索引和数据库索引？

1. B+树的中间节点能存储更多指针
2. **B+树的查询效率更加稳定**：关键字查询的路径长度相同
3. **减少回溯**：由于B+树中叶子节点存在指针，所以在范围查找时不需要回溯到父节点，直接类型链表遍历即可，减少IO

#### Trie树

`Trie树`，又称前缀树，`字典树`， 是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。**一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串**。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。

**Trie树查询和插入时间复杂度都是 O(n)，是一种以空间换时间的方法。当节点树较多的时候，Trie 树占用的内存会很大**。

Trie树常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。



#### 堆

堆通常是一个可以被看做一棵树的数组对象。堆的实现通过构造二叉堆（binary heap），实为二叉树的一种；

- 任意节点小于（或大于）它的所有后裔，最小元（或最大元）在堆的根上（堆序性）。
- **堆总是一棵完全树**。即除了最底层，其他层的节点都被元素填满，且最底层尽可能地从左到右填入。

将根节点最大的堆叫做`最大堆`或大根堆，根节点最小的堆叫做`最小堆`或小根堆。常见的堆有二叉堆、斐波那契堆等。

通常堆是通过一维数组来实现的。在数组起始位置为1的情形中：

- 父节点i的左子节点在位置 2\times i2×*i* ;
- 父节点i的右子节点在位置 2\times i +12×*i*+1 ;
- 子节点i的父节点在位置 i\div 2*i*÷2 ;



### Hash

哈希表（Hash Table，也叫散列表），是根据关键码值 (Key-Value) 而直接进行访问的数据结构。也就是说，**它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度**。哈希表的实现主要需要解决两个问题，哈希函数和冲突解决。

#### 哈希函数

哈希函数也叫散列函数，它对不同的输出值得到一个固定长度的消息摘要。理想的哈希函数对于不同的输入应该产生不同的结构，**同时散列结果应当具有同一性（输出值尽量均匀）和雪崩效应（微小的输入值变化使得输出值发生巨大的变化）**。

#### 冲突解决

- `开放地址法`：
  
  以发生冲突的哈希地址为输入，通过某种哈希冲突函数得到一个新的空闲的哈希地址的方法

  。有以下几种方式：

  - `线性探查法`：从发生冲突的地址开始，依次探查下一个地址，直到找到一个空闲单元。
  - `平方探查法`：设冲突地址为d0，则探查序列为：d0+1^2,d0-1^2,d0+2^2…
  
- `拉链法`：把所有的同义词用单链表链接起来。在这种方法下，哈希表每个单元中存放的不再是元素本身，而是相应同义词单链表的头指针。`HashMap`就是使用这种方法解决冲突的。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hashmap-structure.png)



### 最小生成树算法

- `连通图`：在无向图G中，若从顶点i到顶点j有路径，则称顶点i和顶点j是连通的。若图G中任意两个顶点都连通，则称G为连通图。
- `生成树`：一个连通图的生成树是该连通图的一个极小连通子图，它含有全部顶点，但只有构成一个数的`(n-1)`条边。
- `最小生成树`：对于一个带权连通无向图G中的不同生成树，各树的边上的 **权值之和最小**。构造最小生成树的准则有三条：
  - 必须只使用该图中的边来构造最小生成树。
  - 必须使用且仅使用`(n-1)`条边来连接图中的n个顶点。
  - 不能使用产生回路的边。

#### Prim算法  

假设G=(V,E)是一个具有n个顶点的带权连通无向图，T(U,TE)是G的最小生成树，其中U是T的顶点集，TE是T的边集，则由G构造从起始顶点v出发的最小生成树T的步骤为：

- 初始化U={v}，以v到其他顶点的所有边为候选边(U中所有点到其他顶点的边)。
- 重复以下步骤(n-1)次，使得其他(n-1)个顶点被加入到U中。
  - 从候选边中挑选权值最小的边加入TE，设该边在`V-U`(这里是集合减)中的顶点是k，将k加入U中。
  - 考察当前V-U中的所有顶点j，修改候选边，若边(k,j)的权值小于原来和顶点j关联的候选边，则用(k,j)取代后者作为候选边。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/prim.jpg)

#### Kruskal算法  

假设G=(V,E)是一个具有n个顶点的带权连通无向图，T(U,TE)是G的最小生成树，其中U是T的顶点集，TE是T的边集，则由G构造从起始顶点v出发的最小生成树T的步骤为：

- 置U的初始值等于V(即包含G中的全部顶点)，TE的初始值为空
- 将图G中的边按权值从小到大的顺序依次选取，若选取的边未使生成树T形成回路，则加入TE，否则放弃，知道TE中包含(n-1)条边为止。



### 最短路径算法  

#### Dijkstra —— 贪心算法  

> 从一个顶点到其余顶点的最短路径

设`G=(V,E)`是一个带权有向图，把图中顶点集合V分成两组，第1组为已求出最短路径的顶点（用S表示，初始时S只有一个源点，以后每求得一条最短路径`v,...k`，就将k加到集合S中，直到全部顶点都加入S）。第2组为其余未确定最短路径的顶点集合（用U表示），按最短路径长度的递增次序把第2组的顶点加入S中。

```tex
步骤：

1. 初始时，S只包含源点，即`S={v}`，顶点v到自己的距离为0。U包含除v外的其他顶点，v到U中顶点i的距离为边上的权。
2. 从U中选取一个顶点u，顶点v到u的距离最小，然后把顶点u加入S中。
3. 以顶点u为新考虑的中间点，修改v到U中各个点的距离。
4. 重复以上步骤知道S包含所有顶点。
```

#### Floyd —— 动态规划  

Floyd 算法是解决任意两点间的最短路径的一种算法，可以正确处理有向图或负权（但不可存在负权回路）的最短路径问题。该算法的时间复杂度为 O(N^{3})*O*(*N*3) ，空间复杂度为 O(N^{2})*O*(*N*2)

设 D_{i,j,k}*D**i*,*j*,*k* 为从 i*i* 到 j*j* 的只以 (1..k)(1..*k*) 集合中的节点为中间节点的最短路径的长度。

$$ D_{i,j,k}=\begin{cases} D_{i,j,k-1} & 最短路径不经过 k\
D_{i,k,k-1}+D_{k,j,k-1} & 最短路径经过 k \end{cases} $$

因此， D_{i,j,k}=min(D_{i,k,k-1}+D_{k,j,k-1},D_{i,j,k-1})*D**i*,*j*,*k*=*m**i**n*(*D**i*,*k*,*k*−1+*D**k*,*j*,*k*−1,*D**i*,*j*,*k*−1) 。伪代码描述如下：

```latex
// let dist be a |V| × |V| array of minimum distances initialized to ∞ (infinity)
 for each vertex v
    dist[v][v] ← 0
 for each edge (u,v)
    dist[u][v] ← w(u,v)  // the weight of the edge (u,v)
 for k from 1 to |V|
    for i from 1 to |V|
       for j from 1 to |V|
          if dist[i][j] > dist[i][k] + dist[k][j]
             dist[i][j] ← dist[i][k] + dist[k][j]
         end if
```



### KMP算法

KMP算法解决的问题是字符匹配，这个算法把字符匹配的时间复杂度缩小到`O(m+n)`,而空间复杂度也只有O(m),n是target的长度，m是pattern的长度。

- 部分匹配表（Next数组）：表的作用是 **让算法无需多次匹配S中的任何字符**。能够实现线性时间搜索的关键是 **在不错过任何潜在匹配的情况下，我们"预搜索"这个模式串本身并将其译成一个包含所有可能失配的位置对应可以绕过最多无效字符的列表**。
- Next数组（前缀和前缀的比较）：t为模式串，j为下标
  - `Next[0] = -1`
  - `Next[j] = MAX{ k | 0 < k < j | " t0 t1 ... tk " = "t ( j-k ) t ( j-k+1 ) ... t( j-1 )" }`

|i|	0|	1|	2|	3|	4|	5	|6| |–| | t[i]|	A|	B|	C|	D|	A|	B|	D| |next[i]|	-1|	0	|0	|0	|0	|1	|2|

- NextVal数组：是一种优化后的Next数组，是为了解决类似`aaaab`这种模式串的匹配，减少重复的比较。 如果`t[next[j]]=t[j]`：`nextval[j]=nextval[next[j]]`，否则`nextval[j]=next[j]`。

|i|	0|	1|	2|	3|	4|	5	|6| |–| | t |	a|	b| c|	a| b| a |a| |next[j] |	-1|	0	|0	|0	|1	|2	|1| |nextval[j] |	-1|	0	|0	|-1 |0	|2	|1|

在上面的表格中，`t[next[4]]=t[4]=b`，所以`nextval[4]=nextval[next[4]]=0`



### 查找算法  

#### ASL  

由于查找算法的主要运算是关键字的比较，所以通常把查找过程中对关键字的平均比较次数（平均查找长度）作为衡量一个查找算法效率的标准。`ASL= ∑(n,i=1) Pi*Ci`，其中`n`为元素个数，`Pi`是查找第`i`个元素的概率，一般为`Pi=1/n`，`Ci`是找到第`i`个元素所需比较的次数。

#### 顺序查找  

原理是让关键字与队列中的数从最后一个开始逐个比较，直到找出与给定关键字相同的数为止，它的缺点是效率低下。**时间复杂度o(n)**。

#### 折半查找  

**折半查找要求线性表是有序表**。搜索过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜索过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。这种搜索算法每一次比较都使搜索范围缩小一半。**折半搜索每次把搜索区域减少一半，时间复杂度为O(log n)。**

- **可以借助二叉判定树求得折半查找的平均查找长度**：`log2(n+1)-1`。
- 折半查找在失败时所需比较的关键字个数不超过判定树的深度，n个元素的判定树的深度和n个元素的完全二叉树的深度相同`log2(n)+1`。

```java
public int binarySearchStandard(int[] num, int target){
    int start = 0;
    int end = num.length - 1;
    while(start <= end){ //注意1
        int mid = start + ((end - start) >> 1);
        if(num[mid] == target)
            return mid;
        else if(num[mid] > target){
            end = mid - 1; //注意2
        }
        else{
            start = mid + 1; //注意3
        }
    }
    return -1;
}
```

- 如果是start < end，那么当target等于num[num.length-1]时，会找不到该值。
- 因为num[mid] > target, 所以如果有num[index] == target, index一定小于mid，能不能写成end = mid呢？举例来说：num = {1, 2, 5, 7, 9}; 如果写成end = mid，当循环到start = 0, end = 0时（即num[start] = 1, num[end] = 1时），mid将永远等于0，此时end也将永远等于0，陷入死循环。也就是说寻找target = -2时，程序将死循环。
- 因为num[mid] < target, 所以如果有num[index] == target, index一定大于mid，能不能写成start = mid呢？举例来说：num = {1, 2, 5, 7, 9}; 如果写成start = mid，当循环到start = 3, end = 4时（即num[start] = 7, num[end] = 9时），mid将永远等于3，此时start也将永远等于3，陷入死循环。也就是说寻找target = 9时，程序将死循环。

#### 分块查找  

分块查找又称索引顺序查找，它是一种性能介于顺序查找和折半查找之间的查找方法。**分块查找由于只要求索引表是有序的，对块内节点没有排序要求，因此特别适合于节点动态变化的情况**。



### 排序算法  

#### 常见排序算法  

##### 稳定排序：  

- `冒泡排序` — O(n²)
- `插入排序` — O(n²)
- `桶排序` — O(n); 需要 O(k) 额外空间
- `归并排序` — O(nlogn); 需要 O(n) 额外空间
- `二叉排序树排序` — O(n log n) 期望时间; O(n²)最坏时间; 需要 O(n) 额外空间
- `基数排序` — O(n·k); 需要 O(n) 额外空间

##### 不稳定排序  

- `选择排序` — O(n²)
- `希尔排序` — O(nlogn)
- `堆排序` — O(nlogn)
- `快速排序` — O(nlogn) 期望时间, O(n²) 最坏情况; 对于大的、乱数串行一般相信是最快的已知排序

### 交换排序  

#### 冒泡排序  

它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。**冒泡排序总的平均时间复杂度为O(n^2)。冒泡排序是一种稳定排序算法。**

- 比较相邻的元素。如果第一个比第二个大，就交换他们两个。
- 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。
- 针对所有的元素重复以上的步骤，除了最后一个。
- 持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。

```c++
void bubble_sort(int a[], int n)
{
    int i, j, temp;
    for (j = 0; j < n - 1; j++)
        for (i = 0; i < n - 1 - j; i++)
        {
            if(a[i] > a[i + 1])
            {
                temp = a[i];
                a[i] = a[i + 1];
                a[i + 1] = temp;
            }
        }
}
```

快速排序

#### [快速排序-百度百科](http://baike.baidu.com/link?url=hyQPClbJy1SYY4esOZe9kANDIDxOrKxiSfq0HZl8c5eut40dZS-fd1V0jubijSv7RAogwy6HaQ-B1HbRgHf1hq)  

快速排序是一种 **不稳定** 的排序算法，平均时间复杂度为 **O(nlogn)**。**快速排序使用分治法（Divide and conquer）策略来把一个序列（list）分为两个子序列（sub-lists）。** 步骤为：

- 从数列中挑出一个元素，称为"基准”（pivot），
- 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。
- 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。

> 快排的时间花费主要在划分上，所以
>
> - 最坏情况：时间复杂度为`O(n^2)`。因为最坏情况发生在每次划分过程产生的两个区间分别包含`n-1`个元素和`1`个元素的时候。
> - 最好情况：每次划分选取的基准都是当前无序区的中值。如果每次划分过程产生的区间大小都为n/2，则快速排序法运行就快得多了。

```java
public void sort(int[] arr, int low, int high) {
    int l = low;
    int h = high;
    int povit = arr[low];
    while (l < h) {
        while (l < h && arr[h] >= povit)
            h--;
        if (l < h) {
            arr[l] = arr[h];
            l++;
        }
        while (l < h && arr[l] <= povit)
            l++;
        if (l < h) {
            arr[h] = arr[l];
            h--;
        }
    }

    arr[l] = povit;

    System.out.print("l=" + (l + 1) + ";h=" + (h + 1) + ";povit=" + povit + "\n");
    System.out.println(Arrays.toString(arr));
    if (l - 1 > low) sort(arr, low, l - 1);
    if (h + 1 < high) sort(arr, h + 1, high);
}
```

##### 快排的优化  

1. 当待排序序列的长度分割到一定大小后，使用插入排序。
2. 快排函数在函数尾部有两次递归操作，我们可以对其使用尾递归优化。优化后，可以缩减堆栈深度，由原来的O(n)缩减为O(logn)，将会提高性能。
3. 从左、中、右三个数中取中间值。

### 插入排序  

#### 直接插入排序  

插入排序的基本操作就是将一个数据插入到已经排好序的有序数据中，从而得到一个新的、个数加一的有序数据，算法适用于少量数据的排序，**时间复杂度为O(n^2)。是稳定的排序方法。** **插入算法把要排序的数组分成两部分**：第一部分包含了这个数组的所有元素，但将最后一个元素除外（让数组多一个空间才有插入的位置），而第二部分就只包含这一个元素（即待插入元素）。在第一部分排序完成后，再将这个最后元素插入到已排好序的第一部分中。

```c++
void insert_sort(int* a, int len) {
    for (int i = 1; i < len; ++i) {
        int j = i - 1;
        int temp = a[i];
        while (j >= 0 && temp < a[j]) {
            a[j + 1] = a[j];
            j--;
        }
        a[j + 1] = temp;
    }
}
```

#### 希尔排序

也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。**希尔排序是非稳定排序算法。**

希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。

```c++
void shell_sort(int* a, int len) {
    int step = len / 2;
    int temp;

    while (step > 0) {
        for (int i = step; i < len; ++i) {
            temp = a[i];
            int j = i - step;
            while (j >= 0 && temp < a[j]) {
                a[j + step] = a[j];
                j -= step;
            }
            a[j + step] = temp;
        }
        step /= 2;
    }
}
```

### 选择排序  

#### 直接选择排序  

首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。**实际适用的场合非常罕见。**

```c++
void selection_sort(int arr[], int len) {
	int i, j, min, temp;
	for (i = 0; i < len - 1; i++) {
		min = i;
		for (j = i + 1; j < len; j++)
			if (arr[min] > arr[j])
				min = j;
	   	temp = arr[min];
		arr[min] = arr[i];
		arr[i] = temp;
	}
}
```

#### 堆排序  

堆排序利用了大根堆（或小根堆）堆顶记录的关键字最大（或最小）这一特征，使得在当前无序区中选取最大（或最小）关键字的记录变得简单。

1. 将数组分为有序区和无序区，在无序区中建立最大堆
2. 将堆顶的数据与无序区末尾的数据交换
3. 从后往前，直到所有数据排序完成

```java
public void heapSort(int[] nums) {
    for (int i = nums.length - 1; i >= 0; i--) {
        maxHeap(nums, 0, i);

        swap(nums, 0, i);
    }
}

public void maxHeap(int[] heap, int start, int end) {
    if (start == end) {
        return;
    }

    int parent = start;
    int childLeft = start * 2 + 1;
    int childRight = childLeft + 1;

    if (childLeft <= end) {
        maxHeap(heap, childLeft, end);

        if (heap[childLeft] > heap[parent]) {
            swap(heap, parent, childLeft);
        }
    }

    if (childRight <= end) {
        maxHeap(heap, childRight, end);

        if (heap[childRight] > heap[parent]) {
            swap(heap, parent, childRight);
        }
    }
}

private void swap(int[] nums, int a, int b) {
    int t = nums[a];
    nums[a] = nums[b];
    nums[b] = t;
}
```

### 归并排序  

归并排序采用分治的思想：

- Divide：将n个元素平均划分为各含n/2个元素的子序列；
- Conquer：递归的解决俩个规模为n/2的子问题；
- Combine：合并俩个已排序的子序列。

性能：时间复杂度总是为O(NlogN)，空间复杂度也总为为O(N)，算法与初始序列无关，排序是稳定的。

```java
public void mergeSort(int[] array, int start, int end, int[] temp) {
    if (start >= end) {
        return;
    }

    int mid = (start + end) / 2;

    mergeSort(array, start, mid, temp);
    mergeSort(array, mid + 1, end, temp);

    int f = start, s = mid + 1;
    int t = 0;
    while (f <= mid && s <= end) {
        if (array[f] < array[s]) {
            temp[t++] = array[f++];
        } else {
            temp[t++] = array[s++];
        }
    }

    while (f <= mid) {
        temp[t++] = array[f++];
    }

    while (s <= end) {
        temp[t++] = array[s++];
    }

    for (int i = 0, j = start; i < t; i++) {
        array[j++] = temp[i];
    }
}
```

### 桶排序  

桶排序工作的原理是将 **数组分到有限数量的桶** 里。每个桶再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。当要被排序的数组内的数值是均匀分配的时候，桶排序使用线性时间 O(n)*O*(*n*) 。由于桶排序不是比较排序，他不受到 O(n\log n)*O*(*n*log*n*) 下限的影响。

桶排序以下列程序进行：

- 设置一个定量的数组当作空桶子。
- 寻访序列，并且把项目一个一个放到对应的桶子去。
- 对每个不是空的桶子进行排序。
- 从不是空的桶子里把项目再放回原来的序列中。

```java
private int indexFor(int a, int min, int step) {
	return (a - min) / step;
}

public void bucketSort(int[] arr) {
	int max = arr[0], min = arr[0];
	for (int a : arr) {
		if (max < a)
			max = a;
		if (min > a)
			min = a;
	}
	// 该值可根据实际情况选择
	int bucketNum = max / 10 - min / 10 + 1;
	List buckList = new ArrayList<List<Integer>>();
	// create bucket
	for (int i = 1; i <= bucketNum; i++) {
		buckList.add(new ArrayList<Integer>());
	}
	// push into the bucket
	for (int i = 0; i < arr.length; i++) {
		int index = indexFor(arr[i], min, 10);
		((ArrayList<Integer>) buckList.get(index)).add(arr[i]);
	}
	ArrayList<Integer> bucket = null;
	int index = 0;
	for (int i = 0; i < bucketNum; i++) {
		bucket = (ArrayList<Integer>) buckList.get(i);
		insertSort(bucket);
		for (int k : bucket) {
			arr[index++] = k;
		}
	}
}

// 把桶內元素插入排序
private void insertSort(List<Integer> bucket) {
	for (int i = 1; i < bucket.size(); i++) {
		int temp = bucket.get(i);
		int j = i - 1;
		for (; j >= 0 && bucket.get(j) > temp; j--) {
			bucket.set(j + 1, bucket.get(j));
		}
		bucket.set(j + 1, temp);
	}
}
```

### 基数排序  

对于有d个关键字时，可以分别按关键字进行排序。有俩种方法：

- MSD：先从高位开始进行排序，在每个关键字上，可采用基数排序
- LSD：先从低位开始进行排序，在每个关键字上，可采用桶排序

> 即通过每个数的每位数字的大小来比较

```cpp
//找出最大数字的位数
int maxNum(int arr[], int len) {
    int _max = 0;

    for (int i = 0; i < len; ++i) {
        int d = 0;
        int a = arr[i];

        while (a) {
            a /= 10;
            d++;
        }

        if (_max < d) {
            _max = d;
        }
    }
    return _max;
}


void radixSort(int *arr, int len) {
    int d = maxNum(arr, len);
    int *temp = new int[len];
    int count[10];
    int radix = 1;

    for (int i = 0; i < d; ++i) {
        for (int j = 0; j < 10; ++j) {
            count[j] = 0;
        }

        for (int k = 0; k < len; ++k) {
            count[(arr[k] / radix) % 10]++;
        }

        for (int l = 1; l < 10; ++l) {
            count[l] += count[l - 1];
        }

        for (int m = 0; m < len; ++m) {
            int index = (arr[m] / radix) % 10;
            temp[count[index] - 1] = arr[m];
            count[index]--;
        }

        for (int n = 0; n < len; ++n) {
            arr[n] = temp[n];
        }
        radix *= 10;

    }

    delete (temp);
}
```

### 拓扑排序  

在有向图中找拓扑序列的过程，就是拓扑排序。**拓扑序列常常用于判定图是否有环**。

- 从有向图中选择一个入度为0的结点，输出它。
- 将这个结点以及该结点出发的所有边从图中删除。
- 重复前两步，直到没有入度为0的点。

> 如果所有点都被输出，即存在一个拓扑序列，则图没有环。



### 跳跃表  

跳跃列表是一种数据结构。它允许快速查询一个有序连续元素的数据链表。跳跃列表的平均查找和插入时间复杂度都是 `O(log n)` ，优于普通队列的 `O(n)`。

快速查询是通过维护一个多层次的链表，且每一层链表中的元素是前一层链表元素的子集。一开始时，算法在最稀疏的层次进行搜索，直至需要查找的元素在该层两个相邻的元素中间。这时，算法将跳转到下一个层次，重复刚才的搜索，直到找到需要查找的元素为止。跳过的元素的方法可以是 **随机性选择** 或 **确定性选择**，其中前者更为常见。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/9d89be415d4f099d1eb4042af706f278.png)

在查找目标元素时，从顶层列表、头元素起步。算法沿着每层链表搜索，直至找到一个大于或等于目标的元素，或者到达当前层列表末尾。如果该元素等于目标元素，则表明该元素已被找到；如果该元素大于目标元素或已到达链表末尾，则退回到当前层的上一个元素，然后转入下一层进行搜索。

跳跃列表不像平衡树等数据结构那样提供对最坏情况的性能保证：由于用来建造跳跃列表采用随机选取元素进入更高层的方法，在小概率情况下会生成一个不平衡的跳跃列表（**最坏情况例如最底层仅有一个元素进入了更高层，此时跳跃列表的查找与普通列表一致**）。但是在实际中它通常工作良好，**随机化平衡方案也比平衡二叉查找树等数据结构中使用的确定性平衡方案容易实现**。跳跃列表在并行计算中也很有用：插入可以在跳跃列表不同的部分并行地进行，而不用对数据结构进行全局的重新平衡。

跳跃表插入一个元素：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/e3ccf6537c3a42f6c6f1e8d7e26ba0ed.png)

#### 实现  

因为跳跃列表中的元素可以在多个列表中，所以每个元素可以有多于一个指针。跳跃列表的插入和删除的实现与普通的链表操作类似，但高层元素必须在进行多个链表中进行插入或删除。

```java
package io.github.hadyang.leetcode.algo;

import lombok.Getter;
import lombok.Setter;

import java.util.Arrays;
import java.util.Random;

/**
 * @author haoyang.shi
 */
public class SkipList<K extends Comparable<K>, V> {

    @Getter
    @Setter
    static final class Node<K extends Comparable<K>, V> {
        private K key;

        private V value;

        private Node<K, V> up, down, pre, next;

        Node(K key, V value) {
            this.key = key;
            this.value = value;
        }


        @Override
        public String toString() {
            return "Node{" +
                    "key=" + key +
                    ", value=" + value +
                    ", hashcode=" + hashCode() +
                    ", up=" + (up == null ? "null" : up.hashCode()) +
                    ", down=" + (down == null ? "null" : down.hashCode()) +
                    ", pre=" + (pre == null ? "null" : pre.hashCode()) +
                    ", next=" + (next == null ? "null" : next.hashCode()) +
                    '}';
        }
    }

    private Node<K, V> head;//k,v都是NULL

    private Integer levels = 0;

    private Integer length = 0;

    private Random random = new Random(System.currentTimeMillis());

    public SkipList() {
        createNewLevel();
    }

    public void put(K key, V value) {
        if (key == null || value == null) {
            return;
        }

        Node<K, V> newNode = new Node<>(key, value);
        insertNode(newNode);
    }

    private void insertNode(Node<K, V> newNode) {
        Node<K, V> curNode = findNode(newNode.getKey());
        if (curNode.getKey() == null) {
            insertNext(curNode, newNode);
        } else if (curNode.getKey().compareTo(newNode.getKey()) == 0) {
            //update
            curNode.setValue(newNode.getValue());
            return;
        } else {
            insertNext(curNode, newNode);
        }

        int currentLevel = 1;
        Node<K, V> oldTop = newNode;
        while (random.nextInt(100) < 50) {
            Node<K, V> newTop = new Node<>(newNode.getKey(), null);

            if (currentLevel >= levels) {
                createNewLevel();
            }

            while (curNode.getPre() != null && curNode.getUp() == null) {
                curNode = curNode.getPre();
            }

            if (curNode.getUp() == null) {
                continue;
            }

            curNode = curNode.getUp();
            Node<K, V> curNodeNext = curNode.getNext();

            curNode.setNext(newTop);
            newTop.setPre(curNode);
            newTop.setDown(oldTop);
            oldTop.setUp(newTop);

            newTop.setNext(curNodeNext);
            oldTop = newTop;

            currentLevel++;
        }
    }

    private void createNewLevel() {
        Node<K, V> newHead = new Node<>(null, null);
        if (this.head == null) {
            this.head = newHead;
            this.levels++;
            return;
        }

        this.head.setUp(newHead);
        newHead.setDown(this.head);
        this.head = newHead;
        this.levels++;
    }

    private void insertNext(Node<K, V> curNode, Node<K, V> newNode) {
        Node<K, V> curNodeNext = curNode.getNext();
        newNode.setNext(curNodeNext);
        if (curNodeNext != null) {
            curNodeNext.setPre(newNode);
        }
        curNode.setNext(newNode);
        newNode.setPre(curNode);

        this.length++;
    }

    public V get(K key) {
        Node<K, V> node = findNode(key);
        if (key.equals(node.getKey())) {
            return node.getValue();
        }

        return null;
    }

    private Node<K, V> findNode(K key) {
        Node<K, V> curNode = this.head;

        for (; ; ) {
            while (curNode.getNext() != null && curNode.getNext().getKey().compareTo(key) <= 0) {
                curNode = curNode.getNext();
            }

            if (curNode.getDown() != null) {
                curNode = curNode.getDown();
            } else {
                break;
            }
        }

        return curNode;
    }

    public void print() {
        Node<K, V> curI = this.head;

        String[][] strings = new String[levels][length + 1];
        for (String[] string : strings) {
            Arrays.fill(string, "0");
        }

        while (curI.getDown() != null) {
            curI = curI.getDown();
        }

        System.out.println("levels:" + levels + "_" + "length:" + length);

        int i = 0;
        while (curI != null) {
            Node<K, V> curJ = curI;

            int j = levels - 1;
            while (curJ != null) {
                strings[j][i] = String.valueOf(curJ.getKey());

                if (curJ.getUp() == null) {
                    break;
                }
                curJ = curJ.getUp();
                j--;
            }

            if (curI.getNext() == null) {
                break;
            }
            curI = curI.getNext();
            i++;
        }

        for (String[] string : strings) {
            System.out.println(Arrays.toString(string));
        }
    }

    public static void main(String[] args) {

        SkipList<Integer, String> skipList = new SkipList<>();

        skipList.put(2, "B");
        skipList.put(1, "A");
        skipList.put(3, "C");

        skipList.print();

        System.out.println(skipList.get(2));

    }

}
```



## 操作系统基础  

### 操作系统提供的服务  

操作系统的五大功能，分别为：`作业管理`、`文件管理`、`存储管理`、`输入输出设备管理`、`进程及处理机管理`

### 中断  

所谓的中断就是在计算机执行程序的过程中，由于出现了某些特殊事情，使得CPU暂停对程序的执行，转而去执行处理这一事件的程序。等这些特殊事情处理完之后再回去执行之前的程序。中断一般分为三类：

- `内部异常中断`：由计算机硬件异常或故障引起的中断；
- `软中断`：由程序中执行了引起中断的指令而造成的中断（这也是和我们将要说明的系统调用相关的中断）；
- `外部中断`：由外部设备请求引起的中断，比如I/O请求。

> 简单来说，对中断的理解就是对一些特殊事情的处理。

与中断紧密相连的一个概念就是中断处理程序了。**当中断发生的时候，系统需要去对中断进行处理，对这些中断的处理是由操作系统内核中的特定函数进行的，这些处理中断的特定的函数就是我们所说的中断处理程序了**。

另一个与中断紧密相连的概念就是中断的优先级。**中断的优先级说明的是当一个中断正在被处理的时候，处理器能接受的中断的级别。中断的优先级也表明了中断需要被处理的紧急程度。每个中断都有一个对应的优先级，当处理器在处理某一中断的时候，只有比这个中断优先级高的中断可以被处理器接受并且被处理。优先级比这个当前正在被处理的中断优先级要低的中断将会被忽略**。

典型的中断优先级如下所示：

```
机器错误 > 时钟 > 磁盘 > 网络设备 >  终端 > 软件中断
```

当发生软件中断时，其他所有的中断都可能发生并被处理；但当发生磁盘中断时，就只有时钟中断和机器错误中断能被处理了。

### 系统调用  

在讲系统调用之前，先说下进程的执行在系统上的两个级别：用户级和核心级，也称为`用户态`和`系统态`(`user mode` and `kernel mode`)。

**程序的执行一般是在用户态下执行的，但当程序需要使用操作系统提供的服务时，比如说打开某一设备、创建文件、读写文件等，就需要向操作系统发出调用服务的请求，这就是系统调用**。

Linux系统有专门的函数库来提供这些请求操作系统服务的入口，这个函数库中包含了操作系统所提供的对外服务的接口。**当进程发出系统调用之后，它所处的运行状态就会由用户态变成核心态。但这个时候，进程本身其实并没有做什么事情，这个时候是由内核在做相应的操作，去完成进程所提出的这些请求**。

**系统调用和中断的关系就在于，当进程发出系统调用申请的时候，会产生一个软件中断。产生这个软件中断以后，系统会去对这个软中断进行处理，这个时候进程就处于核心态了**。

那么用户态和核心态之间的区别是什么呢？

- 用户态的进程能存取它们自己的指令和数据，但不能存取内核指令和数据（或其他进程的指令和数据）。然而，核心态下的进程能够存取内核和用户地址
- 某些机器指令是特权指令，在用户态下执行特权指令会引起错误

对此要理解的一个是，**在系统中内核并不是作为一个与用户进程平行的估计的进程的集合，内核是为用户进程运行的**。



# 操作系统

## 计算机体系结构  

### 冯·诺依曼体系结构  

1. 计算机处理的数据和指令一律用二进制数表示

2. 顺序执行程序

   计算机运行过程中，把要执行的程序和处理的数据首先存入主存储器（内存），计算机执行程序时，将自动地并按顺序从主存储器中取出指令一条一条地执行，这一概念称作顺序执行程序。

3. 计算机硬件由运算器、控制器、存储器、输入设备和输出设备五大部分组成。

### 数据的机内表示  

#### 二进制表示  

##### 机器数  

由于计算机中符号和数字一样，都必须用二进制数串来表示，因此，**正负号也必须用0,1来表示**。

##### 原码  

原码用第一位表示符号, 其余位表示值. 比如如果是8位二进制:

```
[+1]原 = 0000 0001

[-1]原 = 1000 0001

第一位是符号位. 因为第一位是符号位, 所以8位二进制数的取值范围就是:

[1111 1111 , 0111 1111]

即

[-127 , 127]
```

原码是人脑最容易理解和计算的表示方式

##### 反码  

- 正数的反码是其本身
- 负数的反码是在其原码的基础上, 符号位不变，其余各个位取反.

```
[+1] = [00000001]原 = [00000001]反

[-1] = [10000001]原 = [11111110]反
```

可见如果一个反码表示的是负数，人脑无法直观的看出来它的数值， 通常要将其转换成原码再计算。

##### 补码  

- 正数的补码就是其本身
- 负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1。 (即在反码的基础上+1)

```
[+1] = [00000001]原 = [00000001]反 = [00000001]补

[-1] = [10000001]原 = [11111110]反 = [11111111]补

1+（-1)= 00000001 + 11111111 = 00000000 = 0
```

对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值.

> 在计算机系统中，**数值一律用补码来表示和存储**。原因在于，使用补码，可以将符号位和数值域统一处理；同时，加法和减法也可以统一处理。此外，补码与原码相互转换，其运算过程是相同的，不需要额外的硬件电路。

##### 定点数与浮点数  

**定点数是小数点固定的数**。在计算机中没有专门表示小数点的位，小数点的位置是约定默认的。一般固定在机器数的最低位之后，或是固定在符号位之后。前者称为定点纯整数，后者称为定点纯小数。

> 定点数表示法简单直观，但是 **数值表示的范围太小**，运算时容易产生溢出。

浮点数是小数点的位置可以变动的数。为增大数值表示范围，防止溢出，采用浮点数表示法。**浮点表示法类似于十进制中的科学计数法**。

IEEE 浮点标准用 V=(-1)^s \times M \times 2^E*V*=(−1)*s*×*M*×2*E* 来表示一个数：

- **符号 s**：决定该数数负数（s=0）还是正数（s=1），对于数值 0 的符号位解释作为特殊情况处理
- **尾数 M**：M 是一个二进制小数，其取值范围为 1 \sim 2-\varepsilon1∼2−*ε* 和 0 \sim 1-\varepsilon0∼1−*ε*
- **阶码 E**：E 对浮点数加权，这个权重是 2 的 E 次幂（E可能是负数）

在位级别，将浮点数的位划分为三个部分：

- 一个单独的符号位 s 直接编码符号 s
- k 位的阶码字段 exp=e_{k-1}...e_1e_0*e**x**p*=*e**k*−1...*e*1*e*0 编码阶码 E
- n 位小数字段 frac=f_{n-1}...f_1f_0*f**r**a**c*=*f**n*−1...*f*1*f*0 编码尾数 M，但编码出来的值也依赖于阶码字段的值是否为 0 （非规格化）

```
|     数符字段 s     |     阶码字段 exp      |     尾数字段 frac       |
```

通常使用的有 32 和 64 位的浮点数，其各个字段的大小如下所示：

- **32位单精度**：单精度二进制小数，使用32位存储。1 8 23 位长
- **64位双精度**：双精度二进制小数，使用64位存储。1 11 52 位长

##### 规格化的浮点数  

当阶码字段 exp 不全为 0 或全为 1 时，该浮点数属于 **规格化** 浮点数。在这种情况下，阶码字段 exp 被解释为以 *偏置（Bias）* 形式表示的有符号整数，即 E=exp-Bias*E*=*e**x**p*−*B**i**a**s* ，其中 exp 是无符号数 exp=e_{k-1}...e_1e_0*e**x**p*=*e**k*−1...*e*1*e*0 Bias=2^{k-1}-1*B**i**a**s*=2*k*−1−1 （单精度为 127，双精度为 1023）。由此产生的指数取值范围，对于单精度是 -126 \sim +127−126∼+127 ，对于双精度为 -1022 \sim +1023−1022∼+1023

> 指数取值范围： -126=1(exp)-127−126=1(*e**x**p*)−127 ， 127=254(exp)-127127=254(*e**x**p*)−127 ，注意 exp 只能取 1 \sim 2541∼254

尾数字段 frac 被解释为小数值，其中 0 \leq frac \le 10≤*f**r**a**c*≤1 ，二进制表示为 0.f_{n-1}...f_{1}f_{0}0.*f**n*−1...*f*1*f*0 ，尾数 M=1+frac*M*=1+*f**r**a**c* ，则尾数的表示范围在 1 \leq M \le 21≤*M*≤2 。

##### 非规格化的浮点数  

当阶码字段 exp 为 0 时，该浮点数属于 **非规格化** 浮点数。在这种情况下，阶码 E=1-Bias*E*=1−*B**i**a**s* ，而尾数 M=f*M*=*f*

##### 特殊的浮点数  

当阶码字段 exp 全为 1 时表示特殊值。frac 字段为 0 则表示无穷大，按符号位的取值，可分为 **正无穷** 和 **负无穷**。当 frac 字段非 0 时表示 “NaN” 即 Not a Number。

#### 位、字节、字  

- `位(Bit)`：电子计算机中最小的数据单位。每一位的状态只能是0或1。
- `字节(Byte)`：**8个二进制位构成1个字节，它是存储空间的基本计量单位**。1个字节可以储存1个英文字母或者半个汉字，换句话说，1个汉字占据2个字节的存储空间。
- `字(Word)`：**由若干个字节构成，字的位数叫做字长，不同档次的机器有不同的字长**。例如一台8位机，它的1个字就等于1个字节，字长为8位。如果是一台16位机，那么，它的1个字就由2个字节构成，字长为16位。**字是计算机进行数据处理和运算的单位**。

##### 字节序  

字节顺序是指占内存多于一个字节类型的数据在内存中的存放顺序，通常有小端、大端两种字节顺序。

- `小端字节序`：低字节数据存放在内存低地址处，高字节数据存放在内存高地址处。
- `大端字节序`：高字节数据存放在低地址处，低字节数据存放在高地址处。

基于X86平台的PC机是小端字节序的，而有的嵌入式平台则是大端字节序的。**所有网络协议也都是采用大端字节序的方式来传输数据的。所以有时我们也会把大端字节序方式称之为网络字节序**。

```
比如数字 0x12345678 在两种不同字节序CPU中的存储顺序如下所示：

    Big Endian
    低地址                                            高地址
    ---------------------------------------------------->
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |     12     |      34    |     56      |     78    |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

    Little Endian
    低地址                                            高地址
    ---------------------------------------------------->
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
    |     78     |      56    |     34      |     12    |
    +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+


从上面两图可以看出，采用Big Endian方式存储数据是符合我们人类的思维习惯的。
```

联合体`union`的存放顺序是所有成员都从低地址开始存放，利用该特性，就能判断CPU对内存采用`Little-endian`还是`Big-endian`模式读写。

##### 字节对齐  

现代计算机中内存空间都是按照字节划分的，从理论上讲似乎对任何类型的变量的访问可以从任何地址开始，但实际情况是在访问特定类型变量的时候经常在特定的内存地址访问，**这就需要各种类型数据按照一定的规则在空间上排列，而不是顺序的一个接一个的排放，这就是对齐**。

- 为什么要进行字节对齐？
  1. 某些平台只能在特定的地址处访问特定类型的数据;
  2. 最根本的原因是效率问题，字节对齐能提高存取数据的速度。

比如有的平台每次都是从偶地址处读取数据,对于一个int型的变量,若从偶地址单元处存放,则只需一个读取周期即可读取该变量，但是若从奇地址单元处存放，则需要2个读取周期读取该变量。

- 字节对齐的原则
  1. `数据成员对齐规则`：结构体或联合体的数据成员，第一个数据成员放在 offset 为0的地方，以后每个数据成员存储的起始位置要从该成员大小或者成员的子成员大小（只要该成员有子成员，比如说是数组，结构体等）的整数倍开始（比如int在32位机为4字节,则要从4的整数倍地址开始存储）。
  2. `结构体作为成员`：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。(struct a里存有struct b,b里有char,int ,double等元素,那b应该从8的整数倍开始存储。)
  3. `收尾工作`：结构体的总大小，也就是sizeof的结果，必须是其内部最大成员的整数倍，不足的要补齐。



## 进程  

**进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示**。

进程的概念主要有两点：

- `进程是一个实体`，**每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）**。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。
- `进程是一个“执行中的程序”`，程序是一个没有生命的实体，只有处理器赋予程序生命时，它才能成为一个活动的实体，我们称其为进程。

### 进程的基本状态  

- `阻塞态`：等待某个事件的完成；
- `就绪态`：等待系统分配处理器以便运行；
- `执行态`：占有处理器正在运行。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/process_status.jpg)

> 执行态 -> 阻塞态：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。

> 阻塞态 -> 就绪态：则是等待的条件已满足，只需分配到处理器后就能运行。

> 执行态 -> 就绪态：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。

> 就绪态 -> 执行态：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态

### 进程调度  

#### 上下文切换  

线程/进程的上下文（以下统称为：上下文）主要包含两个部分：寄存器（尤其是 PC）和操作系统需要的特定数据（PCB）。上下文切换（context switch），是一个存储和重建 CPU 的过程，完整的上下文会涉及到这两部分的切换，旧的上下文被保存，新的上下文被加载。

当系统发生中断或者 OS 进行线程调度时会进行上下文切换。

#### 调度种类  

高级、中级和低级调度作业从提交开始直到完成，往往要经历下述三级调度：

- 高级调度：又称为作业调度，它决定把后备作业调入内存运行；
- 中级调度：又称为在虚拟存储器中引入，在内、外存对换区进行进程对换。
- 低级调度：又称为进程调度，它决定把就绪队列的某进程获得CPU；

#### 非抢占式调度与抢占式调度  

- `非抢占式`：分派程序一旦把处理机分配给某进程后便让它一直运行下去，直到进程完成或发生进程调度进程调度某事件而阻塞时，才把处理机分配给另一个进程。
- `抢占式`：操作系统将正在运行的进程强行暂停，由调度程序将CPU分配给其他就绪进程的调度方式。

#### 调度策略的设计  

- `响应时间`：从用户输入到产生反应的时间
- `周转时间`：从任务开始到任务结束的时间
- `平均周转时间`：周转总时间除以作业个数

CPU任务可以分为交互式任务和批处理任务，调度最终的目标是合理的使用CPU，使得交互式任务的响应时间尽可能短，用户不至于感到延迟，同时使得批处理任务的周转时间尽可能短，减少用户等待的时间。

#### 调度算法  

1. FCFS：调度的顺序就是任务到达就绪队列的顺序。对短作业不公平。
2. SJF：最短的作业(CPU区间长度最小)最先调度。
3. HRN：最高响应比优先法，是 FCFS 和 SJF 的综合平衡，响应比R定义如下： `R =(W+T)/T` 。
4. 优先权调度：每个任务关联一个优先权，调度优先权最高的任务。
5. Round-Robin(RR)：设置一个时间片，按时间片来轮转调度
6. 多级队列调度
   1. 按照一定的规则建立多个进程队列
   2. 不同的队列有固定的优先级（高优先级有抢占权）
   3. 不同的队列可以给不同的时间片和采用不同的调度方法
7. 多级反馈队列：在多级队列的基础上，任务可以在队列之间移动，更细致的区分任务。可以根据“享用”CPU时间多少来移动队列，阻止“饥饿”。

### 进程同步  

#### 临界资源与临界区  

在操作系统中，**进程是占有资源的最小单位（线程可以访问其所在进程内的所有资源，但线程本身并不占有资源或仅仅占有一点必须资源）**。但对于某些资源来说，其在同一时间只能被一个进程所占用。这些一次只能被一个进程所占用的资源就是所谓的临界资源。典型的临界资源比如物理上的打印机，或是存在硬盘或内存中被多个进程所共享的一些变量和数据等(如果这类资源不被看成临界资源加以保护，那么很有可能造成丢数据的问题)。

对于临界资源的访问，必须是互斥进行。也就是当临界资源被占用时，另一个申请临界资源的进程会被阻塞，直到其所申请的临界资源被释放。而进程内访问临界资源的代码被成为临界区。

对于临界区的访问过程分为四个部分：

1. 进入区:查看临界区是否可访问，如果可以访问，则转到步骤二，否则进程会被阻塞
2. 临界区:在临界区做操作
3. 退出区:清除临界区被占用的标志
4. 剩余区：进程与临界区不相关部分的代码

解决临界区问题可能的方法：

1. 一般软件方法
2. 关中断方法
3. 硬件原子指令方法
4. 信号量方法

#### 信号量  

信号量是一个确定的二元组（s，q），其中s是一个具有非负初值的整形变量，q是一个初始状态为空的队列，整形变量s表示系统中某类资源的数目：

- 当其值 `>= 0` 时，表示系统中当前可用资源的数目
- 当其值 `< 0` 时，其绝对值表示系统中因请求该类资源而被阻塞的进程数目

除信号量的初值外，信号量的值仅能由 P 操作和 V 操作更改，操作系统利用它的状态对进程和资源进行管理

#### 锁  

- **互斥锁**：同一时间只能有一个线程访问加锁的数据。
- **自旋锁**：互斥锁的一种实现，如果自旋锁已经被别的执行单元保持，调用者就一直 **循环等待** 是否该自旋锁的保持者已经释放了锁。
- **读写锁**：一种特殊的自旋锁，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作。**写者是排他性的，一个读写锁同时只能有一个写者或多个读者（与CPU数相关），但不能同时既有读者又有写者**。
- **阻塞锁**：与自旋锁不同，改变了线程的运行状态。**让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态**，准备就绪状态的所有线程，通过竞争，进入运行状态。

> 在Java中synchronized,ReentrantLock,Object.wait() / notify()都属于阻塞锁。

- **可重入锁**：也叫做递归锁，指的是同一线程上该锁是可重入的，对于不同线程则相当于普通的互斥锁。
- **公平锁**：加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得。
- **非公平锁**：加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待。`ReentrantLock`中的`lock()`默认就是非公平锁。
- **悲观锁**：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。加锁的时间可能会很长，也就是说悲观锁的并发访问性不好。
- **乐观锁**：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。乐观锁不能解决脏读的问题，可以通过添加时间戳和版本来来解决。

#### 死锁  

死锁是指多个进程因循环等待资源而造成无法执行的现象。死锁会造成进程无法执行，同时会造成系统资源的极大浪费(资源无法释放)。

##### 死锁产生的四个必要条件  

- `互斥使用`：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，则请求者只能等待，直至占有资源的进程用毕释放。
- `不可抢占`：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。
- `请求和保持`：指进程已经保持至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。
- `循环等待`：指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。

##### 死锁避免  

**互斥锁的加锁规则**：给定所有互斥操作一个全序，如果每个线程均按这种顺序获得互斥锁，并且按相反顺序解锁，则不会发生死锁。

#### CAS  

**比较并交换(compare and swap, CAS)**，是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作。**该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值**。

在使用上，通常会记录下某块内存中的旧值，通过对旧值进行一系列的操作后得到新值，然后通过CAS操作将新值与旧值进行交换。**如果这块内存的值在这期间内没被修改过，则旧值会与内存中的数据相同，这时CAS操作将会成功执行使内存中的数据变为新值**。如果内存中的值在这期间内被修改过，则一般来说旧值会与内存中的数据不同，这时CAS操作将会失败，新值将不会被写入内存。

## 进程间通信  

本地进程间通信的方式有很多，可以总结为下面四类：

- 消息传递（管道、FIFO、消息队列）
- 同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量）
- 共享内存（匿名的和具名的）
- 远程过程调用（Solaris门和Sun RPC）

## 子进程  

在 Unix 和类 Unix 系统中，子进程通常为系统调用 `fork` 的产物。调用 `fork` 后的父子进程会运行在不同的内存空间中，当 `fork` 发生时两者的内存空间有着完全相同的内容，对内存的写入和修改、文件的映射都是独立的，两个进程不会相互影响。除此之外，子进程几乎是父进程的完整副本。

既然父进程和子进程拥有完全相同的内存空间并且两者对内存的写入都不会相互影响，那么是否意味着子进程在 `fork` 时需要对父进程的内存进行全量的拷贝呢？

在一些早期的 *nix 系统上，系统调用 `fork` 确实会立刻对父进程的内存空间进行复制，但是在今天的多数系统中， `fork` 并不会立刻触发这一过程，而是在内存被修改时，才会进行数据复制（Copy-On-Write）。

当 `fork` 函数调用时，父进程和子进程会被 Kernel 分配到不同的虚拟内存空间中，所以在两个进程看来它们访问的是不同的内存：

- 在真正访问虚拟内存空间时，Kernel 会将虚拟内存映射到物理内存上，所以父子进程共享了物理上的内存空间；
- 当父进程或者子进程对共享的内存进行修改时，共享的内存才会以页为单位进行拷贝，父进程会保留原有的物理空间，而子进程会使用拷贝后的新物理空间；

## 线程  

线程是 **操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位**。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。在Unix System V及SunOS中也被称为`轻量进程(lightweight processes)`，但轻量进程更多指`内核线程(kernel thread)`，而把`用户线程(user thread)`称为线程。

线程是独立调度和分派的基本单位。线程可以操作系统内核调度的内核线程，如`Win32线程`；由用户进程自行调度的用户线程，如Linux平台的POSIX `Thread`；或者由内核与用户进程，如`Windows 7的线程`，进行混合调度。

同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。但同一进程中的多个线程有各自的调用栈，自己的寄存器环境，自己的线程本地存储。

### 线程的属性  

- **轻型实体**：线程中的实体基本上不拥有系统资源，只是有一点必不可少的、能保证独立运行的资源。线程的实体包括程序、数据和TCB。线程是动态概念，它的动态特性由线程控制块TCB（Thread Control Block）描述。TCB包括以下信息：

  - 线程状态。
  - 当线程不运行时，被保存的现场资源。
  - 一组执行堆栈。
  - 存放每个线程的局部变量主存区。
  - 访问同一个进程中的主存和其它资源。

  用于指示被执行指令序列的程序计数器、保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈。

- **独立调度和分派的基本单位**：在多线程OS中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位。由于线程很“轻”，故线程的切换非常迅速且开销小（在同一进程中的）。

- **可并发执行**：在一个进程中的多个线程之间，可以并发执行，甚至允许在一个进程中所有线程都能并发执行；同样，不同进程中的线程也能并发执行，充分利用和发挥了处理机与外围设备并行工作的能力。

- **共享进程资源**：在同一进程中的各个线程，都可以共享该进程所拥有的资源，这首先表现在：所有线程都具有相同的地址空间（进程的地址空间），这意味着，线程可以访问该地址空间的每一个虚地址；此外，还可以访问进程所拥有的已打开文件、定时器、信号量机构等。由于同一个进程内的线程共享内存和文件，所以线程之间互相通信不必调用内核。

> 线程共享的环境包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。

线程是程序执行的一条路径，在多线程的OS中，线程是调度和分配的基本单位，而进程是拥有资源的基本单位。

### 进程 vs 线程  

**线程本质就是堆栈**，当一段程序在执行，能代表它的是他的过去和现在。*过去* 在堆栈中，*现在* 则是 CPU 的所有寄存器，如果我们要挂起一个线程，我们把寄存器也保存到堆栈中，我们就具有它的所有状态，可以随时恢复它。

**进程的本质是地址空间**，当我们切换线程的时候，同时切换它的地址空间（通过修改MMU即可），则认为发生了进程切换。

## 中断  

中断（英语：Interrupt）是指 **处理器接收到来自硬件或软件的信号，提示发生了某个事件，应该被注意，这种情况就称为中断**。

通常，在接收到来自外围硬件（相对于中央处理器和内存）的异步信号，或来自软件的同步信号之后，处理器将会进行相应的 *硬件／软件* 处理。发出这样的信号称为进行中断请求（interrupt request，IRQ）。**硬件中断导致处理器通过一个运行信息切换（context switch）来保存执行状态（以程序计数器和程序状态字等寄存器信息为主）；软件中断则通常作为CPU指令集中的一个指令，以可编程的方式直接指示这种运行信息切换，并将处理导向一段中断处理代码**。中断在计算机多任务处理，尤其是即时系统中尤为有用。

### 硬件中断  

由硬件发出或产生的中断称为硬中断，按硬中断事件的来源和实现手段可将中断划分为外中断和内中断：

- **外中断**：又称为中断或异步中断，是指 **来自处理器以外的中断信号，包括时钟中断、键盘中断、外部设备中断等**。外中断又分为可屏蔽中断和不可屏蔽中断，各个中断具有不同的优先级，表示事件的紧急程度，在处理高一级中断时，往往会部分或全部屏蔽低等级中断。
- **内中断**：又称为异常或同步中断（产生时必须考虑与处理器时钟同步），是指 **来自处理器内部的中断信号，通常是由于程序执行过程中，发现与当前指令关联的、不正常的或错误的事件**。

### 软件中断  

软件中断：是一条CPU指令，用以自陷一个中断。由于 **软中断指令通常要运行一个切换CPU至内核态（Kernel Mode/Ring 0）的子例程，它常被用作实现系统调用（System call）**。

处理器通常含有一个内部中断屏蔽位，并允许通过软件来设定。一旦被设定，所有外部中断都将被系统忽略。这个屏蔽位的访问速度显然快于中断控制器上的中断屏蔽寄存器，因此可提供更快速地中断屏蔽控制。

中断尽管可以提高计算机处理性能，但 **过于密集的中断请求／响应反而会影响系统性能。这类情形被称作中断风暴（interrupt storm）**。

## 内核态&用户态  

**内核态是一种 CPU 的特权态**，CPU 可以在特权态下执行特殊的指令，访问这个特权态才运行访问的资源。上面提到的三种中断形式：外中断、异常中断、软件中断，均可使 OS 从用户态切换到内核态。

### 内核态切换  

**内核态切换不一定进行上下文切换**。先考虑简单的内核态切换——获取当前系统时间。CPU 从用户态切换到内核态，保存用户态的寄存器数据，执行内核代码以获取数据，将数据存储到调用者可访问的存储器或寄存器，恢复用户态的寄存器数据并返回。这里未进行完整的上下文切换，只是涉及用户态到内核态的模式切换。

现在考虑一个系统调用，该调用会阻塞调用者，直到发生某些事件或数据可用为止。在这种情况下，内核将被迫保存调用者的完整上下文，将其标记为 阻塞态，以便调度程序在该事件或数据到达之前无法运行它。这时调度程序会加载另一个就绪线程/进程的上下文。这里的内核态切换就会导致上下文切换。



## 内存管理  

### 存储器工作原理  

应用程序如何在计算机系统上运行的呢？首先，用编程语言编写和编辑应用程序，所编写的程序称为源程序，源程序不能再计算机上直接被运行，需要通过三个阶段的处理：**编译程序处理源程序并生成目标代码，链接程序把他们链接为一个可重定位代码，此时该程序处于逻辑地址空间中；下一步装载程序将可执行代码装入物理地址空间，直到此时程序才能运行**。

#### 程序编译  

源程序经过编译程序的处理生成目标模块（目标代码）。**一个程序可由独立编写且具有不同功能的多个源程序模块组成，由于模块包含外部引用（即指向其他模块中的数据或指令地址，或包含对库函数的引用），编译程序负责记录引用发生的位置，其处理结果将产生相应的多个目标模块，每个模块都附有供引用使用的内部符号表和外部符号表。符号表中依次给出各个符号名及在本目标模块中的名字地址，在模块链接时进行转换**。

#### 程序链接  

链接程序(Linker)的作用是根据目标模块之间的调用和依赖关系，将主调模块、被调模块以及所用到的库函数装配和链接成一个完整的可装载执行模块。根据程序链接发生的时间和链接方式，程序链接可分为以下三种方式：

- **静态链接**：在程序装载到内存和运行前，就已将它所有的目标模块及所需要的库函数进行链接和装配成一个完整的可执行程序且此后不再拆分。
- **动态链接**：在程序装入内存前并未事先进行程序各目标模块的链接，而是在程序装载时一边装载一边链接，生成一个可执行程序。在装载目标模块时，若发生外部模块调用，将引发响应外部目标模块的搜索、装载和链接。
- **运行时链接**：在程序执行过程中，若发现被调用模块或库函数尚未链接，先在内存中进行搜索以查看是否装入内存；若已装入，则直接将其链接到调用程序中，否则进行该模块在外存上的搜索，以及装入内存和进行链接，生成一个可执行程序。

运行时链接将链接推迟到程序执行时，可以很好的提高系统资源的利用率和系统效率。

#### 程序装载  

程序装载就是将可执行程序装入内存，这里有三种方式：

- **绝对装载**：装载模块中的指令地址始终与其内存中的地址相同，即模块中出现的所有地址均为绝对地址。
- **可重定位装载**：根据内存当时的使用情况，决定将装载代码模块放入内存的物理位置。模块内使用的都是相对地址。
- **动态运行时装载**：为提高内存利用率，装入内存的程序可换出到磁盘上，适当时候再换入内存中，对换前后程序在内存中的位置可能不同，即允许进程的内存映像在不同时候处于不同位置，此时模块内使用的地址必定为相对地址。

磁盘中的装载模块所使用的是逻辑地址，其逻辑地址集合称为进程的逻辑地址空间。进程运行时，其装载代码模块将被装入物理地址空间中，此时程序和数据的实际地址不可能同原来的逻辑一致。**可执行程序逻辑地址转换为物理地址的过程被称为 “地址重定位”**。

- **静态地址重定位**：由装载程序实现装载代码模块的加载和物理地址转换，把它装入分配给进程的内存指定区域，其中所有逻辑地址修改为物理地址。地址转换在进程执行前一次完成，易于实现，但不允许程序在执行过程中移动位置。
- **动态地址重定位**：由装载程序实现装载代码模块的加载，把它装入分配给进程的内存指定区域，但对链接程序处理过的程序的逻辑地址不做任何改变，程序内存起始地址被置入硬件专用寄存器 —— **重定位寄存器**。程序执行过程中，每当CPU引用内存地址时，有硬件截取此逻辑地址，并在它被发送到内存之前加上重定位寄存器的值，以实现地址转换。
- **运行时链接地址重定位**：对于静态和动态地址重定位装载方式而言，装载代码模块是由整个程序的所有目标模块及库函数经链接和整合构成的可执行程序，即在程序启动执行前已经完成了程序的链接过程。可见，装载代码的正文结构是静态的，在程序运行期间保持不变。**运行时链接装载方式必然采用运行时链接地址重定位**。

> 重定位寄存器：用于保存程序内存起始地址。

### 连续存储管理  

#### 固定分区存储管理  

固定分区存储管理又称为静态分区模式，基本思想是：内存空间被划分成数目固定不变的分区，各分区大小不等，每个分区装入一个作业，若多个分区中都有作业，则他们可以并发执行。

为说明各分区分配和使用情况，需要设置一张内存分配表，记录内存中划分的分区及其使用情况。内存分配表中指出各分区起始地址和长度，占用标志用来指示此分区是否被使用。

#### 可变分区存储管理  

可变分区存储管理按照作业大小来划分分区，但划分的时间、大小、位置都是动态的。系统把作业装入内存时，根据其所需要的内存容量查看是否有足够空间，若有则按需分割一个分区分配给此作业；若无则令此作业等待内存资源。

### 虚拟内存  

在连续存储管理的方式下，程序直接操作物理内存。这样的内存管理方式会造成诸多错误：**地址空间不隔离**、运行时内存地址不确定、内存使用率低。为解决这些问题人们提出了 **内存分段** 技术，同时内存分段需要引入 **虚拟地址空间** 的概念。

> 地址空间：可寻址的一片空间，如果这个空间是虚拟的，就是虚拟地址空间；如果是物理的，就是物理地址空间

虚拟内存是计算机系统内存管理的一种技术，**虚拟地址空间构成虚拟内存**。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片。还有部分暂时存储在外部磁盘存储器上（Swap），在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存的使用也更有效率。

**虚拟内存不只是用磁盘空间来扩展物理内存** 的意思——这只是扩充内存级别以使其包含硬盘驱动器而已。把内存扩展到磁盘只是使用虚拟内存技术的一个结果，它的作用也可以通过覆盖或者把处于不活动状态的程序以及它们的数据全部交换到磁盘上等方式来实现。

#### 内存分页  

内存分段能很好的解决地址空间不隔离、运行时内存地址不确定的问题，但对于内存使用率低不能很好的解决。这个问题的关键是能不能在换出一个完整的程序之后，把另一个完整的程序换进来。而这种分段机制，映射的是一片连续的物理内存，所以得不到解决。

**内存分页仍然是一种虚拟地址空间到物理地址空间映射的机制，但粒度更加的小了**。内存分页的虚拟地址空间仍然是连续的，但是，每一页映射后的物理地址就不一定是连续的了。正是因为有了分页的概念，程序的换入换出就可以以页为单位了。

#### MMU  

内存管理单元（memory management unit，MMU），它是一种负责处理中央处理器（CPU）的内存访问请求的计算机硬件。它的功能包括 **虚拟地址到物理地址的转换**（即虚拟内存管理）、内存保护、中央处理器高速缓存的控制。

内存管理单元通常借助一种 **转译旁观缓冲器（Translation Lookaside Buffer，TLB）** 的高速缓存来将虚拟页号转换为物理页号。当 TLB 中没有转换记录时，则使用一种较慢的机制，其中包括专用硬件（hardware-specific）的数据结构（Data structure）或软件辅助手段。这个数据结构称为 **分页表**，页表中的数据就叫做 **分页表项（page table entry，PTE）**。物理页号结合页偏移量便提供出了完整的物理地址。

有时，TLB 或 PTE 会禁止对虚拟页的访问，这可能是因为没有物理随机存取存储器（random access memory）与虚拟页相关联。如果是这种情况， MMU 将向 CPU 发出 **缺页错误（page fault）** 的信号。操作系统将进行处理，也许会尝试寻找 RAM 的空白帧，同时创建一个新的 PTE 将之映射到所请求的虚拟地址。如果没有空闲的 RAM，可能必须关闭一个已经存在的页面，使用一些替换算法，将之保存到磁盘中（这被称之为 **页面调度**）。

#### TLB  

最简单的分页表系统通常维护一个帧表和一个分页表，帧表处理帧映射信息。分页表处理页的虚拟地址和物理帧的映射。还有一些辅助信息，如当前存在标识位(present bit)，**脏数据标识位** 或已修改的标识位，地址空间或 **进程ID** 信息。

辅助存储，比如硬盘可以用于增加物理内存。页可以调入和调出到物理内存和磁盘。当前存在标识位可以指出那些页在物理内存，哪些页在硬盘上。页可以指出如何处理这些不同页。是否从硬盘读取一个页，或把其他页从物理内存调出。页面的频繁更换，导致整个系统效率急剧下降，这个现象称为 **内存抖动（或颠簸）**。抖动一般是内存分配算法不好，内存太小引或者程序的算法不佳引起的。

脏数据标识位可以优化性能。一个页从硬盘调入到物理内存中，读取后调出，当页没有更改不需要写回硬盘。但是如果页在调入物理内存后被修改，会标记其为脏数据，意味着该页必需被写回备用存储。这种策略需要当页被调入到内存后，后备存储保留一份页的拷贝。有了脏数据标志位，一些页随时会同时存在于物理内存和后备存储中。

地址空间 或 进程ID 信息是必要的，内存管理系统需要知道页对应的进程。两个不同的进程可以使用两个相同的虚拟地址。分页表必需为两个进程提供不同的虚拟内存。用 **虚拟内存页关联进程ID** 页可以帮助选择要调出的页，当页关联到不活跃进程上，特别是那些主要代码页被调出的进程，相比活跃进程需要页的可能性会更小。

#### 进程空间  

有内存分页后，进程的概念很自然就被发明出来了。TLB 是 MMU 的输入，那么一个自然的想法，我们有多个 TLB ，一会儿用这个，一会儿用那个，这样我们可以根据需要用不同的内存，这个用来表达不同 MMU 的概念，体现在软件的观感上，就是进程。

当然， MMU 封装为进程，还和“线程”概念进行了一定程度上进行了绑定，所以，软件的进程，不是简单的 MMU 的封装，但我们在理解寻址的概念的时候，是可以简单这样认为的。有了页寻址的概念，进程的空间和物理地址看到的空间就很不一样了。

#### 进程内核空间  

从进程发出的内存访问，都通过 MMU 翻译，包括请求从一个进程切换到另一个进程。这样一来，进程的权力太大了。所以，还是很自然的，我们在 MMU 中可以设置一个标志，说明 **某些地址是具有更高优先级** 的，一般情况下不允许访问，要访问就要提权。一旦提权，代码执行流就强行切换到这片高级内存的特定位置。这样，一个进程就有了两个权限级别：用户态和内核态，用户态用于一般的程序，内核态用来做进程的管理。

用户态和内核态都在同一个页表中管理，所以，本质上它们属于 **同一个进程**。只是它们属于进程的不同权限而已。为了实现的方便，现在通常让所有进程的 MMU 页表的内核空间指向物理空间的同一个位置，这样，看起来我们就有了一个独立于所有进程的实体，这个实体被称为 *操作系统内核*，它是管理所有进程的一个中心软件。

#### 页面调度算法  

- **FIFO算法**：先入先出，即淘汰最早调入的页面。
- **OPT(MIN)算法**：选未来最远将使用的页淘汰，是一种最优的方案，可以证明缺页数最小。可惜，MIN需要知道将来发生的事，只能在理论中存在，实际不可应用。
- **LRU(Least-Recently-Used)算法**：用过去的历史预测将来，选最近最长时间没有使用的页淘汰(也称最近最少使用)。性能最接近OPT。**与页面使用时间有关**。
- **LFU(Least Frequently Used)算法**：即最不经常使用页置换算法，要求在页置换时置换引用计数最小的页，因为经常使用的页应该有一个较大的引用次数。**与页面使用次数有关**。
- **Clock**：给每个页帧关联一个使用位，当该页第一次装入内存或者被重新访问到时，将使用位置为1。每次需要替换时，查找使用位被置为0的第一个帧进行替换。在扫描过程中，如果碰到使用位为1的帧，将使用位置为0，在继续扫描。如果所谓帧的使用位都为0，则替换第一个帧。



## 磁盘与文件  

### 磁盘  

磁盘是可以持久存储的设备，根据存储介质的不同，常见磁盘可以分为两类：机械磁盘和固态磁盘

**机械磁盘**，也称为硬盘驱动器，通常缩写为HDD。机械磁盘主要有盘片和读写磁头组成，数据就存储在盘片的环状磁道中。在读写数据前，需要移动读写磁头，定位到数据所在的磁道，然后才能访问数据。最小读写单位是 **扇区** ，一般大小为512字节。

**固态磁盘**，通常缩写为SSD，有固态电子元器件组成。固态磁盘不需要磁道寻址，所以，不管是连续I/O还是随机I/O的性能，都比机械磁盘要好得多。

**连续 I/O 还可以通过预读的方式，来减少I/O请求的次数**，这也是其性能优异的一个原因。很多性能优化的方案，也都会从这个角度出发，来优化I/O性能。最小读写单位是 页，通常大小是 4KB ，8KB 等。

#### 磁盘调度  

磁盘访问延迟 = 队列时间 + 控制器时间 + 寻道时间 + 旋转时间 + 传输时间

磁盘调度的目的是减小延迟，其中前两项可以忽略，寻道时间是主要矛盾。

#### 磁盘调度算法  

- `FCFS`：先进先出的调度策略，这个策略具有公平的优点，因为每个请求都会得到处理，并且是按照接收到的顺序进行处理。
- `SSTF(Shortest-seek-time First 最短寻道时间优先)`：选择使磁头从当前位置开始移动最少的磁盘I/O请求，所以 SSTF 总是选择导致最小寻道时间的请求。总是选择最小寻找时间并不能保证平均寻找时间最小，但是能提供比 FCFS 算法更好的性能，会存在饥饿现象（会导致较远的I/O请求不能满足）。
- `SCAN`：SSTF+中途不回折，每个请求都有处理机会。SCAN 要求磁头仅仅沿一个方向移动，并在途中满足所有未完成的请求，直到它到达这个方向上的最后一个磁道，或者在这个方向上没有其他请求为止。由于磁头移动规律与电梯运行相似，SCAN 也被称为`电梯算法`。

> SCAN 算法对最近扫描过的区域不公平，因此，它在访问局部性方面不如 FCFS 算法和 SSTF 算法好。

- `C-SCAN`：SCAN+直接移到另一端，两端请求都能很快处理。把扫描限定在一个方向，当访问到某个方向的最后一个磁道时，磁道返回磁盘相反方向磁道的末端，并再次开始扫描。其中“C”是Circular（环）的意思。
- `LOOK(C-LOOK)`：釆用SCAN算法和C-SCAN算法时磁头总是严格地遵循从盘面的一端到另一端，显然，在实际使用时还可以改进，**即磁头移动只需要到达最远端的一个请求即可返回，不需要到达磁盘端点**。这种形式的SCAN算法和C-SCAN算法称为LOOK和C-LOOK调度。这是因为它们在朝一个给定方向移动前会查看是否有请求。

### 文件系统  

文件系统是对存储设备上的文件，进行组织管理的一种机制。而 Linux 在各种文件系统实现上，抽象了一层虚拟文件系统 VFS ，它定义了一组，所有文件系统都支持的，数据结构和标准接口。VFS 内部通过目录项，索引节点，逻辑块以及超级块等数据结构，来管理文件。

- 目录项：记录了文件的名字，以及文件与其他目录项之间的目录关系。
- 索引节点：记录了文件的元数据
- 逻辑块：是由连续磁盘扇区构成的最小读写单元，用来存储文件系统
- 超级块：用来记录文件系统整体的状态，如索引节点和逻辑块的使用情况等。

其中，目录项是一个内存缓存；而超级块，索引节点和逻辑块，都是存储在磁盘中的持久数据。

如果每次都读写 512 字节这么小的单位的话，效率很低。所以，文件系统会把连续的扇区或页，组成逻辑块，然后以逻辑块作为最小单元来管理数据。常见的逻辑块的大小是 4KB ，也就是连续8个扇区，或者单独的一个页，都可以组成一个逻辑块。

#### 通用块层  

为了减小不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理各种不同的块设备。 通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层。它主要有两个功能：

- 同虚拟文件系统的功能类似：向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序。
- I/O调度：对文件系统和应用程序发来的I/O请求排队，并通过重新排序，请求合并等方式，提高磁盘读写的效率。Linux 内核支持四种 I/O 调度算法，分别是 NONE , NOOP , CFQ 以及 DeadLine

#### IO 栈  

可以把 Linux 存储系统的I/O栈，由上到下分为三个层次，分别是文件系统层，通用块层和设备层。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/linux_disk_io_stack-diagram.png)

- **文件系统层**：包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过调用块层，来存储和管理磁盘数据。
- **调用块层**：包扣块设备I/O队列和I/O调度器。它会对文件系统的I/O请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层。
- **设备层**：包扣存储设备和相应的驱动程序，负责最终物理设备的I/O操作。

### Linux文件权限  

Linux文件采用10个标志位来表示文件权限，如下所示：

```sh
-rw-r--r--  1 skyline  staff    20B  1 27 10:34 1.txt
drwxr-xr-x   5 skyline  staff   170B 12 23 19:01 ABTableViewCell
```

第一个字符一般用来区分文件和目录，其中：

- d：表示是一个目录，事实上在ext2fs中，目录是一个特殊的文件。
- －：表示这是一个普通的文件。
- l: 表示这是一个符号链接文件，实际上它指向另一个文件。
- b、c：分别表示区块设备和其他的外围设备，是特殊类型的文件。
- s、p：这些文件关系到系统的数据结构和管道，通常很少见到。

第2～10个字符当中的每3个为一组，左边三个字符表示所有者权限，中间3个字符表示与所有者同一组的用户的权限，右边3个字符是其他用户的权限。

这三个一组共9个字符，代表的意义如下：

- r(Read，读取)：对文件而言，具有读取文件内容的权限；对目录来说，具有浏览目录的权限
- w(Write,写入)：对文件而言，具有新增、修改文件内容的权限；对目录来说，具有删除、移动目录内文件的权限。
- x(eXecute，执行)：对文件而言，具有执行文件的权限；对目录来说该用户具有进入目录的权限。

权限的掩码可以使用十进制数字表示：

- 如果可读，权限是二进制的100，十进制是4；
- 如果可写，权限是二进制的010，十进制是2；
- 如果可运行，权限是二进制的001，十进制是1；

#### chmod命令  

chmod命令非常重要，用于改变文件或目录的访问权限。用户用它控制文件或目录的访问权限。

该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。

1. 文字设定法

chmod ［who］ ［+ | - | =］ ［mode］ 文件名

命令中各选项的含义为：

操作对象who可是下述字母中的任一个或者它们的组合：

- u 表示“用户（user）”，即文件或目录的所有者。
- g 表示“同组（group）用户”，即与文件属主有相同组ID的所有用户。
- o 表示“其他（others）用户”。
- a 表示“所有（all）用户”。它是系统默认值。

操作符号可以是：

- - 添加某个权限。
- - 取消某个权限。
- = 赋予给定权限并取消其他所有权限（如果有的话）。

设置mode所表示的权限可用下述字母的任意组合：

- r 可读。
- w 可写。
- x 可执行。
- X 只有目标文件对某些用户是可执行的或该目标文件是目录时才追加x 属性。
- s 在文件执行时把进程的属主或组ID置为该文件的文件属主。方式“u＋s”设置文件的用户ID位，“g＋s”设置组ID位。
- t 保存程序的文本到交换设备上。
- u 与文件属主拥有一样的权限。
- g 与和文件属主同组的用户拥有一样的权限。
- o 与其他用户拥有一样的权限。

文件名：以空格分开的要改变权限的文件列表，支持通配符。

在一个命令行中可给出多个权限方式，其间用逗号隔开。例如：`chmod g+r，o+r example`使同组和其他用户对文件example 有读权限。

1. 数字设定法

直接使用数字表示的权限来更改：

```sh
例： 
$ chmod 644 mm.txt
```

#### chgrp命令  

功能：改变文件或目录所属的组。

语法：chgrp ［选项］ group filename

```sh
例：
$ chgrp - R book /opt/local /book
```

改变/opt/local /book/及其子目录下的所有文件的属组为book。

#### chown命令  

功能：更改某个文件或目录的属主和属组。这个命令也很常用。例如root用户把自己的一个文件拷贝给用户xu，为了让用户xu能够存取这个文件，root用户应该把这个文件的属主设为xu，否则，用户xu无法存取这个文件。

语法：chown ［选项］ 用户或组 文件

说明：chown将指定文件的拥有者改为指定的用户或组。用户可以是用户名或用户ID。组可以是组名或组ID。文件是以空格分开的要改变权限的文件列表，支持通配符。

```sh
例：把文件shiyan.c的所有者改为wang。

    chown wang shiyan.c
```



## 设备管理  

外部设备分为两大类：

- **存储型设备**：以存储大量信息和快速检索为目标，在系统中存储持久性信息。
- **I/O型设备**：如显示器、打印机等。

### I/O硬件原理  

#### I/O系统  

通常把I/O设备及其接口线路、控制部件、通道和管理软件称为I/O系统，把计算机的内存和设备介质之间的信息传送操作称为I/O操作。可按照不同方式对设备进行分类：按I/O操作特性分为输入型设备、输出型设备和存储型设备；按I/O信息交换单位分为字符设备和块设备。

> 输入、输出型设备通常是字符设备，存储型设备通常是块设备。

存储型设备又分为顺序存储设备和直接存取设备。前者严格依赖信息的物理位置进行读写和定位，如磁带。后者的特点是存取任何一个物理块所需要的时间几乎不依赖于此信息所处的位置，如磁盘。

#### I/O控制方式  

##### 轮询方式  

轮询方式又称程序直接控制方式，使用查询指令测试设备控制器的忙闲状态位，确定内存和设备是否能交换数据。轮询方式采用三条指令：查询指令，查询设备是否就绪；读写指令，当设备就绪时执行数据交换；转移指令，当设备未就绪时执行转移指令指向查询指令继续查询。可见，在这种方式下CPU和设备只能串行工作。

##### 中断方式  

在这种方式下CPU和设备之间传输数据的过程如下：

1. 进程发出启动I/O指令，CPU加载控制信息到设备控制器的寄存器，然后进程继续执行不涉及本次I/O数据的任务，或放弃CPU等待设备I/O操作完成。
2. 设备控制器检查寄存器的内容，按照I/O指令的要求执行相应I/O操作，一旦传输完成，设备控制器发出I/O中断请求信号。
3. CPU收到并响应I/O中断后，转向设备的I/O中断处理程序执行。
4. 中断处理程序执行数据读取操作，将I/O缓冲寄存器的内容写入内存，操作结束后退出中断处理程序，返回发生中断前的状态。
5. 进程调度程序在适当的时候让得到数据的进程恢复执行。

在I/O中断方式中，如果设备控制器的数据缓冲区较小，当缓冲器装满后便会发生中断，那么在数据传输过程中发生中断次数会很多，这样就消耗了大量CPU时间。

##### DMA方式  

虽然中断方式提高了CPU利用率，但是在响应中断请求后必须停止现行程序，转入中断处理程序并参与数据传输操作。在`DMA(Direct Memory Access)`方式中，内存和设备之间有一条数据通路成块地传送数据，无须CPU干预，实际数据传输操作由DMA直接完成。为实现DMA，至少需要以下逻辑部件：

1. 内存地址寄存器：存放内存中需要交换数据的地址，DMA传送之前由程序送入首地址；DMA传送过程中，每次交换数据都把地址寄存器的内容加1。
2. 字计数器：记录传送数据的总字数，每次传送一个字就把字计数器减1。
3. 数据缓冲寄存器或数据缓冲区：暂存每次传送的数据。
4. 设备地址寄存器：存放I/O信息的地址，如磁盘的柱面号。
5. 中断机制和控制逻辑：用于向CPU提出I/O中断请求及CPU发来的I/O命令，管理DMA的传送过程。

##### 通道方式  

通道又称I/O处理器，能完成内存和设备之间的信息传送，与CPU并行地执行操作。采用I/O通道设计后，I/O操作过程如下：CPU在执行主程序时遇到I/O请求，启动在指定通道上选址的设备，一旦启动成功，通道开始控制设备进行操作，这时CPU就可以执行其他任务并与通道并行工作，直到I/O操作完成；当通道发出I/O操作结束中断时，处理器才响应并停止当前工作，转向I/O操作结束事件。



## I/O  

### 基本概念  

#### 文件描述符fd  

文件描述符（`File descriptor`）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。

文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于 `UNIX、Linux` 这样的操作系统。

#### 缓存 I/O  

缓存 `I/O` 又被称作标准 `I/O`，大多数文件系统的默认 `I/O` 操作都是缓存 `I/O`。在 `Linux`的`缓存 I/O` 机制中，操作系统会将 `I/O` 的数据缓存在文件系统的页缓存（ `page cache`）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 `CPU` 以及内存开销是非常大的。

### IO模式  

刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段：

1. 等待数据准备
2. 将数据从内核拷贝到进程中

正式因为这两个阶段，Linux系统产生了下面五种网络模式的方案。

- `阻塞 I/O`（blocking IO）
- `非阻塞 I/O`（nonblocking IO）
- `I/O 多路复用`（ IO multiplexing）
- `信号驱动 I/O`（ signal driven IO）
- `异步 I/O`（asynchronous IO）

> 由于signal driven IO在实际中并不常用，所以这里只提及剩下的四种 IO Model。

#### 阻塞IO  

在 `Linux` 中，默认情况下所有的 `socket` 都是 `blocking` ，一个典型的读操作流程大概是这样：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/359a774ea7d5d1e6ac08845023993796.png)

当用户进程调用了 `recvfrom` 这个系统调用， `kernel` 就开始了 IO 的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的 `UDP` 包。这个时候 `kernel` 就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当 `kernel` 一直等到数据准备好了，它就会将数据从 `kernel` 中拷贝到用户内存，然后 `kernel` 返回结果，用户进程才解除 `block` 的状态，重新运行起来。

> blocking IO的特点就是在IO执行的两个阶段都被block了

#### 非阻塞 I/O  

`Linux` 下，可以通过设置 `socket` 使其变为 `non-blocking` 。当对一个 `non-blocking socket` 执行读操作时，流程是这个样子：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/076dcab40e2b43efa5d1aa97d96a85e2.png)

当用户进程发出 `read` 操作时，如果 `kernel` 中的数据还没有准备好，那么它并不会 `block` 用户进程，而是立刻返回一个 `error` 。从用户进程角度讲 ，它发起一个 `read` 操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个 `error` 时，它就知道数据还没有准备好，于是它可以再次发送 `read` 操作。一旦 `kernel` 中的数据准备好了，并且又再次收到了用户进程的 `system call` ，那么它马上就将数据拷贝到了用户内存，然后返回。

> nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有

#### IO多路复用  

IO多路复用就是我们说的 `select，poll，epoll` ，有些地方也称这种IO方式为 `event driven IO` 。`select/epoll` 的好处就在于单个 `process` 就可以同时处理多个网络连接的 IO 。它的基本原理就是 `select，poll，epoll` 这个 `function` 会不断的轮询所负责的所有 `socket` ，当某个 `socket` 有数据到达了，就通知用户进程。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/c6d2db53d71a8c76c2c9a546c5811773.png)

**当用户进程调用了 select，那么整个进程会被 block**，而同时， `kernel` 会监视所有 `select` 负责的 `socket` ，当任何一个 `socket` 中的数据准备好了， `select` 就会返回。这个时候用户进程再调用 `read` 操作，将数据从 `kernel` 拷贝到用户进程。

> I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，`select()` 函数就可以返回。

这个图和 `blocking IO` 的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个 `system call` (`select` 和 `recvfrom`)，而 `blocking IO` 只调用了一个 `system call` (`recvfrom`)。但是，用 `select` 的优势在于它可以同时处理多个 `connection` 。

所以，**如果处理的连接数不是很高的话，使用 `select/epoll` 的 `web server` 不一定比使用 `multi-threading + blocking IO` 的 `web server` 性能更好，可能延迟还更大**。`select/epoll` 的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。

在IO多路复用实际使用中，对于每一个socket，一般都设置成为 `non-blocking` ，但是，如上图所示，整个用户的 `process` 其实是一直被block的。只不过 `process` 是被 `select` 这个函数 `block` ，而不是被 `socket IO` 给 `block` 。

##### 基本概念  

在 I/O 编程过程中,当需要同时处理多个客户端接入请求时，可以利用多线程或者 `I/O 多路复用` 技术进行处理。**`I/O多路复用` 技术通过把多个I/O的阻塞复用到同一个selct的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求**。**与传统的 `多线程/多进程` 模型比，I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源**，I/O多路复用的主要应用场景如下。

- 服务器需要同时处理多个处于监听状态或者多个连接状态的套接字
- 服务器需要同时处理多种网络协议的套接字

目前支持I/O多路复用的系统调用有 `select、pselect、poll、epoll`，在Linux网络编程; 过程中，很长一段时间都使用 `select` 做轮询和网络事件通知，然而 `select` 的一些固有缺陷导致了它的应用受到了很大的限制。最终 `Linux` 不得不在新的内核版本中寻找 `select` 的替代方案，最终选择了 `epoll`。 `epoll` 与 `select` 的原理比较类似，为了克服 `select` 的缺点， `epoll` 作了很多重大改进，现总结如下。

**支持一个进程打开的 socket 描述符（FD）不受限制（仅受限于操作系统的最大文件句柄数）。**  

**`select` 最大的缺陷就是单个进程所打开的 FD 是有一定限制的**，它由 `FD_SETSIZE` 设置，默认值是 `1024` 。对于那些需要支持上万个 TCP 连接的大型服务器来说显然太少了。可以选择修改这个宏然后重新编译内核，不过这会带来网络效率的下降。我们也可以通过选择多进程的方案（传统的 Apache 方案）解决这个问题，不过虽然在 Linux上创建进程的代价比较小，但仍旧是不可忽视的，另外，进程间的数据交换非常麻烦，对于 Java 由于没有共享内存，需要通过 `Socket` 通信或者其他方式进行数据同步，这带来了额外的性能损耗，增加了程序复杂度，所以也不是一种完美的解决方案。值得庆幸的是， `epoll` 并没有这个限制，它所支持的 `FD` 上限是操作系统的 **最大文件句柄数**，这个数字远远大于 `1024` 。例如，在 `1 GB` 内存的机器上大约是 10万个句柄左右，具体的值可以通过`cat /proc/sys/fs/file- max` 察看，**通常情况下这个值跟系统的内存关系比较大**。

**I/O效率不会随着FD数目的增加而线性下降。**

传统的 `select/poll` 另-个致命弱点就是当你拥有一个很大的 `socket` 集合，由于网络延时或者链路空闲，任一时刻只有少部分的 `socket` 是“活跃”的，但是 **`select/poll` 每次调用都会线性扫描全部的集合，导致效率呈现线性下降**。 `epoll` 不存在这个问题，它只会对“活跃”的 `socket` 进行操作，这是因为在内核实现中 `epoll` 是根据每个 `fd` 上面的 `callback`函数实现的，那么，只有“活跃”的 `socket` 才会主动的去调用 `callback` 函数，其他 `idle`状态 `socket` 则不会。**在这点上， `epoll` 实现了一个伪 AIO**。针对 `epoll` 和 `select` 性能对比的 `benchmark` 测试表明：**如果所有的 `socket` 都处于活跃态，例如一个高速 `LAN`环境， `epoll` 并不比 `select/poll` 效率高太多；相反，如果过多使用 `epoll_ ctl` , 效率相比还有稍微的下降。但是一旦使用 `idleconnections` 模拟 `WAN` 环境，`epoll` 的效率就远在 `select/poll` 之上了**。

**使用 mmap 加速内核与用户空间的消息传递**  

无论是 `select`，`poll` 还是 `epoll` 都需要内核把 FD 消息通知给用户空间，如何避免不必要的内存复制（Zero Copy）就显得非常重要， `epoll` 是通过内核和用户空间 `mmap` 共享同一块内存来实现。

**Epoll 的 API 更加简单**  

包括创建一个 `epoll` 描述符、添加监听事件、阻塞等待所监听的事件发生，关闭 `epoll` 描述符等。

值得说明的是，用来克服 `select/poll` 缺点的方法不只有 `epoll` , `epoll` 只是一种 `Linux` 的 实现方案。在 `freeBSD` 下有 `kqueue`

#### Epoll 边缘触发&水平触发  

epoll 对文件描述符的操作有两种模式：LT（`level trigger`）和ET（`edge trigger`）。LT模式是 **默认模式** ，LT模式与ET模式的区别如下：

- **LT模式**：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用 epoll_wait 时，会再次响应应用程序并通知此事件。
- **ET模式**：当 epoll_wait 检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用 epoll_wait 时，不会再次响应应用程序并通知此事件。

> ET模式 在很大程度上减少了 epoll 事件被重复触发的次数，因此 **效率要比LT模式高**。epoll 工作在ET模式的时候，**必须使用非阻塞套接口**，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。

## 异步 I/O  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/3b385bdf805241ee6cd0d4634bd7510a.png)

用户进程发起 `read` 操作之后，立刻就可以开始去做其它的事。而另一方面，从 `kernel` 的角度，当它受到一个 `asynchronous read` 之后，首先它会立刻返回，所以不会对用户进程产生任何 `block` 。然后，`kernel` 会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，`kernel` 会给用户进程发送一个 `signal` ，告诉它 `read` 操作完成了。

### blocking vs non-blocking  

调用 `blocking IO` 会一直 `block` 住对应的进程直到操作完成，而 `non-blocking IO` 在 `kernel` 还准备数据的情况下会立刻返回。

### synchronous IO vs asynchronous IO  

在说明`synchronous IO`和`asynchronous IO`的区别之前，需要先给出两者的定义。 `POSIX` 的定义是这样子的：

- A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;
- An asynchronous I/O operation does not cause the requesting process to be blocked;

两者的区别就在于 `synchronous IO` 做 `IO operation` 的时候会将 `process` 阻塞。按照这个定义，之前所述的 `blocking IO，non-blocking IO，IO multiplexing` 都属于 `synchronous IO`。

有人会说，`non-blocking IO` 并没有被 `block` 啊。这里有个非常 **狡猾** 的地方，定义中所指的 `IO operation` 是指真实的 IO 操作，就是例子中的 `recvfrom` 这个 `system call` 。`non-blocking IO` 在执行 `recvfrom` 这个 `system call` 的时候，如果 `kernel` 的数据没有准备好，这时候不会 `block` 进程。但是，当 `kernel` 中数据准备好的时候，`recvfrom`会将数据从 `kernel` 拷贝到用户内存中，这个时候进程是被 `block` 了，在这段时间内，进程是被 `block` 的。

而 `asynchronous IO` 则不一样，当进程发起 `IO` 操作之后，就直接返回再也不理睬了，直到 `kernel` 发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被 `block`。



## 面试题  

#### PE文件  

PE文件的全称是`Portable Executable`，意为可移植的可执行的文件，常见的EXE、DLL、OCX、SYS、COM都是PE文件，PE文件是微软Windows操作系统上的程序文件（可能是间接被执行，如DLL）。

------

#### 什么是活锁？与死锁有和区别？  

活锁指的是 **任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败**。 活锁和死锁的区别在于，处于活锁的实体是在不断的改变状态，所谓的“活”， 而处于死锁的实体表现为等待；**活锁有可能自行解开，死锁则不能**。

活锁应该是一系列进程在轮询地等待某个不可能为真的条件为真。活锁的时候进程是不会`blocked`，这会导致耗尽CPU资源。

为解决活锁可以引入一些随机性，例如如果检测到冲突，那么就暂停随机的一定时间进行重试。这回大大减少碰撞的可能性。典型的例子是以太网的`CSMA/CD`检测机制。

------

#### 直接寻址与间接寻址？  

寻址方式就是处理器根据指令中给出的地址信息来寻找物理地址的方式，是确定本条指令的数据地址以及下一条要执行的指令地址的方法。在操作系统中分为指令寻址和操作数寻址。

**指令寻址**：在内存中查找指令的方式。

- **顺序寻址方式**：即采用PC计数器来计数指令的顺序；
- **跳跃寻址方式**：下条指令的地址码不是由程序计数器给出，而是由本条指令给出。

**操作数寻址**：形成操作数的有效地址的方法称为操作数的寻址方式。

- **立即寻址**：操作数作为指令的一部分而直接写在指令中；
- **直接寻址**：直接寻址是一种基本的寻址方法。**在指令格式的地址的字段中直接指出操作数在内存的地址。由于操作数的地址直接给出而不需要经过某种变换**，所以称这种寻址方式为直接寻址方式。
- **简介寻址**：间接寻址是相对直接寻址而言的，在间接寻址的情况下，**指令地址字段中的形式地址不是操作数的真正地址，而是操作数地址的指示器，或者说此形式地址单元的内容才是操作数的有效地址**。

------

#### 如何从用户态切换到内核态？  

1. 程序请求系统服务，执行系统调用
2. 程序运行期间产生中断事件，运行程序被中断，转向中断处理程序处理
3. 程序运行时产生异常事件，运行程序被打断，转向异常处理程序。

这三种情况都是通过中断机制发生，可以说 **中断和异常是用户态到内核态转换的仅有途径**。

------

#### 实时操作系统和分时操作系统的区别？  

- **分时操作系统**：**多个联机用户同时适用一个计算机系统在各自终端上进行交互式会话，程序、数据和命令均在会话过程中提供，以问答方式控制程序运行**。系统把处理器的时间划分为时间片轮流分配给各个连接终端。
- **实时操作系统**：当外部时间或数据产生时，能够对其予以接受并以足够快的速度进行处理，所得结果能够在规定时间内控制生产过程或对控制对象作出快速响应，并控制所有实时任务协调的操作系统。因而，**提供及时响应和高可靠性是其主要特点**。实时操作系统有硬实时和软实时之分，硬实时要求在规定的时间内必须完成操作，这是在操作系统设计时保证的；软实时则只要按照任务的优先级，尽可能快地完成操作即可。我们通常使用的操作系统在经过一定改变之后就可以变成实时操作系统。

下面还要补充一个批处理操作系统：**批处理是指用户将一批作业提交给操作系统后就不再干预，由操作系统控制它们自动运行。这种采用批量处理作业技术的操作系统称为批处理操作系统**。批处理操作系统分为单道批处理系统和多道批处理系统。批处理操作系统不具有交互性，它是为了提高CPU的利用率而提出的一种操作系统。

如果某个操作系统兼有批处理、分时和实时处理的全部或两种功能，我们称为通用操作系统。



# 计算机网络

## 网络分层  

### OSI  

| 层         | 功能                                                         |
| ---------- | ------------------------------------------------------------ |
| 应用层     | 网络进程到应用程序。针对特定应用规定各层协议、时序、表示等，进行封装 。在端系统中用软件来实现，如HTTP等 |
| 表示层     | 数据表示形式，加密和解密，把机器相关的数据转换成独立于机器的数据。规定数据的格式化表示 ，数据格式的转换等 |
| 会话层     | 主机间通讯，管理应用程序之间的会话。规定通信时序 ；数据交换的定界、同步，创建检查点等 |
| 传输层     | 在网络的各个节点之间可靠地分发数据包。所有传输遗留问题；复用；流量；可靠 |
| 网络层     | 在网络的各个节点之间进行地址分配、路由和（不一定可靠的）分发报文。路由（ IP寻址）；拥塞控制。 |
| 数据链路层 | 一个可靠的点对点数据直链。检错与纠错（CRC码）；多路访问；寻址 |
| 物理层     | 一个（不一定可靠的）点对点数据直链。定义机械特性；电气特性；功能特性；规程特性 |



## 底层网络协议  

### ARP（地址解析协议）  

基本功能为透过目标设备的IP地址，查询目标设备的MAC地址，以保证通信的顺利进行。在每台安装有TCP/IP协议的电脑或路由器里都有一个ARP缓存表，表里的IP地址与MAC地址是一对应的。

当发送数据时，主机A会在自己的ARP缓存表中寻找是否有目标IP地址。如果找到就知道目标MAC地址为（00-BB-00-62-C2-02），直接把目标MAC地址写入帧里面发送就可；如果在ARP缓存表中没有找到相对应的IP地址，主机A就会在网络上发送一个 **广播（ARP request）**，目标MAC地址是“FF.FF.FF.FF.FF.FF”，这表示向同一网段内的所有主机发出这样的询问：“192.168.38.11的MAC地址是什么？”网络上其他主机并不响应ARP询问，只有主机B接收到这个帧时，才向主机A做出这样的回应（ARP response）：“192.168.38.11的MAC地址是（00-BB-00-62-C2-02）”。这样，主机A就知道主机B的MAC地址，它就可以向主机B发送信息。同时它还更新自己的ARP缓存表，下次再向主机B发送信息时，直接从ARP缓存表里查找就可。**ARP缓存表采用老化机制**，在一段时间内如果表中的某一行没有使用，就会被删除，这样可以大大减少ARP缓存表的长度，加快查询速度。

> 当发送主机和目的主机不在同一个局域网中时，即便知道目的主机的MAC地址，两者也不能直接通信，必须经过路由转发才可以。所以此时，发送主机通过ARP协议获得的将不是目的主机的真实MAC地址，而是一台可以通往局域网外的路由器的MAC地址。于是此后发送主机发往目的主机的所有帧，都将发往该路由器，通过它向外发送。这种情况称为ARP代理（ARP Proxy）。

### ICMP（互联网控制消息协议）  

它 **用于TCP/IP网络中发送控制消息**，提供可能发生在通信环境中的各种问题反馈，通过这些信息，令管理者可以对所发生的问题作出诊断，然后采取适当的措施解决。它与传输协议最大的不同：它一般不用于在两点间传输数据，而常常 **用于返回的错误信息或是分析路由**。

ICMP控制的内容包括但不仅限于：echo响应（ping）、目标网络不可达、目标端口不可达、禁止访问的网络、拥塞控制、重定向、TTL超时…

### 路由选择协议  

路由选择协议分为：静态的和动态的。Internet中使用的是动态路由选择协议，在Internet的概念中，将整个互联网划分为许多个小的**自治系统（AS）**。AS的最主要的特征：**一个AS对其他AS表现出的是一个单一 和一致的路由选择策略**。

由于AS的存在，路由选择协议又分为两种：

- 内部网关协议（IGP）：即在一个AS内部使用的路由选择协议，而这与互联网中其他AS选用什么路由协议无关。比如：OSPF
- 外部网关协议（EGP）：若源主机和目的主机不再同一个AS中，就需要使用一种协议将路由选择信息传递到另一个AS中，这就是EGP。比如：BGP。

### OSPF（开放式最短路径优先）  

OSPF属于内部网关协议（IGP）的一种，使用Dijkstra提出的**最短路径算法**。

OSPF提出了“区域（Area）”的概念，一个网络可以由单一区域或者多个区域组成。其中，一个特别的区域被称为骨干区域（Backbone Area），该区域是整个OSPF网络的核心区域，并且所有其他的区域都与之直接连接。所有的内部路由都通过骨干区域传递到其他非骨干区域。所有的区域都必须直接连接到骨干区域，如果不能创建直接连接，那么可以通过虚拟链路（Virtual-link）和骨干区域创建虚拟连接。

划分区域的优点：

- 将洪泛法的范围限制在一个区域中。
- 减少每个区域内部路由信息交换的通信量。
- OSPF使用的是**分布式链路状态协议**，使用 **洪泛法**向该路由器所有的相邻路由器发送信息。最终整个区域的所有路由器都得到一个这个信息的副本。这个副本就是 **链路状态数据库（LSDB）用来保存当前网络拓扑结构**，路由器上属于同一区域的链路状态数据库是相同的（属于多个区域的路由器会为每个区域维护一份链路状态数据库）。
- OSPF使用 **“代价（Cost）”**作为路由度量。
- 只有当链路发生变化时才会更新信息。

> 如果同一个目的网络有多条路径，OSPF协议可以进行 **负载均衡**。

### BGP（边界网关协议）  

由于BGP是工作在AS之间的协议，并且各个AS的情况复杂，所以 **BGP只是力求找到一个可以到达目的网络且比较好的路由，而并不是寻找一条最佳路由**。每一个AS都应该有一个**“BGP发言人“**，一般来说，两个BGP发言人是通过一个共享网络连接在一起的，BGP发言人往往是**BGP边界路由**，但也可以不是。

一个BGP发言人与其他AS的BGP发言人要交换路由信息，首先要建立TCP连接，然后在此连接上交换BGP报文以建立BGP会话。当BGP发言人交换了路由信息后，就构造自治系统连通图，最后通过该图来进行路由选择。

### DHCP（动态主机设置协议）  

DHCP是一个局域网的网络协议，使用UDP协议工作，主要有两个用途：

- 用于内部网络或网络服务供应商自动分配IP地址给用户
- 用于内部网络管理员作为对所有电脑作中央管理的手段

**动态主机设置协议（DHCP）是一种使网络管理员能够集中管理和自动分配IP网络地址的通信协议**。在IP网络中，每个连接Internet的设备都需要分配唯一的IP地址。DHCP使网络管理员能从中心结点监控和分配IP地址。当某台计算机移到网络中的其它位置时，能自动收到新的IP地址。

DHCP使用了 **租约** 的概念，或称为计算机IP地址的有效期。租用时间是不定的，主要取决于用户在某地连接Internet需要多久，这对于教育行业和其它用户频繁改变的环境是很实用的。通过较短的租期，DHCP能够在一个计算机比可用IP地址多的环境中动态地重新配置网络。DHCP支持为计算机分配静态地址，如需要永久性IP地址的Web服务器。

### NAT（地址转换协议）  

NAT是一种 **在IP封包通过路由器或防火墙时重写来源IP地址或目的IP地址的技术**。这种技术被普遍使用在有多台主机但只通过一个公有IP地址访问因特网的私有网络中。



## TCP  

### TCP概述  

#### TCP的特点  

- TCP是面向连接的传输层协议。
- TCP连接是点对点的（套接字–IP:Port到套接字）。
- TCP提供可靠交付的服务。
- TCP提供全双工通信。
- 面向字节流。

#### TCP与UDP的区别  

|            | TCP          | UDP        |
| ---------- | ------------ | ---------- |
| 是否连接   | 面向连接     | 面向非连接 |
| 传输可靠性 | 可靠         | 不可靠     |
| 应用场合   | 传输大量数据 | 少量数据   |
| 速度       | 慢           | 快         |

### TCP报文结构  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/tcp_head.png)

- **源端口、目的端口**：16位长。标识出远端和本地的端口号。

- 序列号（seq）

  ：32位长

  - 如果含有同步标识（SYN），则此为最初的序列号；第一个数据比特的序列码为本序列号加一
  - 如果没有同步标识（SYN），则此为第一个数据比特的序列码

- **确认号（ack）**：32位长。希望收到的下一个数据报的序列号，表明到序列号 `N-1` 为止的所有数据已经正确收到。

- TCP协议数据报头长：4位长。表明TCP头中包含多少个 4字节

- 保留：置0

- **ACK**：期望收到的数据的开始序列号。也即已经收到的数据的字节长度加1

- PSH：表示是带有PUSH标志的数据。接收方因此请求数据报一到便可送往应用程序而不必等到缓冲区装满时才传送。

- **RST**：用于复位由于主机崩溃或其它原因而出现的错误的连接。还可以用于拒绝非法的数据报或拒绝连接请求。

- **SYN**：用于建立连接。

- **FIN**：用于释放连接。

- **窗口大小（WIN）**：16位长。表示从确认号开始，本报文的发送方（数据发送端 or 数据接收端）可以接收的字节数，即接收窗口大小。用于流量控制。

- **校验和（Checksum）**：16位长。是为了确保高可靠性而设置的。它校验头部、数据和伪TCP头部之和。

- 紧急指针：`URG=1`时才有意义。

- 可选项：长度可变，最长40个字节。每个选项的开始是 1 字节的 kind 字段，说明选项的类型。

  - 0：选项表结束（1字节）

  - 1：无操作（1字节）用于选项字段之间的字边界对齐

  - 2：**MMS** 最大报文段长度，通常在创建连接而设置 SYN 标志的数据包中指明这个选项，指明本端所能接收的最大长度的报文段。通常将 MSS 设置为（MTU-40）字节，携带 TCP 报文段的 IP 数据报的长度就不会超过 MTU（MTU最大长度为1518字节，最短为64字节），从而避免本机发生IP分片。只能出现在同步报文段中，否则将被忽略。

  - 3：**窗口扩大因子（4字节，wscale）**，取值 0-14 。用来把 TCP 的窗口的值左移的位数，使窗口值乘倍。只能出现在同步报文段中，否则将被忽略。

  - 4：**sackOK** 发送端支持并同意使用SACK选项。

  - 5：**SACK** 选择确认选项

  - 8：

    时间戳

     

    计算 RTT；用于处理TCP序号超过

     

    2^32232 

    的情况，又称为防止序号回绕（PAWS）。

    - 发送端的时间戳（Timestamp）
    - 时间戳回显应答（Timestamp Echo）

> TCP最小长度为 20 个字节。

### 三次握手  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/tcp_handshake.png)

- 第一次握手：建立连接时，客户端发送 SYN 包（seq=j）到服务器，并进入`SYN_SENT`状态，等待服务器确认。
- 第二次握手：服务器收到 SYN 包，必须确认客户的 SYN（ack=j+1），同时自己也发送一个 SYN 包（seq=k），即 SYN + ACK 包，此时服务器进入 `SYN_RECV` 状态；
- 第三次握手：客户端收到服务器的 SYN+ACK 包，向服务器发送确认包 ACK（ack=k+1），此包发送完毕，客户端和服务器进入`ESTABLISHED`（TCP连接成功）状态，完成三次握手。

TCP 连接使用三次握手的首要原因：为了 **阻止历史的重复连接初始化造成的混乱问题**。如果通信双方的通信次数只有两次，那么发送方一旦发出建立连接的请求之后它就没有办法撤回这一次请求，如果在网络状况复杂或者较差的网络中，发送方连续发送多次建立连接的请求，如果 TCP 建立连接只能通信两次，那么接收方只能选择接受或者拒绝发送方发起的请求，它并不清楚这一次请求是不是由于网络拥堵而早早过期的连接。

所以，TCP 选择使用三次握手来建立连接并在连接引入了 RST 这一控制消息，接收方当收到请求时会将发送方发来的 SEQ+1 发送给对方，这时由发送方来判断当前连接是否是历史连接：

- 如果当前连接是历史连接，即 SEQ 过期或者超时，那么发送方就会直接发送 RST 控制消息中止这一次连接；
- 如果当前连接不是历史连接，那么发送方就会发送 ACK 控制消息，通信双方就会成功建立连接；

使用三次握手和 RST 控制消息将是否建立连接的最终控制权交给了发送方，因为只有发送方有足够的上下文来判断当前连接是否是错误的或者过期的，这也是 TCP 使用三次握手建立连接的最主要原因。

#### 内核对 TCP 的处理  

Socket 是一个由 （源IP、源Port、目标IP、目标Port、协议） 组成的五元组，唯一标示一个 socket 连接。

TCP 建立连接的整体流程：

1. 服务器端在调用 `listen` 之后，内核会建立两个队列，`SYN`队列和`ACCEPT`队列，其中`ACCPET`队列的长度由`backlog`指定。
2. 服务器端在调用 `accpet` 之后，将阻塞，等待 `ACCPT` 队列有元素。
3. 客户端在调用 `connect` 之后，将开始发起 `SYN` 请求，请求与服务器建立连接，此时称为第一次握手。
4. 服务器端在接受到 `SYN` 请求之后，把请求方放入 `SYN` 队列中，并给客户端回复一个确认帧 `ACK` ，此帧还会携带一个请求与客户端建立连接的请求标志，也就是 `SYN` ，这称为第二次握手
5. 客户端收到 `SYN+ACK` 帧后， `connect` 返回，并发送确认建立连接帧 `ACK` 给服务器端。这称为第三次握手
6. 服务器端收到 `ACK` 帧后，会把请求方从 `SYN` 队列中移出，放至 `ACCEPT` 队列中，而 `accept` 函数也等到了自己的资源，从阻塞中唤醒，从 `ACCEPT` 队列中取出请求方，重新建立一个新的 `sockfd` ，并返回。

在服务端如何分发多个连接的请求？

由于 `TCP/IP` 协议栈是维护着一个接收和发送缓冲区的。在接收到来自客户端的数据包后，服务器端的 `TCP/IP` 协议栈应该会做如下处理：

1. 如果收到的是请求连接的数据包，则传给监听着连接请求端口的 `socetfd` 套接字。
2. 如果是已经建立过连接后的客户端数据包，则将数据放入接收缓冲区。这样，当服务器端需要读取指定客户端的数据时，则可以利用 `socketfd_new` 套接字通过 `recv` 或者 `read` 函数到缓冲区里面去取指定的数据（因为 `socketfd_new` 代表的 `socket` 对象记录了客户端IP和端口，因此可以鉴别）。

数据包如何找到相对应的 socket ，这个方法在 Linux Kernel 代码里也是有体现的：

```cpp
static inline struct sock *__inet_lookup(struct net *net,
                     struct inet_hashinfo *hashinfo,
                     const __be32 saddr, const __be16 sport,
                     const __be32 daddr, const __be16 dport,
                     const int dif)
{
    u16 hnum = ntohs(dport);
    /* 先尝试查找处于连接成功的 socket */
    struct sock *sk = __inet_lookup_established(net, hashinfo,
                saddr, sport, daddr, hnum, dif);
     /* 如果没有找到连接成功的socket，那么就去处于 listen 状态的 socket 查找 */
    return sk ? : __inet_lookup_listener(net, hashinfo, daddr, hnum, dif);
}
```

### 四次挥手  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/tcp_finish.jpg)

由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。

- 客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送（报文段4）。
- 服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1（报文段5）。和SYN一样，一个FIN将占用一个序号。
- 服务器B关闭与客户端A的连接，发送一个FIN给客户端A（报文段6）。
- 客户端A发回ACK报文确认，并将确认序号设置为收到序号加1（报文段7）

对于复杂的网络状态，TCP 的实现提出了多种应对措施， `TIME_WAIT` 状态的提出就是为了应对其中一种异常状况。在 `TIME_WAIT` 阶段，主动端等待 2*MSL（**最大分段寿命**：表示一个 TCP 分段可以存在于互联网系统中的最大时间，由 TCP 的实现，超出这个寿命的分片都会被丢弃） 时间， MSL 建议为 2 分钟。

如果没有 `TIME_WAIT` 状态，Client 不再保存这个连接的信息，收到一个不存在的连接的包，Client 会响应 `RST` 包，导致 Server 端异常响应。此时， `TIME_WAIT` 是为了 **保证全双工的 TCP 连接正常终止**。

如果双方挥手之后，一个 网络四元组（src/dst ip/port）被回收，而此时网络中还有一个迟到的数据包没有被 Server 接收，Client 应用程序又立刻使用了同样的四元组再创建了一个新的连接后，这个迟到的数据包才到达 Server，那么这个数据包就会让 Server 以为是 Client 刚发过来的。此时， `TIME_WAIT` 的存在是为了 **保证网络中迷失的数据包正常过期**。

> TCP采用四次挥手关闭连接如图所示为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？
>
> 这是因为服务端的 LISTEN 状态下的 SOCKET 当收到 SYN 报文的建连请求后，它可以把 ACK 和 SYN （ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。

### 数据传输  

#### 可靠传输  

通常在每个 TCP 报文段中都有一对序号和确认号。TCP报文发送者称自己的字节流的编号为 **序号** （sequence number），称接收到对方的字节流编号为 **确认号** 。TCP 报文的接收者为了确保可靠性，在接收到一定数量的连续字节流后才发送确认。这是对 TCP 的一种扩展，称为选择确认（Selective Acknowledgement）。选择确认使得 TCP 接收者可以对乱序到达的数据块进行确认。**每一个字节传输过后，SN号都会递增1**。

通过使用序号和确认号，TCP 层可以把收到的报文段中的字节按正确的顺序交付给应用层。序号是 32 位的无符号数，在它增大到 2^{32}-1232−1 时，便会回绕到 0。对于初始化序列号(ISN)的选择是 TCP 中关键的一个操作，它可以确保强壮性和安全性。

TCP 协议使用序号标识每端发出的字节的顺序，从而另一端接收数据时可以重建顺序，无惧传输时的包的乱序交付或丢包。在发送第一个包时（SYN包），选择一个 **随机数** 作为序号的初值，以克制 TCP 序号预测攻击。

发送确认包（Acks），携带了接收到的对方发来的字节流的编号，称为确认号，以告诉对方 **已经成功接收的数据流的字节位置**。Ack并不意味着数据已经交付了上层应用程序。可靠性通过发送方检测到丢失的传输数据并重传这些数据。包括 **超时重传**（Retransmission timeout，RTO）与 **重复累计确认** （duplicate cumulative acknowledgements，DupAcks）。

#### 重复累计确认重传  

如果一个包（不妨设它的序号是 100 ，即该包始于第 100 字节）丢失，接收方就不能确认这个包及其以后的包，因为采用了 **累计ACK** 。接收方在收到 100 以后的包时，发出对包含第 99 字节的包的确认。这种重复确认是包丢失的信号。**发送方如果收到 3 次对同一个包的确认，就重传最后一个未被确认的包**。阈值设为 3 被证实可以减少乱序包导致的无作用的重传（spurious retransmission）现象。**选择性确认（SACK）**的使用能明确反馈哪个包收到了，极大改善了TCP重传必要的包的能力。

##### 超时重传  

发送方使用一个保守估计的时间作为收到数据包的确认的超时上限。如果超过这个上限仍未收到确认包，发送方将重传这个数据包。每当发送方收到确认包后，会重置这个重传定时器。典型地，定时器的值设定为 {\text{smoothed RTT}}+\max(G,4\times {\text{RTT variation}})smoothed RTT+max(*G*,4×RTT variation) 其中 G*G* 是时钟粒度。进一步，如果重传定时器被触发，仍然没有收到确认包，定时器的值将被设为前次值的二倍（直到特定阈值）。这可对抗 中间人攻击方式的拒绝服务攻击，这种攻击愚弄发送者重传很多次导致接受者被压垮。

##### 数据传输举例  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2020-02-14-20-03-25.png)

1. 发送方首先发送第一个包含序列号为1（可变化）和 1460 字节数据的 TCP 报文段给接收方。接收方以一个没有数据的 TCP 报文段来回复（只含报头），用确认号 1461 来表示已完全收到并请求下一个报文段。
2. 发送方然后发送第二个包含序列号为 1461 ，长度为 1460 字节的数据的 TCP 报文段给接收方。正常情况下，接收方以一个没有数据的 TCP 报文段来回复，用确认号 2921（1461+1460）来表示已完全收到并请求下一个报文段。发送接收这样继续下去。
3. **然而当这些数据包都是相连的情况下，接收方没有必要每一次都回应**。比如，他收到第 1 到 5 条TCP报文段，只需回应第五条就行了。在例子中第3条TCP报文段被丢失了，所以尽管他收到了第 4 和 5 条，然而他只能回应第 2 条。
4. 发送方在发送了第三条以后，没能收到回应，因此当时钟（timer）过时（expire）时，他重发第三条。（每次发送者发送一条TCP报文段后，都会再次启动一次时钟：RTT）。
5. 这次第三条被成功接收，接收方可以直接确认第5条，因为4，5两条已收到。

#### 流量控制  

流量控制用来避免主机分组发送得过快而使接收方来不及完全收下，一般由接收方通告给发送方进行调控，这里的窗口被称为 **接收通知窗口（Receiver’s Advertised Window）**。

流量控制通过 **滑动窗口机制** 来实现： **报文发送方** 在 **WIN** 域指出还可接收的字节数量（rwnd）。报文接收方在没有新的确认包的情况下至多发送 WIN 允许的字节数量。在数据传输过程中，报文发送方可修改 WIN 的值。

> 报文发送方：即可以是握手的发起方（客户端），也可以是握手的被动接收方（服务端）

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/flow_control_win.png)

1. 报文段 2 中提供的窗口大小为 6144 字节；
2. 由于这是一个较大的窗口，因此发送端立即连续发送了6个报文段（4~9），停止；
3. 报文段 10 确认了所有的数据（从第 1 到 6144 字节），但提供的窗口大小却为 2048，这很可能是接收程序不能读取多于 2048 字节的数据；
4. 报文段 11 和 12 完成了客户的数据传输，且最后一个报文段带有 FIN 标志；
5. 报文段 13 包含与报文段 10 相同的确认序号，但通告了一个更大的窗口大小；
6. 报文段 14 确认了最后的 2048 字节的数据和 FIN ；
7. 报文段 15 和 16 仅用于通告一个更大的窗口大小；
8. 报文段 17 和 18 完成通常的关闭过程；

当接收方宣布接收窗口的值为 0，发送方停止进一步发送数据，开始了 **保持定时器（persist timer）**，以 **避免因随后的修改接收窗口的数据包丢失使连接的双侧进入死锁** ，发送方无法发出数据直至收到接收方修改窗口的指示。当定时器到期时， TCP 发送方尝试恢复发送一个小的 **ZWP 包（Zero Window Probe）**，期待接收方回复一个带着新的接收窗口大小的确认包。一般 ZWP 包会设置成 3 次，如果 3 次过后还是 0 的话，有的 TCP 实现就会发 RST 把链接断了。

#### 拥塞控制  

TCP 拥塞控制算法是互联网上主要的拥塞控制措施，它使用一套基于 **线増积减**（Additive increase/multiplicative decrease，AIMD）的网络拥塞控制方法来控制拥塞，**防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载**。

除了 **拥塞窗口大小（cwnd）** 之外，TCP 连接的双方都有 **接收窗口大小（rwnd）**。客户端能够同时传输的最大数据段的数量是接收窗口大小和拥塞窗口大小的最小值，即 min(rwnd, cwnd)*m**i**n*(*r**w**n**d*,*c**w**n**d*) 。

TCP 协议使用慢启动阈值（Slow start threshold, ssthresh）来决定使用慢启动或者拥塞避免算法：

- 当拥塞窗口大小小于慢启动阈值时，使用慢启动；
- 当拥塞窗口大小大于慢启动阈值时，使用拥塞避免算法；
- 当拥塞窗口大小等于慢启动阈值时，使用慢启动或者拥塞避免算法；

##### 慢开始和拥塞避免  

客户端维持一个 **拥塞窗口 `cwnd`** 的状态变量，初始值一般为 2\times MSS2×*M**S**S* 。

- `慢开始`：**由小到大的指数增大拥塞窗口**。首先将 cwnd 设置为一个最大报文段 MMS ，在收到一个对新的报文段的确认后，把拥塞窗口增加一个 MMS 。
- `拥塞避免`：当慢开始到阈值（ssthresh）后，使用拥塞避免算法（ cwnd 每次加1 ）。当发送方发送的数据包丢包时，将 ssthresh 置为 cwnd 的一半，将 cwnd 置为1，再次执行慢开始。

##### 快重传和快恢复  

**快速重传和恢复（fast retransmit and recovery，FRR）** 是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了FRR，如果接收机接收到一个不按顺序的数据段，它会立即给客户端发送一个重复确认。如果客户端接收到三个重复确认，它会认定数据段丢失，并立即重传这些丢失的数据段。

有了 FRR，就不会因为重传时要求的暂停被耽误。当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。

##### BBR  

BBR（Bottleneck Bandwidth and Round-trip propagation time）是 Google 研发的新的拥塞控制算法。自从 20 世纪 80年代后， TCP 中的拥塞控制算法都使用的是 **基于丢包的拥塞控制**（拥塞避免），在之前的网络带宽、路由器 Buffer 的情况下，该算法效果良好。

但是在当前的网络条件下，基于丢包的拥塞控制算法则会导致 TCP 性能问题：

- 在小 Buffer 路由器环境下，丢包发生在拥塞之前。在高速，长途链路中，基于丢包的拥塞控制会导致吞吐量过低，因为它反应过度，即使丢包是由瞬时流量突发引起的，也会因丢包而将发送速率减半（即使链路大部分处于空闲状态，这种丢包也可能非常频繁）
- 在大 Buffer 路由器环境下，拥塞发生在丢包之前。在互联网的边缘，基于丢包的拥塞控制通过反复填充大量的缓存，从而导致了臭名昭著的 **bufferbloat** 问题。

> bufferbloat 问题：由于路由器的大缓存，减少链路丢包。再加上网络中 TCP 大量使用基于丢包的拥塞控制算法（丢包才触发速度下调，但是要丢包，缓存就得先被填满，缓存都填满，延迟更高）

BBR 算法使用最大带宽和往返时间来建立网络的显式模型。每次对包传递进行累积或选择性确认，都会生成一个速率样本，该速率采样记录在数据包传输与该包确认之间的时间间隔内传递的数据量，从而使拥塞控制算法能够提供更高的吞吐量和更低的延迟。

## 最大分段大小  

**最大分段大小 (MSS)** 是在单个分段中 TCP 愿意接受的数据的字节数最大值。MSS应当足够小以避免IP分片，它会导致丢包或过多的重传。

**在 TCP 连接创建时，双端在 SYN 报文中用 MSS 选项宣布各自的 MSS ，这是从双端各自直接相连的数据链路层的最大传输单元(MTU)的尺寸减去固定的 IP 首部和 TCP 首部长度**。以太网MTU为 1500 字节， MSS值可达 1460 字节。使用 IEEE 802.3 的 MTU 为 1492 字节，MSS 可达 1452 字节。

如果目的IP地址为“非本地的”，MSS通常的默认值为 536（这个默认值允许 20 字节的 IP 首部和 20 字节的 TCP 首部以适合 576字节 IP 数据报）。此外，发送方可用传输路径 MTU 发现（RFC 1191）推导出从发送方到接收方的网络路径上的最小 MTU，以此动态调整 MSS 以避免网络 IP 分片。

MSS 发布也被称作“MSS协商”（MSS negotiation）。严格讲，这并非是协商出来一个统一的MSS值，TCP 允许连接两端使用各自不同的MSS值。例如，这会发生在参与 TCP 连接的一台设备使用非常少的内存处理到来的 TCP 分组。

### 选择确认  

**最初采取累计确认的 TCP 协议在丢包时效率很低**。例如，假设通过10个分组发出了1万个字节的数据。如果第一个分组丢失，在纯粹的累计确认协议下，接收方不能说它成功收到了 1,000 到 9,999 字节，但未收到包含 0 到 999 字节的第一个分组。因而，发送方可能必须重传所有1万个字节。

为此，TCP采取了 **选择确认（selective acknowledgment，SACK）** 选项。RFC 2018 对此定义为 **允许接收方确认它成功收到的分组的不连续的块**，以及基础 TCP 确认的成功收到最后连续字节序号。这种确认可以指出 SACK block，包含了已经成功收到的连续范围的开始与结束字节序号。在上述例子中，接收方可以发出 SACK 指出序号 1000 到 9999 ，发送方因此知道只需重发第一个分组(字节 0 到 999)。

TCP 发送方会把乱序收包当作丢包，因此会重传乱序收到的包，导致连接的性能下降。重复SACK选项（duplicate-SACK option）是定义在RFC 2883中的SACK的一项扩展，可解决这一问题。接收方发出 D-SACK 指出没有丢包，接收方恢复到高传输率。 D-SACK 使用了 SACK 的第一个段来做标志：

- 如果 SACK 的第一个段的范围被 ACK 所覆盖，那么就是 D-SACK;
- 如果 SACK 的第一个段的范围被 SACK 的第二个段覆盖，那么就是 D-SACK

> D-SACK旨在告诉发送端：收到了重复的数据，数据包没有丢，丢的是ACK包；

SACK 选项并不是强制的。仅当双端都支持时才会被使用。 TCP 连接创建时会在 TCP 头中协商 SACK 细节。在 Linux下，可以通过 `tcp_sack` 参数打开 SACK 功能（Linux 2.4后默认打开）。Linux下的 `tcp_dsack` 参数用于开启D-SACK功能（Linux 2.4后默认打开）。选择确认也用于流控制传输协议 (SCTP)。



## IP  

### 地址分类  

- A类：**8位网络号**，`0_ _ _ _ _ _ _`，1.0.0.0 ~ 126.0.0.0
- B类：**16位网络号**，`10 _ _ ...`，128.0.0.0 ~ 191.255.255.255
- C类：**24位网络号**，`110_ _ _...`，192.0.0.0 ~ 223.255.255.255
- D类：**多播地址**，`1110_ _ _...`
- E类：**保留地址**，`1111_ _ _ ...`

### 私有地址  

- A类:`10.0.0.0 ~ 10.255.255.255`(长度相当于1个A类IP地址)
- B类:`172.16.0.0 ~ 172.31.255.255`(长度相当于16个连续的B类IP地址)
- C类:`192.168.0.0 ~ 192.168.255.255`(长度相当于256个连续的C类IP地址)

### 特殊的IP地址  

- `0.0.0.0`：已经不是一个真正意义上的IP地址。它表示的是这样一个集合：**所有不清楚的主机和目的网络。这里的“不清楚”是指在本机的路由表里没有特定条目指明如何到达**。如果在网络设置中设置了缺省网关,那么系统会自动产生一个目的地址为0.0.0.0的缺省路由.对本机来说,它就是一个“收容所”,所有不认识的“三无”人员,一 律送进去。
- `255.255.255.255`： 限制广播地址，对本机来说,这个地址指本网段内(同一广播域)的所有主机。**这个地址不能被路由器转发**。
- `127.0.0.1`：本机地址主要用于测试。这样一个地址,是不能把它发到网络接口的。



## HTTP  

- HTTP构建于`TCP/IP`协议之上，默认端口号是80。
- HTTP是 **无连接无状态** 的。

无连接的含义是 **限制每次连接只处理一个请求**。服务器处理完客户的请求，并收到客户的应答后，即断开连接。后来使用了`Keep-Alive`技术。

无状态是指 **协议对于事务处理没有记忆能力，服务器不知道客户端是什么状态**。即我们给服务器发送 HTTP 请求之后，服务器根据请求，会给我们发送数据过来，但是，发送完，不会记录任何信息。

HTTP 协议这种特性有优点也有缺点，优点在于解放了服务器，每一次请求“点到为止”不会造成不必要连接占用，**缺点在于每次请求会传输大量重复的内容信息**。

为了解决HTTP无状态的缺点，两种用于保持 HTTP 连接状态的技术就应运而生了，一个是 `Cookie`，而另一个则是 `Session`。`Cookie`在客户端记录状态，比如登录状态。`Session`在服务器记录状态。

### Http的报文结构  

#### HTTP 请求报文头部  

- `User-Agent`：产生请求的浏览器类型。
- `Accept`：客户端可识别的响应内容类型列表;
- `Accept-Language`：客户端可接受的自然语言;
- `Accept-Encoding`：客户端可接受的编码压缩格式;
- `Accept-Charset`：可接受的应答的字符集;
- `Host`：请求的主机名，允许多个域名同处一个IP 地址，即虚拟主机;（必选）
- `Connection`：连接方式(close 或 `keep-alive`);
- `Cookie`：存储于客户端扩展字段，向同一域名的服务端发送属于该域的cookie;
- `请求包体`：在`POST`方法中使用。
- `Referer`：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。
- `If-Modified-Since`：文档的最后改动时间

#### HTTP 响应头  

- `Allow`	服务器支持哪些请求方法（如GET、POST等）。
- `Content-Encoding`	文档的编码（Encode）方法。
- `Content-Length`	表示内容长度。只有当浏览器使用持久HTTP连接时才需要这个数据。
- `Content-Type`	表示后面的文档属于什么MIME类型。
- `Date`	当前的GMT时间。你可以用setDateHeader来设置这个头以避免转换时间格式的麻烦。
- `Expires`	应该在什么时候认为文档已经过期，从而不再缓存它。
- `Last-Modified`	文档的最后改动时间。
- `Refresh`	表示浏览器应该在多少时间之后刷新文档，以秒计。
- `Server`	服务器名字。
- `Set-Cookie`	设置和页面关联的Cookie。
- `ETag`：被请求变量的实体值。ETag是一个可以与Web资源关联的记号（MD5值）。
- `Cache-Control`：这个字段用于指定所有缓存机制在整个请求/响应链中必须服从的指令。

> max-age：表示当访问此网页后的 x 秒内再次访问不会去服务器；no-cache，实际上Cache-Control: no-cache是会被缓存的，只不过每次在向客户端（浏览器）提供响应数据时，缓存都要向服务器评估缓存响应的有效性；no-store，这个才是响应不被缓存的意思；

> `Last-Modified`与`If-Modified-Since`都是用来记录页面的最后修改时间。当客户端访问页面时，服务器会将页面最后修改时间通过 Last-Modified 标识由服务器发往客户端，客户端记录修改时间，再次请求本地存在的cache页面时，客户端会通过 If-Modified-Since 头将先前服务器端发过来的最后修改时间戳发送回去，服务器端通过这个时间戳判断客户端的页面是否是最新的，如果不是最新的，则返回新的内容，如果是最新的，则返回 304。

### Http的状态码含义。  

- `1**`	信息，服务器收到请求，需要请求者继续执行操作

- `2**`	成功，操作被成功接收并处理

- `3**`    重定向，需要进一步的操作以完成请求
  - `301 Moved Permanently`。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替
  - `302 Moved Temporarily`。与301类似。但资源只是临时被移动。客户端应继续使用原有URI
  - `304 Not Modified`。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。**客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源**。
  
- `4**`     客户端错误，请求包含语法错误或无法完成请求
  - `400 Bad Request` 由于客户端请求有语法错误，不能被服务器所理解。
  - `401 Unauthorized` 请求未经授权。这个状态代码必须和WWW-Authenticate报头域一起使用
  - `403 Forbidden` 服务器收到请求，但是拒绝提供服务。服务器通常会在响应正文中给出不提供服务的原因
  - `404 Not Found` 请求的资源不存在，例如，输入了错误的URL

- `5**`    服务器错误，服务器在处理请求的过程中发生了错误
  - `500 Internal Server Error` 服务器发生不可预期的错误，导致无法完成客户端的请求。
  - `503 Service Unavailable` 服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常。

### Http request的几种类型。  

- `GET`	请求指定的页面信息，并返回实体主体。
- `POST`	向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。
- `PUT`	从客户端向服务器传送的数据取代指定的文档的内容。
- `DELETE`	请求服务器删除指定的页面。

> GET可提交的数据量受到URL长度的限制，HTTP协议规范没有对URL长度进行限制。这个限制是特定的浏览器及服务器对它的限制

> 理论上讲，POST是没有大小限制的，HTTP协议规范也没有进行大小限制，出于安全考虑，服务器软件在实现时会做一定限制

### 条件 GET  

HTTP条件GET 是 `HTTP` 协议为了减少不必要的带宽浪费，提出的一种方案。实际上就是利用`If-Modified-Since`做浏览器缓存。

### 持久连接  

我们知道 HTTP 协议采用`请求-应答`模式，当使用普通模式，即非 Keep-Alive 模式时，每个请求/应答客户和服务器都要新建一个连接，完成之后立即断开连接（HTTP协议为无连接的协议）；当使用 `Keep-Alive 模式`（又称持久连接、连接重用）时，`Keep-Alive` 功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，`Keep-Alive` 功能避免了建立或者重新建立连接。

在 HTTP 1.0 中, 没有官方的 `keep alive` 的操作。通常是在现有协议上添加一个指数。如果浏览器支持 keep-alive，它会在请求的包头中添加：

```
Connection: Keep-Alive
```

然后当服务器收到请求，作出回应的时候，它也添加一个头在响应中：

```
Connection: Keep-Alive
```

这样做，连接就不会中断（超过 Keep-Alive 规定的时间–服务器设置，意外断电等情况除外），而是保持连接。当客户端发送另一个请求时，它会使用同一个连接。这一直继续到客户端或服务器端认为会话已经结束，其中一方中断连接。

在 HTTP 1.1 版本中，默认情况下所有连接都被保持，如果加入 “Connection: close” 才关闭。

> HTTP Keep-Alive 简单说就是保持当前的TCP连接，避免了重新建立连接。

> **HTTP 长连接不可能一直保持，例如 Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100，表示这个长连接最多接收100次请求就断开**。

> HTTP是一个无状态协议，这意味着每个请求都是独立的，Keep-Alive没能改变这个结果。另外，**Keep-Alive也不能保证客户端和服务器之间的连接一定是活跃的**，在HTTP1.1版本中也如此。唯一能保证的就是当连接被关闭时你能得到一个通知，所以不应该让程序依赖于Keep-Alive的保持连接特性，否则会有意想不到的后果。

> 使用长连接之后，客户端、服务端怎么知道本次传输结束呢？两部分：1. 判断传输数据是否达到了Content-Length 指示的大小；2. 动态生成的文件没有 Content-Length ，它是分块传输（chunked），这时候就要根据 chunked 编码来判断，chunked 编码的数据在最后有一个空 chunked 块，表明本次传输数据结束。

### 跨站攻击  

CSRF（Cross-site request forgery，跨站请求伪造）伪造请求，冒充用户在站内的正常操作，比如爬虫。

#### 防范的方法  

- 关键操作只接受POST请求
- 验证码
- 检测 Referer
- Token
  - Token 要足够随机——只有这样才算不可预测
  - Token 是一次性的，即每次请求成功后要更新Token——这样可以增加攻击难度，增加预测难度
  - Token 要注意保密性——敏感操作使用 post，防止 Token 出现在 URL 中

### 断点续传  

要实现断点续传的功能，通常都需要客户端记录下当前的下载进度，并在需要续传的时候通知服务端本次需要下载的内容片段。

HTTP1.1协议中定义了断点续传相关的HTTP头 `Range` 和 `Content-Range` 字段，一个最简单的断点续传实现大概如下：

1. 客户端下载一个1024K的文件，已经下载了其中512K
2. 网络中断，客户端请求续传，因此需要在HTTP头中申明本次需要续传的片段：`Range:bytes=512000-`，这个头通知服务端从文件的512K位置开始传输文件。
3. 服务端收到断点续传请求，从文件的512K位置开始传输，并且在HTTP头中增加：`Content-Range:bytes 512000-/1024000`，并且此时服务端返回的HTTP状态码应该是`206`，而不是200。

但是在实际场景中，会出现一种情况，即在终端发起续传请求时，URL对应的文件内容在服务端已经发生变化，此时续传的数据肯定是错误的。如何解决这个问题了？显然此时我们需要有一个标识文件唯一性的方法。在RFC2616中也有相应的定义，比如 **实现Last-Modified来标识文件的最后修改时间，这样即可判断出续传文件时是否已经发生过改动**。同时RFC2616中还定义有一个ETag的头，可以使用ETag头来放置文件的唯一标识，比如文件的MD5值。

客户端在发起续传请求时应该在HTTP头中申明`If-Match` 或者 `If-Modified-Since` 字段，帮助服务端判别文件变化。

### 一次HTTP请求  

1. 域名解析
   1. 浏览器缓存
   2. 系统缓存
   3. hosts
   4. ISP DNS 缓存
   5. DNS 服务器搜索
2. 浏览器发送 HTTP 请求到目标服务器
3. 服务器永久重定向
4. 浏览器跟踪重定向地址
5. 服务器“处理”请求
6. 服务器发回一个HTML响应
7. 浏览器开始显示HTML
8. 浏览器请求获取嵌入在 HTML 中的对象（图片&脚本等）
9. 浏览器发送异步（AJAX）请求



## HTTPS

`HTTPS` 是一种通过计算机网络进行安全通信的传输协议。HTTPS经由HTTP进行通信，但利用 `SSL/TLS` 来加密数据包。 `HTTPS` 开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。

`HTTPS` 的主要思想是在不安全的网络上创建一安全信道，并可在使用适当的加密包和服务器证书可被验证且可被信任时，对窃听和中间人攻击提供合理的防护。HTTPS的信任继承基于预先安装在浏览器中的证书颁发机构（如`Symantec、Comodo、GoDaddy和GlobalSign`等）（意即“我信任证书颁发机构告诉我应该信任的”）

### HTTP 为什么不安全  

`http` 协议属于 **明文传输协议** ，交互过程以及数据传输都没有进行加密，通信双方也没有进行任何认证，通信过程非常容易遭遇劫持、监听、篡改，严重情况下，会造成恶意的流量劫持等问题，甚至造成个人隐私泄露（比如银行卡卡号和密码泄露）等严重的安全问题。

比如常见的，在 `http` 通信过程中，“中间人”将广告链接嵌入到服务器发给用户的 `http` 报文里，导致用户界面出现很多不良链接； 或者是修改用户的请求头 `URL` ，导致用户的请求被劫持到另外一个网站，用户的请求永远到不了真正的服务器。这些都会导致用户得不到正确的服务，甚至是损失惨重。

### HTTPS 如何保证安全  

#### 数字证书  

TLS 握手的作用之一是 身份认证（authentication） ，被验证的一方需要提供一个身份证明，在 HTTPS 的世界里，这个身份证明就是 `TLS 证书` ，或者称为 `HTTPS 证书`。

世界上的 CA 机构会遵守 `X.509` 规范来签发公钥证书（Public Key Certificate），证书内容的语法格式遵守 `ASN.1`，证书大致包含如下内容：

```ASN.1
Certificate:
    Data:
        Version: 3 (0x2)                                                              //版本号
        Serial Number:                                                                //证书序列号
            0e:3c:c1:49:94:b3:e1:74:a6:34:54:d9:90:64:66:d7
    Signature Algorithm: sha256WithRSAEncryption                                      //签名算法
        Issuer: C=US, O=DigiCert Inc, OU=www.digicert.com, CN=GeoTrust RSA CA 2018    //签发机构
        Validity                                                                      //有效期
            Not Before: Dec 25 00:00:00 2017 GMT
            Not After : Dec 24 12:00:00 2020 GMT
        Subject: C=CN, L=北京市, O=智者四海（北京）技术有限公司, OU=IT, CN=*.zhihu.com      //证书主体
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption                                       //公钥算法
                Public-Key: (2048 bit)
                Modulus:
                    00:a0:a8:71:...                                                   //公钥
                Exponent: 65537 (0x10001)
        X509v3 extensions:                                                            //扩展信息
            X509v3 Authority Key Identifier: 
                keyid:90:58:FF:B0:9C:75:A8:51:54:77:B1:ED:F2:A3:43:16:38:9E:6C:C5     //授权密钥标识
            X509v3 Subject Key Identifier: 
                31:63:1F:A1:0B:43:D7:A5:8C:3D:F6:2E:85:69:D4:E1:E3:56:91:46           //主体密钥标识
            X509v3 Subject Alternative Name: 
                DNS:*.zhihu.com, DNS:zhihu.com
            X509v3 Key Usage: critical
                Digital Signature, Key Encipherment
            X509v3 Extended Key Usage: 
                TLS Web Server Authentication, TLS Web Client Authentication
            X509v3 CRL Distribution Points: 
                Full Name:
                  URI:http://cdp.geotrust.com/GeoTrustRSACA2018.crl

            X509v3 Certificate Policies: 
                Policy: 2.16.840.1.114412.1.1
                  CPS: https://www.digicert.com/CPS
                Policy: 2.23.140.1.2.2

            Authority Information Access: 
                OCSP - URI:http://status.geotrust.com
                CA Issuers - URI:http://cacerts.geotrust.com/GeoTrustRSACA2018.crt

            X509v3 Basic Constraints: 
                CA:FALSE
    Signature Algorithm: sha256WithRSAEncryption                                      //签名算法
         54:73:e6:02:...                                                              //数字签名
```

同一个CA颁发的证书序列号都必须是唯一的。

#### 证书链  

证书链是从终端用户证书后跟着一系列的 CA 证书，例如：`CA_ZHIHU` -> `CA_GEO` -> `CA_ROOT`，而通常 **最后一个是自签名证书（根证书）**，并且有如下关系：

> A -> B 表示 “A是由B签发的” （更确切地说，A是由B中所载公钥对应的私钥签署的）

- 在证书链上除根证书外，证书颁发者等于其后一个证书的主题。即：`CA_ZHIHU`.`Authority Key Identifier`=`CA_GEO`.`Subject Key Identifier`
- 除了最后一个证书，每个证书都是由其后的一个证书签名的。即：`CA_ZHIHU` 由 `CA_GEO` 签名，`CA_GEO` 由 `CA_ROOT` 签名
- 最后的证书是信任主题，由于是通过可信过程得到的，你可以信任它，一般为系统内置。

证书链用于检查目标证书（证书链里的第一个证书）里的公钥及其它数据是否属于其主题。检查是这么做的，用证书链中的下一个证书的公钥来验证它的签名，一直检查到证书链的尾端，**如果所有验证都成功通过，那个这个证书就是可信的**。

#### 证书认证  

数字签名其实就是把 **散列值** 经过非对称加密算法加密得到的一个 **加密的散列值** 。数字签名一般用于身份认证和防止抵赖。

##### 根认证机构的构建  

1. 根认证机构 CA 生成公钥 `ca_KeyPub` 和私钥 `ca_KeyPri` ，以及基本信息表 `ca_Info`（CSR）。`ca_Info` 中一般包含了 CA 的名称、证书的有效期等信息。
2. 根认证机构 CA 对 `ca_KeyPub + ca_Info` 进行散列运算，得到散列值 `ca_Hash` 。
3. 根认证机构 CA 使用其私钥 `ca_KeyPri` 对 `ca_Hash` 进行非对称加密，得到加密的散列值 `enc_ca_Hash` 。
4. 根认证机构 CA 将 `ca_KeyPub + ca_Info + enc_ca_Hash` 组合生成自签名的数字证书 `ca_Cert` 。这张证书称之为根证书。

`ca_Cert` 可用于签署下一级的证书。

##### 二级（或以上）认证机构的构建  

1. 二级认证机构 CA2 生成公钥 `ca2_KeyPub` 和私钥 `ca2_KeyPri` ，以及基本信息表 `ca2_Info` 。 `ca2_Info` 中一般包含了 CA2 的名称、证书要求的有效期等信息。
2. 二级认证机构 CA2 将 `ca2_KeyPub` `、ca2_Info` 送给根认证机构 CA 。
3. 根认证机构 CA 通过某种方式验证 CA2 的身份之后，再加上根认证机构自己的一些信息 `ca_Info` ，然后对它们 `ca2_KeyPub + ca2_Info + ca_Info` 进行散列运算，得到散列值 `ca2_Hash` 。
4. 根认证机构 CA 使用其私钥 `ca_KeyPri` 对 `ca2_Hash` 进行非对称加密，得到加密的散列值 `enc_ca2_Hash` 。
5. 根认证机构 CA 将 `ca2_KeyPub + ca2_Info + ca_Info + enc_ca2_Hash` 组合签署成数字证书 `ca2_Cert` 并回送给 CA2 。

`ca2_Cert` 可用于签署下一级的证书。

##### 二级（或以上）认证机构的证书签署  

1. 服务器 S2 生成公钥 `s2_KeyPub` 和私钥 `s2_KeyPri` ，以及基本信息表 `s2_Info` 。 `s2_Info` 中一般包含了 S2 的名称、证书要求的有效期等信息。
2. 服务器 S2 将 `s2_KeyPub` 、 `s2_Info` 送给二级认证机构 CA2。
3. 二级认证机构 CA2 通过某种方式验证 S2 的身份之后，再加上根认证机构自己的一些信息 `ca2_Info` ，然后对它们 `s2_KeyPub + s2_Info + ca2_Info` 进行散列运算，得到散列值 `s2_Hash` 。
4. 二级认证机构 CA2 使用其私钥 `ca2_KeyPri` 对 `s2_Hash` 进行非对称加密，得到加密的散列值 `enc_s2_Hash` 。
5. 二级认证机构 CA2 将 `s2_KeyPub + s2_Info + ca2_Info + enc_s2_Hash` 组合签署成数字证书 `s2_Cert` 并回送给 S2 。

`s2_Cert` 不可用于签署下一级的证书。

> openssl ca 的 `-extensions` 参数控制，生成 `s2_Cert` 时是使用参数 `server_cert`生成，所以不具备签署的能力

从上面可以看出，证书签署的流程是： `ca_Cert -> ca2_Cert -> s2_Cert` 。它是一条完整的链条，我们把它称之为 **证书链** 。

##### 二级（或以上）认证机构的验证  

1. 服务器 S2 下发证书 `s2_Cert` 、 `ca2_Cert` （证书链）给客户端 C 。
2. 客户端 C 检查到 `s2_Cert` 中的 `ca2_Info` ，发现它是由 CA2 签署的。
3. 客户端 C 取出 `ca2_Cert` 中的 `ca2_KeyPub` ，对 `s2_Cert` 中的 `enc_s2_Hash` 进行解密得到 `s2_Hash` 。
4. 客户端 C 对 `s2_Cert` 中的 `s2_KeyPub + s2_Info + ca2_Info` 进行散列运算，得到散列值 `s2_Hash_tmp`。
5. 客户端 C 判断 `s2_Hash` 和 `s2_Hash_tmp` 是否相等。如果两者相等，则证明 `s2_Cert`是由 `ca2_Cert` 签署的。
6. 客户端 C 检查到 `ca2_Cert` 中的 `ca_Info` ，发现它是由 CA 签署的。
7. 客户端 C 取出 `ca_Cert` 中的 `ca_KeyPub` ，对 `ca2_Cert` 中的 `enc_ca2_Hash` 进行解密得到 `ca2_Hash` 。
8. 客户端 C 对 `ca2_Cert` 中的 `ca2_KeyPub + ca2_Info + ca_Info` 进行散列运算，得到散列值 `ca2_Hash_tmp` 。
9. 客户端 C 判断 `ca2_Hash` 和 `ca2_Hash_tmp` 是否相等。如果两者相等，证明 `ca2_Cert` 是由 `ca_Cert` 签署的。
10. 客户端 C 检查 `ca_Cert` ，发现该证书是根证书，且已经被系统信任，身份验证通过。

#### 无 SNI 支持问题  

很多公司由于业务众多，域名也是相当多的，为了方便运维，会让很多域名指向同样的 ip，然后统一将流量/请求分发到后端，此时就会面临一个问题：由于 `TLS/SSL` 在 HTTP 层之下，客户端和服务器握手的时候还拿不到 `origin` 字段，所以服务器不知道这个请求是从哪个域名过来的，而服务器这边每个域名都对应着一个证书，服务器就不知道该返回哪个证书啦。这个问题有两个通用解决方案：

1. 使用 **VIP 服务器**，每个域名对应一个 VIP，然后 VIP 与统一接入服务对接，通过 ip 来分发证书，不过运维成本很高，可能也需要大量的 VIP 服务器
2. 采用 **多泛域名**，将多个泛域名证书打包进一个证书。它的缺点是每次添加域名都需要更新证书。

#### 证书选择  

证书有多张加密方式，不同的加密方式对 CPU 计算的损耗不同，安全级别也不同。TLS 在进行第一次握手的时候，客户端会向服务器端 `say hello`，这个时候会告诉服务器，它支持哪些算法，此时 **服务器可以将最适合的证书发给客户端**。

#### 证书的吊销  

CA 证书的吊销存在两种机制，一种是 **在线检查（OCSP）**，客户端向 CA 机构发送请求检查公钥的靠谱性；第二种是客户端储存一份 CA 提供的 **证书吊销列表（CRL）**，定期更新。前者要求查询服务器具备良好性能，后者要求每次更新提供下次更新的时间，一般时差在几天。安全性要求高的网站建议采用第一种方案。

大部分 CA 并不会提供吊销机制（CRL/OCSP），靠谱的方案是 **为根证书提供中间证书**，一旦中间证书的私钥泄漏或者证书过期，可以直接吊销中间证书并给用户颁发新的证书。中间证书还可以产生下一级中间证书，多级证书可以减少根证书的管理负担。

#### SSL/TLS协议

不使用SSL/TLS的HTTP通信，就是不加密的通信。所有信息明文传播，带来了三大风险。

1. 窃听风险（eavesdropping）：第三方可以获知通信内容。
2. 篡改风险（tampering）：第三方可以修改通信内容。
3. 冒充风险（pretending）：第三方可以冒充他人身份参与通信。

SSL/TLS协议是为了解决这三大风险而设计的，希望达到：

1. 所有信息都是加密传播，第三方无法窃听。
2. 具有校验机制，一旦被篡改，通信双方会立刻发现。
3. 配备身份证书，防止身份被冒充。

目前，应用最广泛的是 `TLS 1.0`，接下来是`SSL 3.0`。但是，主流浏览器都已经实现了 `TLS 1.2` 的支持。`TLS 1.0`通常被标示为`SSL 3.1`，`TLS 1.1`为`SSL 3.2`，`TLS 1.2`为`SSL 3.3`。

#### TLS 运行过程  

`SSL/TLS`协议的基本思路是采用 **公钥加密法**，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。因此，`SSL/TLS`协议的基本过程是这样的：

1. 客户端向服务器端索要并验证公钥。
2. 双方协商生成"对话密钥”。
3. 双方采用"对话密钥"进行加密通信。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/44e2b283e89f3fbe81b280df04d2feeb.png)

“握手阶段"涉及四次通信，我们一个个来看。需要注意的是，**“握手阶段"的所有通信都是明文的**。

##### 客户端发出请求（ClientHello）  

首先，客户端（通常是浏览器）先向服务器发出加密通信的请求，这被叫做 `ClientHello`请求。

在这一步，客户端主要向服务器提供以下信息。

1. 支持的协议版本，比如TLS 1.0版。
2. 一个客户端生成的**随机数**，稍后用于生成对话密钥。
3. 支持的加密方法，比如RSA公钥加密。
4. 支持的压缩方法。

这里需要注意的是，客户端发送的信息之中不包括服务器的域名。也就是说，理论上服务器只能包含一个网站，否则会分不清应该向客户端提供哪一个网站的数字证书。这就是为什么通常一台服务器只能有一张数字证书的原因。

对于虚拟主机的用户来说，这当然很不方便。2006年，TLS协议加入了一个 *Server Name Indication* 扩展，允许客户端向服务器提供它所请求的域名。

##### 服务器回应（SeverHello）  

服务器收到客户端请求后，向客户端发出回应，这叫做 `SeverHello` 。服务器的回应包含以下内容。

1. 确认使用的加密通信协议版本，比如TLS 1.0版本。如果浏览器与服务器支持的版本不一致，服务器关闭加密通信。
2. 一个服务器生成的**随机数**，稍后用于生成对话密钥。
3. 确认使用的加密方法，比如 RSA 公钥加密。
4. 服务器证书。

除了上面这些信息，如果服务器需要确认客户端的身份，就会再包含一项请求，要求客户端提供 **“客户端证书”**。比如，金融机构往往只允许认证客户连入自己的网络，就会向正式客户提供 **USB** 密钥，里面就包含了一张客户端证书。

##### 客户端回应  

客户端收到服务器回应以后，首先验证服务器证书。如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。

**如果证书没有问题，客户端就会从证书中取出服务器的公钥**。然后，向服务器发送加密信息，包含下面三项信息。

1. 一个**随机数**。该随机数用服务器公钥加密，防止被窃听。
2. 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。
3. 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供服务器校验。

上面第一项的随机数，是整个握手阶段出现的第三个随机数，又称 `pre-master key` 。有了它以后，客户端和服务器就同时有了三个随机数，接着双方就用事先商定的加密方法，各自生成本次会话所用的同一把"会话密钥”。

至于 **为什么一定要用三个随机数，来生成"会话密钥”**：

> 不管是客户端还是服务器，都需要随机数，这样生成的密钥才不会每次都一样。由于SSL协议中证书是静态的，因此十分有必要引入一种随机因素来保证协商出来的密钥的随机性。
>
> 对于 RSA 密钥交换算法来说，`pre-master-key`本身就是一个随机数，再加上 hello 消息中的随机，**三个随机数通过一个密钥导出器最终导出一个对称密钥**。
>
> `pre master` 的存在在于 `SSL` 协议不信任每个主机都能产生完全随机的随机数，如果随机数不随机，那么 `pre master secret`（对称密钥） 就有可能被猜出来，那么仅适用 `pre master secret` 作为密钥就不合适了，因此必须引入新的随机因素，那么客户端和服务器三个随机数一同生成的密钥就不容易被猜出了，**一个伪随机可能完全不随机，可是是三个伪随机就十分接近随机了，每增加一个自由度，随机性增加的可不是一个量级**。

此外，如果前一步，服务器要求客户端证书，客户端会在这一步发送证书及相关信息。

##### 服务器的最后回应  

服务器收到客户端的第三个随机数 `pre-master key` 之后，计算生成本次会话所用的"会话密钥”。然后，向客户端最后发送下面信息。

1. 编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。
2. 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的 hash 值，用来供客户端校验。

至此，整个握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的HTTP协议，只不过用"会话密钥"加密内容。

### HTTPS 的七个误解

- `HTTPS无法缓存？`：许多人以为，出于安全考虑，浏览器不会在本地保存HTTPS缓存。实际上，只要在HTTP头中使用特定命令，**HTTPS是可以缓存的**。
- `SSL证书很贵？`：如果你在网上搜一下，就会发现很多便宜的SSL证书，大概10美元一年，这和一个 `.com` 域名的年费差不多。而且事实上，还能找到免费的 `SSL` 证书。
- `HTTPS站点必须有独享的IP地址？`使用子域名通配符SSL证书（`wildcard SSL certificate`，价格大约是每年125美元），就能在一个IP地址上部署多个HTTPS子域名。
- `转移服务器时要购买新证书？`
- `HTTPS太慢？`：使用HTTPS不会使你的网站变得更快（实际上有可能，请看下文），但是有一些技巧可以大大减少额外开销。
- `有了HTTPS，Cookie和查询字符串就安全了？`：虽然无法直接从HTTPS数据中读取Cookie和查询字符串，但是你仍然需要使它们的值变得难以预测。
- `只有注册登录页，才需要HTTPS？`：这种想法很普遍。人们觉得，HTTPS可以保护用户的密码，此外就不需要了。Firefox浏览器新插件Firesheep，证明了这种想法是错的。我们可以看到，在Twitter和Facebook上，劫持其他人的session是非常容易的。

### 中间人攻击（MITM）  

#### TLS对中间人攻击的抵御  

当然正常情况下，我们的网络安全肯定不会这么脆弱。得利于TLS证书体系，虽然我们能发起中间人攻击，不过浏览器察觉到了证书的异常。这是因为我们冒充了目标网站，但是并没有目标网站的证书，这样浏览器在校验证书时很容易发现证书错误。

#### 无法抵御中间人攻击的实例  

**部分开发者忽视证书校验**，或对证书异常处理不当，导致本来十分有效LTS失去原本的防御能力。有许多APP存在类似的问题，包括个别金融类应用，还有部分APP部分模块的流量存在被劫持的风险。



## Websocket  

### 简介  

WebSocket 是一种与 HTTP 不同的协议。两者都位于 OSI 模型的应用层，并且都依赖于传输层的 TCP 协议。 虽然它们不同，但 RFC 6455 规定：*WebSocket设计为通过 80 和 443 端口工作，以及支持HTTP代理和中介*，从而使其与HTTP协议兼容。为了实现兼容性， WebSocket 握手使用 HTTP Upgrade 头从 HTTP 协议更改为 WebSocket 协议。

与HTTP不同，WebSocket 提供全双工通信。此外，WebSocket 还可以在 TCP 之上启用消息流。 TCP 单独处理字节流，没有固有的消息概念。

WebSocket协议规范将 `ws`（WebSocket）和 `wss` （WebSocket Secure）定义为两个新的统一资源标识符（URI）方案，分别对应明文和加密连接。

#### 优点  

- **较少的控制开销**。在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小。在不包含扩展的情况下，对于服务器到客户端的内容，此头部大小只有2至10字节（和数据包长度有关）；对于客户端到服务器的内容，此头部还需要加上额外的4字节的掩码。相对于HTTP请求每次都要携带完整的头部，此项开销显著减少了。
- **更强的实时性**。由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于HTTP请求需要等待客户端发起请求服务端才能响应，延迟明显更少；
- **保持连接状态**。与 HTTP 不同的是，Websocket需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。而HTTP请求可能需要在每个请求都携带状态信息（如身份认证等）。
- **更好的二进制支持**。 Websocket 定义了二进制帧，相对HTTP，可以更轻松地处理二进制内容。
- **可以支持扩展**。Websocket 定义了扩展，用户可以扩展协议、实现部分自定义的子协议。如部分浏览器支持压缩等。
- **更好的压缩效果**。相对于HTTP压缩，Websocket 在适当的扩展支持下，可以沿用之前内容的上下文，在传递类似的数据时，可以显著地提高压缩率

### 连接过程  

WebSocket 是独立的、创建在 TCP 上的协议。Websocket 通过 HTTP/1.1 协议的101状态码进行握手。为了创建Websocket连接，需要通过浏览器发出请求，之后服务器进行回应，这个过程通常称为 **握手（handshaking）**。

客户端请求

```log
GET / HTTP/1.1
Upgrade: websocket
Connection: Upgrade
Host: example.com
Origin: http://example.com
Sec-WebSocket-Key: sN9cRrP/n9NdMgdcy2VJFQ==
Sec-WebSocket-Version: 13
```

服务器回应

```log
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: fFBooB7FAkLlXgRSz0BT3v4hq5s=
Sec-WebSocket-Location: ws://example.com/
```



#MySQL

## SQL  

### 连接  

在 MySQL 中 `JOIN`、 `CROSS JOIN` 、 `INNER JOIN` 是等价的，都是内连接。

#### 内连接  

- `JOIN`、 `CROSS JOIN` 、 `INNER JOIN` 当使用这三个子句时，其结果都是笛卡尔积；
- 如果以上三个子句加上 `ON`，则为 **等值连接**：只会返回 `ON` 子句相等的结果

#### 外连接  

外连接分为 `LEFT JOIN` 、 `RIGHT JOIN` 和 `NATURAL JOIN`，所有外连接均可省略 `OUTER`关键字，即 `LEFT OUTER JOIN...ON...` 与 `LEFT JOIN...ON...`等效。

- `T1 LEFT JOIN T2 ON T1.id=T2.id`：左外连接，返回所有列、T1 所有行、T2 中 条件符合的行
- `T1 RIGHT JOIN T2 ON T1.id=T2.id`：右外连接，返回所有列、T2 所有行、T1 中 条件符合的行
- `T1 NATURAL JOIN T2`：自然连接，返回 T1 所有行、T2 中与 T1 匹配的行，相同的属性被合并

对于自然连接要多做说明，现在有表 `join_test1` 、`join_test2`：

```log
mysql> select * from  join_test1;
+----+------+
| id | name |
+----+------+
|  1 | A    |
|  2 | B    |
|  3 | C    |
+----+------+
3 rows in set (0.00 sec)

mysql> select * from  join_test2;
+----+------+
| id | sex  |
+----+------+
|  1 | 男   |
|  2 | 女   |
|  4 | 男   |
+----+------+
3 rows in set (0.00 sec)
```

自然连接的结果：

```log
mysql> select * from join_test1 NATURAL join join_test2;
+----+------+------+
| id | name | sex  |
+----+------+------+
|  1 | A    | 男   |
|  2 | B    | 女   |
+----+------+------+
```

上面三种子句，又可组合出 `NATURAL LEFT|RIGHT JOIN...`：这种子句就结合了 `NATURAL JOIN` 和 `LEFT|RIGHT JOIN..ON...` 的特点：**在执行左|右连接的同时，将相同属性合并**。

```log
mysql> select * from join_test1 NATURAL left join join_test2;
+----+------+------+
| id | name | sex  |
+----+------+------+
|  1 | A    | 男   |
|  2 | B    | 女   |
|  3 | C    | NULL |
+----+------+------+
3 rows in set (0.00 sec)
```

### 子查询  

#### 子查询作为标量  

```sql
SELECT (SELECT s2 FROM t1);
```

#### 子查询比较  

```
non_subquery_operand comparison_operator (subquery)
```

= > < >= <= <> != <=> LIKE

#### ANY IN SOME  

```
operand comparison_operator ANY (subquery)
operand IN (subquery)
operand comparison_operator SOME (subquery)
```

#### EXISTS or NOT EXISTS  

```sql
SELECT column1 FROM t1 WHERE EXISTS (SELECT * FROM t2);
```

#### ALL  

operand comparison_operator ALL (subquery)

```sql
SELECT s1 FROM t1 WHERE s1 > ALL (SELECT s1 FROM t2);
```

#### 关联查询  

```sql
SELECT * FROM t1
  WHERE column1 = ANY (SELECT column1 FROM t2
                       WHERE t2.column2 = t1.column2);

select Score, (select count(distinct Score) from Scores b where b.Score>= s.Score) Rank from Scores s order by Score desc
```

#### 派生表  

```sql
SELECT ... FROM (subquery) [AS] tbl_name ...
```



## MySQL 架构  

总体来说 MySQL 可以分为两层，第一层是 MySQL 的服务层，包含 MySQL 核心服务功能：解析、分析、优化、缓存以及内置函数，所有跨存储引擎的功能都在这一层实现：存储过程、触发器、视图等。

第二层是 MySQL 的 **存储引擎层**，MySQL 中可使用多种存储引擎：InnoDB、MyISAM、Memory。存储引擎负责 MySQL 中数据的存取。服务层通过统一的 API 与存储引擎进行通信，这些 API 屏蔽来同步存储引擎之间的差异，使得这些差异对上层的查询过程透明。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/mysql_architecture.svg)

### MySQL Server  

#### 连接器  

连接器负责跟客户端建立连接、获取权限、维持和管理连接。

#### 查询缓存  

查询缓存将查询结果按 K-V 的形式进行缓存，K 是查询的语句，V 是查询的结果。当一个表发生更新后，该表对应的所有缓存均会失效。

#### 分析器  

分析器有两个功能：**词法分析**、**语法分析**。对于一个 SQL 语句，分析器首先进行词法分析，对 SQL 语句进行拆分，识别出各个字符串代表的含义。然后就是语法分析，分析器根据定义的语法规则判断 SQL 是否满足 MySQL 语法。

#### 优化器  

优化器在获取到分析器的结果后，通过表结构和 SQL 语句选择执行方案，比如：多表关联时，各个表如何进行连接；当表中有索引时，应该怎样选择索引 等等。

#### 执行器  

获取到执行方案后，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。在进行查询时，MySQL 执行器内部执行步骤如下：

1. 调用引擎接口取这个表的第一行，判断该行是否满足 WHERE 子句，如果满足则将这行存在结果集中，否则跳过。
2. 调用引擎接口取下一行，重复相同的判断逻辑，直到取到这个表的最后一行。
3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。

对于走索引的查询，执行的逻辑也差不多。第一次调用的是 *取满足条件的第一行* 这个接口，之后循环取 *满足条件的下一行* 这个接口，这些接口都是引擎中已经定义好的。

#### Update 处理逻辑  

这里简单的分析下 Update 的处理逻辑

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/mysql_update_process.jpg)

1. MySQL Server 发送更新请求到 InnoDB 引擎
2. 从 Buffer Pool 加载对应记录的 Data Page（P1）
   1. 若 Buffer Pool 中没有该记录，则从磁盘加载该记录
3. 将 P1 存储到 Undo Page 中，并在 Redo Log Buffer 中记录 Undo 操作
4. 更新 P1 为 P1’ ，并将 P1’ 写入 Dirty Page ，记录变更到 Redo Log Buffer（Prepare 状态）
5. 返回 MySQL Server 执行完成
6. MySQL Server 记录 binlog
7. MySQL Server 提交 Commit
8. Redo Log Buffer 状态有 Prepare 更改为 Commit，并刷入磁盘
9. 当 Dirty Page 过多时，启动 ChcekPoint 机制，将脏页刷入磁盘



## InnoDB 索引  

### 数据存储  

当 InnoDB 存储数据时，它可以使用不同的行格式进行存储；MySQL 5.7 版本支持以下格式的行存储方式：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/81407aa14450d2d6fac1a70961880aac.png)

> `Antelope` 是 InnoDB 最开始支持的文件格式，它包含两种行格式 `Compact` 和 `Redundant` ，它最开始并没有名字； `Antelope` 的名字是在新的文件格式 `Barracuda`出现后才起的， `Barracuda` 的出现引入了两种新的行格式 `Compressed` 和 `Dynamic`；InnoDB 对于文件格式都会向前兼容，而官方文档中也对之后会出现的新文件格式预先定义好了名字：Cheetah、Dragon、Elk 等等。

两种行记录格式 `Compact` 和 `Redundant` 在磁盘上按照以下方式存储：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/a18d600fb632031a00937b1e667e446e.png)

`Compact` 和 `Redundant` 格式最大的不同就是记录格式的第一个部分；在 `Compact` 中，行记录的第一部分倒序存放了一行数据中列的长度（Length），而 `Redundant` 中存的是每一列的偏移量（Offset），从总体上上看， `Compact` 行记录格式相比 `Redundant` 格式能够减少 `20%` 的存储空间。

#### 行溢出数据  

当 InnoDB 使用 `Compact` 或者 `Redundant` 格式存储极长的 `VARCHAR` 或者 `BLOB` 这类大对象时，我们并不会直接将所有的内容都存放在数据页节点中，而是将数据中的前 `768` 个字节存储在数据页中，后面会通过偏移量指向溢出页（off-page），最大768字节的作用是便于创建 **前缀索引**。溢出页（off-page）不存储在 B+tree 中，**使用的是uncompress BLOB page，并且每个字段的溢出都是存储独享**。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/19af5612d981bf2ae2ea7d5b5b9b26ac.png)

但是当我们使用新的行记录格式 `Compressed` 或者 `Dynamic` 时都只会在行记录中保存 `20`个字节的指针，实际的数据都会存放在溢出页面中。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/f7dc83f1b5cfb5f428adc404ce3cfa13.png)

当然在实际存储中，可能会对不同长度的 TEXT 和 BLOB 列进行优化。

> 想要了解更多与 InnoDB 存储引擎中记录的数据格式的相关信息，可以阅读 [InnoDB Record Structure](https://dev.mysql.com/doc/internals/en/innodb-record-structure.html)

#### 数据页结构  

与现有的大多数存储引擎一样，InnoDB 使用页作为磁盘管理的最小单位；数据在 InnoDB 存储引擎中都是按行存储的，每个 `16KB` 大小的页中可以存放 `2-200` 行的记录。

页是 InnoDB 存储引擎管理数据的最小磁盘单位，而 `B-Tree` 节点就是实际存放表中数据的页面，我们在这里将要介绍页是如何组织和存储记录的；首先，一个 InnoDB 页有以下七个部分：

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/771f5daaf406ec0990ca339c9a594bec.png)

每一个页中包含了两对 `header/trailer`：内部的 `Page Header/Page Directory` 关心的是页的状态信息，而 `Fil Header/Fil Trailer` 关心的是记录页的头信息。

在页的头部和尾部之间就是用户记录和空闲空间了，每一个数据页中都包含 `Infimum` 和 `Supremum` 这两个虚拟的记录（可以理解为占位符）， `Infimum` 记录是比该页中任何主键值都要小的值， `Supremum` 是该页中的最大值：

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/85f36113b83bba8aa1ceb1d75bc97271.png)

`User Records` 就是整个页面中真正用于存放行记录的部分，而 `Free Space` 就是空余空间了，它是一个链表的数据结构，为了保证插入和删除的效率，整个页面并不会按照主键顺序对所有记录进行排序，它会自动从左侧向右寻找空白节点进行插入，行记录在物理存储上并不是按照顺序的，它们之间的顺序是由 `next_record` 这一指针控制的。

`B+` 树在查找对应的记录时，并不会直接从树中找出对应的行记录，它只能获取记录所在的页，将整个页加载到内存中，再通过 `Page Directory` 中存储的稀疏索引和 `n_owned、next_record` 属性取出对应的记录，不过因为这一操作是在内存中进行的，所以通常会忽略这部分查找的耗时。这样就存在一个命中率的问题，如果一个page中能够相对的存放足够多的行，那么命中率就会相对高一些，性能就会有提升。

B+树底层的叶子节点为一双向链表，因此 **每个页中至少应该有两行记录**，这就决定了 InnoDB 在存储一行数据的时候不能够超过 `8kb`，但事实上应该更小，因为还有一些 InnoDB 内部数据结构要存储。

通常我们认为 `blob` 这类的大对象的存储会把数据存放在 off-page，其实不然，**关键点还是要看一个 page 中到底能否存放两行数据，blob 可以完全存放在数据页中(单行长度没有超过 `8kb`)，而 `varchar` 类型的也有可能存放在溢出页中(单行长度超过 `8kb`，前 `768byte` 存放在数据页中)**。

### 索引  

索引是数据库中非常非常重要的概念，它是存储引擎能够快速定位记录的秘密武器，对于提升数据库的性能、减轻数据库服务器的负担有着非常重要的作用；**索引优化是对查询性能优化的最有效手段**，它能够轻松地将查询的性能提高几个数量级。

InnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，这是关系型数据库中查找最为常用和有效的索引，但是 **B+ 树索引并不能找到一个给定键对应的具体值，它只能找到数据行对应的页**，然后正如上一节所提到的，数据库把整个页读入到内存中，并在内存中查找具体的数据行。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/c60f9c70aa5f25cea0f109f4064e13ab.png)

B+ 树是平衡树，它查找任意节点所耗费的时间都是完全相同的，比较的次数就是 B+ 树的高度；

> `B+` 树的叶子节点存放所有指向关键字的指针，节点内部关键字记录和节点之间都根据关键字的大小排列。当顺序递增插入的时候，只有最后一个节点会在满掉的时候引起索引分裂，此时无需移动记录，只需创建一个新的节点即可。而当非递增插入的时候，会使得旧的节点分裂，还可能伴随移动记录，以便使得新数据能够插入其中。**一般建议使用一列顺序递增的 ID 来作为主键**，但不必是数据库的 `autoincrement` 字段，只要满足顺序增加即可，如 `twitter` 的 `snowflake` 即为顺序递增的 ID 生成器。

#### B+ 树的高度  

这里我们先假设 B+ 树高为2，即存在一个根节点和若干个叶子节点，那么这棵 B+ 树的存放总记录数为：根节点指针数*单个叶子节点记录行数。这里假设一行记录的大小为1k，那么一个页上的能放 16 行数据。假设主键ID为 bigint 类型，长度为 8 字节，而指针大小在 InnoDB 源码中设置为 6 字节，这样一共14字节，那么可以算出一棵高度为 2 的 B+ 树，能存放 16 \times 1024\div 14\times 16=1872016×1024÷14×16=18720 条这样的数据记录。

根据同样的原理我们可以算出一个高度为3的B+树可以存放： 1170\times 1170\times 16=21,902,4001170×1170×16=21,902,400 条这样的记录。所以在 InnoDB 中 B+ 树高度一般为 1~3 层，它就能满足千万级的数据存储。

#### 聚集索引  

InnoDB 存储引擎中的表都是使用索引组织的，也就是按照键的顺序存放；聚集索引就是按照表中主键的顺序构建一颗 B+ 树，并在叶节点中存放表中的行记录数据。

> 如果没有定义主键，则会使用非空的 UNIQUE键 做主键 ; 如果没有非空的 UNIQUE键 ，则系统生成一个6字节的 `rowid` 做主键;

```sql
CREATE TABLE users(
    id INT NOT NULL,
    first_name VARCHAR(20) NOT NULL,
    last_name VARCHAR(20) NOT NULL,
    age INT NOT NULL,
    PRIMARY KEY(id),
    KEY(last_name, first_name, age)
    KEY(first_name)
);
```

如果使用上面的 SQL 在数据库中创建一张表，B+ 树就会使用 id 作为索引的键，并在叶子节点中存储一条记录中的所有信息。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/4bc2f4c58303c2b20751ff20cd692d33.png)

> 图中对 B+ 树的描述与真实情况下 B+ 树中的数据结构有一些差别，不过这里想要表达的主要意思是：**聚集索引叶节点中保存的是整条行记录，而不是其中的一部分**。

聚集索引与表的物理存储方式有着非常密切的关系，所有正常的表应该 **有且仅有一个** 聚集索引（绝大多数情况下都是主键），表中的所有行记录数据都是按照 **聚集索引** 的顺序存放的。

当我们使用聚集索引对表中的数据进行检索时，可以直接获得聚集索引所对应的整条行记录数据所在的页，不需要进行第二次操作。

#### 辅助索引  

数据库将 **所有的非聚集索引都划分为辅助索引**，但是这个概念对我们理解辅助索引并没有什么帮助；辅助索引也是通过 B+ 树实现的，但是它的叶节点并不包含行记录的全部数据，仅包含索引中的所有键和一个用于查找对应行记录的『书签』，在 InnoDB 中这个书签就是当前记录的主键。

辅助索引的存在并不会影响聚集索引，因为聚集索引构成的 B+ 树是数据实际存储的形式，而辅助索引只用于加速数据的查找，所以一张表上往往有多个辅助索引以此来提升数据库的性能。

> 一张表一定包含一个聚集索引构成的 B+ 树以及若干辅助索引的构成的 B+ 树。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/1bef5c5161044e2cf889574577eef6c9.png)

如果在表 `users` 中存在一个辅助索引 (`first_name, age`)，那么它构成的 B+ 树大致就是上图这样，按照 (first_name, age) 的字母顺序对表中的数据进行排序，当查找到主键时，再通过聚集索引获取到整条行记录。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2f31d7b8720a113ae5a7ed3c48a1c9d4.png)

上图展示了一个使用辅助索引查找一条表记录的过程：通过辅助索引查找到对应的主键，最后在聚集索引中使用主键获取对应的行记录，这也是通常情况下行记录的查找方式。

#### 覆盖索引  

聚簇索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录，这种行为被称之为 **回表**。回表会导致查询时多次读取磁盘，为减少IO MySQL 在辅助索引上进行优化，将辅助索引作为 **覆盖索引**（Covering index）。在查询的时候，如果 `SELECT` 子句中的字段为主键、辅助索引的键则不进行回表。

### 索引失效  

索引并不是时时都会生效的，比如以下几种情况，将导致索引失效：

1. 如果条件中有 or，即使其中有条件带索引也不会使用。要想使用or，又想让索引生效，只能将 or 条件中的每个列都加上索引
2. 对于多列索引，不是使用的最左匹配，则不会使用索引。
3. 如果 mysql 估计使用全表扫描要比使用索引快，则不使用索引。例如，使用`<>`、`not in` 、`not` `exist`，对于这三种情况大多数情况下认为结果集很大，MySQL 就有可能不使用索引。

### 索引使用  

- (7) - SELECT
- (8) - DISTINCT <select_list>
- (1) - FROM <left_table>
- (3) - <join_type> JOIN <right_table>
- (2) - ON <join_condition>
- (4) - WHERE <where_condition>
- (5) - GROUP BY <group_by_list>
- (6) - HAVING <having_condition>
- (9) - ORDER BY <order_by_condition>
- (10) - LIMIT <limit_number>

关于 SQL 语句的执行顺序，有三个值得我们注意的地方：

- **FROM 才是 SQL 语句执行的第一步，并非 SELECT**。 数据库在执行 SQL 语句的第一步是将数据从硬盘加载到数据缓冲区中，以便对这些数据进行操作。
- **SELECT 是在大部分语句执行了之后才执行的，严格的说是在 FROM 和 GROUP BY 之后执行的**。理解这一点是非常重要的，这就是你不能在 WHERE 中使用在 SELECT 中设定别名的字段作为判断条件的原因。
- **无论在语法上还是在执行顺序上， UNION 总是排在在 ORDER BY 之前**。很多人认为每个 UNION 段都能使用 ORDER BY 排序，但是根据 SQL 语言标准和各个数据库 SQL 的执行差异来看，这并不是真的。尽管某些数据库允许 SQL 语句对子查询（subqueries）或者派生表（derived tables）进行排序，但是这并不说明这个排序在 UNION 操作过后仍保持排序后的顺序。

虽然SQL的逻辑查询是根据上述进行查询，但是数据库也许并不会完全按照逻辑查询处理的方式来进行查询。 MySQL 数据库有两个组件 `Parser`（分析SQL语句）和 `Optimizer`（优化）。

从官方手册上看，可以理解为， `MySQL` 采用了基于开销的优化器，以确定处理查询的最解方式，也就是说执行查询之前，都会先选择一条自以为最优的方案，然后执行这个方案来获取结果。在很多情况下， `MySQL` 能够计算最佳的可能查询计划，但在某些情况下， `MySQL`没有关于数据的足够信息，或者是提供太多的相关数据信息，估测就不那么友好了。

存在索引的情况下，优化器优先使用条件用到索引且最优的方案。**当 SQL 条件有多个索引可以选择， MySQL 优化器将直接使用效率最高的索引执行**。



## InnoDB 并发控制  

### InnoDB 锁机制  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/e86d2bb63f9ecf327e588f352bb26d3b.png)

InnoDB默认使用行锁，实现了两种标准的行锁——共享锁与排他锁；

| 行锁类型            | 锁功能                             | 锁兼容性                       | 加锁                                                         | 释放锁                                                       |
| ------------------- | ---------------------------------- | ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 共享锁（读锁、S锁） | 允许获取共享锁的亊务读数据         | 与共享锁兼容，与排它锁不兼容   | 只有 `SerializaWe` 隔离级别会默认为：读加共享锁；其他隔离级别下，可显示使用 `select...lock in share model` 为读加共享锁 | 在事务提交或回滚后会自动同时释放锁；除了使用 `start transaction` 的方式显式开启事务，InnoDB 也会自动为增删改査语句开启事务，并自动提交或回滚；(`autocommit=1`) |
| 排它锁（写锁、X锁） | 允许获取排它锁的事务更新或删除数据 | 与共享锁不兼容，与排它锁不兼容 | 在默认的 `Reapeatable Read` 隔离级别下，InnoDB 会自动为增删改操作的行加排它锁；也可显式使用 `select...for update`为读加排它锁 | …                                                            |

> 1. 除了显式加锁的情况，其他情况下的加锁与解锁都无需人工干预
> 2. InnoDB 所有的行锁算法都是基于索引实现的，锁定的也都是索引或索引区间

#### 当前读 & 快照读  

**当前读**：即加锁读，读取记录的最新版本，会加锁保证其他并发事务不能修改当前记录，直至获取锁的事务释放锁；使用当前读的操作主要包括：**显式加锁的读操作与插入/更新/删除等写操作**，如下所示：

```sql
select * from table where ? lock in share mode;
select * from table where ? for update;
insert into table values (…);
update table set ? where ?;
delete from table where ?;
```

> 注：当 `Update` SQL 被发给 `MySQL` 后， `MySQL Server` 会根据where条件，读取第一条满足条件的记录，然后 InnoDB 引擎会将第一条记录返回，并加锁，待 `MySQL Server` 收到这条加锁的记录之后，会再发起一个 `Update` 请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有满足条件的记录为止。因此， `Update` 操作内部，就包含了当前读。同理， `Delete` 操作也一样。 `Insert` 操作会稍微有些不同，简单来说，就是 `Insert` 操作可能会触发 `Unique Key` 的冲突检查，也会进行一个当前读。

**快照读：即不加锁读，读取记录的快照版本而非最新版本，通过MVCC实现**；

InnoDB 默认的 `RR` 事务隔离级别下，不显式加`lock in share mode`与`for update`的 `select` 操作都属于快照读，保证事务执行过程中只有第一次读之前提交的修改和自己的修改可见，其他的均不可见；

#### 共享锁与独占锁  

#### 意向锁  

InnoDB 支持多粒度的锁，允许表级锁和行级锁共存。一个类似于 `LOCK TABLES ... WRITE`的语句会获得这个表的 `x` 锁。为了实现多粒度锁，InnoDB 使用了意向锁（简称 I 锁）。I 锁是表明一个事务稍后要获得针对一行记录的某种锁（`s or x`）的对应表的表级锁，有两种：

- 意向排它锁（简称 IX 锁）表明一个事务意图在某个表中设置某些行的 x 锁
- 意向共享锁（简称 IS 锁）表明一个事务意图在某个表中设置某些行的 s 锁

`SELECT ... LOCK IN SHARE MODE` 设置一个 `IS` 锁, `SELECT ... FOR UPDATE` 设置一个 `IX` 锁。意向锁的原则如下：

- 一个事务必须先持有该表上的 IS 或者更强的锁才能持有该表中某行的 S 锁
- 一个事务必须先持有该表上的 IX 锁才能持有该表中某行的 X 锁

新请求的锁只有兼容已有锁才能被允许，否则必须等待不兼容的已有锁被释放。**一个不兼容的锁请求不被允许是因为它会引起死锁，错误会发生**。意向锁只会阻塞全表请求（比如 `LOCK TABLES ... WRITE` ）。**意向锁的主要目的是展示某人正在锁定表中一行，或者将要锁定一行**。

#### Record Lock  

记录锁（Record Lock）是加到**索引记录**上的锁，假设我们存在下面的一张表 `users`：

```sql
CREATE TABLE users(
    id INT NOT NULL AUTO_INCREMENT,
    last_name VARCHAR(255) NOT NULL,
    first_name VARCHAR(255),
    age INT,
    PRIMARY KEY(id),
    KEY(last_name),
    KEY(age)
);
```

如果我们使用 `id` 或者 `last_name` 作为 SQL 中 `WHERE` 语句的过滤条件，那么 InnoDB 就可以通过索引建立的 B+ 树找到行记录并添加索引，但是如果使用 `first_name` 作为过滤条件时，由于 InnoDB 不知道待修改的记录具体存放的位置，也无法对将要修改哪条记录提前做出判断就会锁定整个表。

#### Gap Lock  

记录锁是在存储引擎中最为常见的锁，除了记录锁之外，InnoDB 中还存在间隙锁（Gap Lock），间隙锁是对索引记录中的一段连续区域的锁；当使用类似 `SELECT * FROM users WHERE id BETWEEN 10 AND 20 FOR UPDATE;` 的 SQL 语句时，就会阻止其他事务向表中插入 `id = 15` 的记录，因为整个范围都被间隙锁锁定了。

> 间隙锁是存储引擎对于性能和并发做出的权衡，并且只用于某些事务隔离级别。

虽然间隙锁中也分为共享锁和互斥锁，不过它们之间并不是互斥的，也就是不同的事务可以同时持有一段相同范围的共享锁和互斥锁，它唯一阻止的就是**其他事务向这个范围中添加新的记录**。

##### 间隙锁的缺点  

- 间隙锁有一个比较致命的弱点，就是当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据。在某些场景下这可能会对性能造成很大的危害
- 当Query无法利用索引的时候， InnoDB会放弃使用行级别锁定而改用表级别的锁定，造成并发性能的降低；
- 当Quuery使用的索引并不包含所有过滤条件的时候，数据检索使用到的索引键所指向的数据可能有部分并不属于该Query的结果集的行列，但是也会被锁定，因为间隙锁锁定的是一个范围，而不是具体的索引键；
- 当Query在使用索引定位数据的时候，如果使用的索引键一样但访问的数据行不同的时候（索引只是过滤条件的一部分），一样会被锁定

##### Next-Key Lock  

Next-Key 锁相比前两者就稍微有一些复杂，它是记录锁和记录前的间隙锁的结合，在 `users` 表中有以下记录：

```
    +------|-------------|--------------|-------+
    |   id | last_name   | first_name   |   age |
    |------|-------------|--------------|-------|
    |    4 | stark       | tony         |    21 |
    |    1 | tom         | hiddleston   |    30 |
    |    3 | morgan      | freeman      |    40 |
    |    5 | jeff        | dean         |    50 |
    |    2 | donald      | trump        |    80 |
    +------|-------------|--------------|-------+
```

如果使用 Next-Key 锁，那么 Next-Key 锁就可以在需要的时候锁定以下的范围：

```
    (-∞, 21]
    (21, 30]
    (30, 40]
    (40, 50]
    (50, 80]
    (80, ∞)
```

> 既然叫 Next-Key 锁，锁定的应该是当前值和后面的范围，但是实际上却不是，Next-Key 锁锁定的是当前值和前面的范围。

当我们更新一条记录，比如 `SELECT * FROM users WHERE age = 30 FOR UPDATE;`，InnoDB 不仅会在范围 `(21, 30]` 上加 Next-Key 锁，还会在这条该记录索引增长方向的范围 `(30, 40]` 加间隙锁，所以插入 `(21, 40]` 范围内的记录都会被锁定。

> Next-Key 锁的作用其实是为了解决幻读的问题。

#### 插入意向锁  

插入意向锁是在插入一行记录操作之前设置的一种间隙锁，这个锁释放了一种插入方式的信号，亦即多个事务在相同的索引间隙插入时如果不是插入间隙中相同的位置就不需要互相等待。假设有索引值`4、7`，几个不同的事务准备插入`5、6`，每个锁都在获得插入行的独占锁之前用插入意向锁各自锁住了`4、7`之间的间隙，但是不阻塞对方因为插入行不冲突。

#### 自增锁  

自增锁是一个特殊的表级锁，事务插入自增列的时候需要获取，最简单情况下如果一个事务插入一个值到表中，任何其他事务都要等待，这样第一个事物才能获得连续的主键值。

#### 锁选择  

```
+——-+————-+
| id | name |
+——-+————-+
| 1 | title1 |
+——-+————-+
| 2 | title2 |
+——-+————-+
| 3 | title3 |
+——-+————-+
| 9 | title9 |
+——-+————-+
| 10 | title10 |
+——-+————-+
```

按照原理来说，`id>5 and id<7`这个查询条件，在表中找不到满足条件的项，因此会对第一个不满足条件的项(`id = 9`)上加GAP锁，防止后续其他事务插入满足条件的记录。

而 **GAP 锁与GAP 锁是不冲突的**，那么为什么两个同时执行`id>5 and id<7`查询的事务会冲突呢？

原因在于，`MySQL Server`并没有将`id<7`这个查询条件下降到`InnoDB`引擎层，因此`InnoDB`看到的查询，是`id>5`，正向扫描。读出的记录`id=9`，先加上`next key锁`(Lock X + GAP lock)，然后返回给 MySQL Server 进行判断。 MySQL Server 此时才会判断返回的记录是否满足`id<7`的查询条件。此处不满足，查询结束。

因此，`id=9`记录上，真正持有的锁是`next key`锁，**而`next key`锁之间是相互冲突的**，这也说明了为什么两个`id>5 and id<7`查询的事务会冲突的原因。

### MVCC  

InnoDB 引擎支持 MVCC(Multiversion Concurrency Control)：InnoDB 保存了行的历史版本，以支持事务的并发控制和回滚。这些历史信息保存在表空间的 **回滚段（Rollback Segment）** 里，回滚段中存储着 **Undo Log**。当事务需要进行回滚时，InnoDB 就会使用这些信息来进行 Undo 操作，同时这些信息也可用来实现 **一致性读**。

InnoDB 在存储的每行数据中都增加了三列隐藏属性：

- `DB_TRX_ID`：最后一次插入或更新的事务ID
- `DB_ROLL_PTR`：指向已写入回滚段的 Undo Log 记录。如果这行记录是更新的，那么就可以根据这个 Undo Log 记录重建之间的数据
- `DB_ROW_ID`：自增序列，如果表未指定主键，则由该列作为主键

在回滚段的 Undo Log 被分为 `Insert Undo Log` 和 `Update Undo Log`。Insert Undo Log 只是在事务回滚的时候需要，在事务提交后就可丢弃。Update Undo Log 不仅仅在回滚的时候需要，还要提供一致性读，所以只有在所有需要该 Update Undo Log 构建历史版本数据的事务都提交后才能丢弃。MySQL 建议尽量频繁的提交事务，这样可以保证 InnoDB 快速的丢弃 Update Undo Log，防止其过大。

在 InnoDB 中，行数据的物理删除不是立刻执行，InnoDB 会在行删除的 Undo Log 被丢弃时才会进行物理删除。这个过程被称之为 **清理（Purge）**，其执行过程十分迅速。

#### MVCC 二级索引  

InnoDB 在更新时对 二级索引 和 聚集索引的处理方式不一样。在聚集索引上的更新是原地更新（in-place），其中的隐藏属性 `DB_ROLL_PTR` 指向的 Undo Log 可以重建历史数据。但是二级索引没有隐藏属性，所以不能原地更新。

当二级索引的数据被更新时，旧的二级索引记录标记为 **标记删除（delete-marked）**，然后插入一条新的索引记录，最终标记删除的索引记录会被清除。当二级索引记录被标记为 delete-marked 或者有更新的事务更新时，InnoDB 会查找聚集索引。在聚集索引中检查行的 `DB_TRX_ID`，如果事务修改了记录，则从 Undo Log 中构建行数据的正确版本。如果二级索引记录被标记为 delete-marked 或者 二级索引有更新的事务更新，覆盖索引技术不会被使用（获取行任意数据均需要回表）。

#### MVCC vs 乐观锁  

**MVCC 并不是一个与乐观和悲观并发控制对立的东西，它能够与两者很好的结合以增加事务的并发量**，在目前最流行的 SQL 数据库 MySQL 和 PostgreSQL 中都对 MVCC 进行了实现；但是由于它们分别实现了悲观锁和乐观锁，所以 MVCC 实现的方式也不同。

MVCC 可以保证不阻塞地读到一致的数据。但是，MVCC 并没有对实现细节做约束，为此不同的数据库的语义有所不同，比如：

- `postgres` 对写操作也是乐观并发控制；在表中保存同一行数据记录的多个不同版本，每次写操作，都是创建，而回避更新；在事务提交时，按版本号检查当前事务提交的数据是否存在写冲突，则抛异常告知用户，回滚事务；
- `innodb` 则只对读无锁，写操作仍是上锁的悲观并发控制，这也意味着，`innodb` 中只能见到因死锁和不变性约束而回滚，而见不到因为写冲突而回滚，不像 postgres 那样对数据修改在表中创建新纪录，而是每行数据只在表中保留一份，在更新数据时上行锁，同时将旧版数据写入 `undo log`。表和 undo log 中行数据都记录着事务ID，在检索时，只读取来自当前已提交的事务的行数据。

可见 MVCC 中的写操作仍可以按悲观并发控制实现，而 `CAS` 的写操作只能是乐观并发控制。还有一个不同在于，MVCC 在语境中倾向于 “对多行数据打快照造平行宇宙”，然而 `CAS`一般只是保护单行数据而已。比如 mongodb 有 CAS 的支持，但不能说这是 MVCC。



### InnoDB 事务隔离  

#### 几种隔离级别  

事务的隔离性是数据库处理数据的几大基础之一，而隔离级别其实就是提供给用户用于在性能和可靠性做出选择和权衡的配置项。

ISO 和 ANIS SQL 标准制定了四种事务隔离级别，而 InnoDB 遵循了 SQL:1992 标准中的四种隔离级别：`READ UNCOMMITED`、`READ COMMITED`、`REPEATABLE READ` 和 `SERIALIZABLE`；每个事务的隔离级别其实都比上一级多解决了一个问题：

- `RAED UNCOMMITED`：使用查询语句不会加锁，可能会读到未提交的行（Dirty Read）；

  > 可以读取未提交记录。此隔离级别，不会使用，忽略。

- `READ COMMITED`：只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果（Non-Repeatable Read）；

  > 快照读忽略，本文不考虑。针对当前读，RC隔离级别保证对读取到的记录加锁 (记录锁)，存在幻读现象。

- `REPEATABLE READ`：快照读忽略，本文不考虑。针对当前读，**RR隔离级别保证对读取到的记录加锁 (记录锁)，同时保证对读取的范围加锁，新的满足查询条件的记录不能够插入 (间隙锁)**，不存在幻读现象。

- `SERIALIZABLE`：从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。

  > Serializable隔离级别下，读写冲突，因此并发度急剧下降，在MySQL/InnoDB下不建议使用。

MySQL 中默认的事务隔离级别就是 `REPEATABLE READ`，但是它通过 Next-Key 锁也能够在某种程度上解决幻读的问题。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/15a2370c552e932907f8b2d3587171ef.png)

接下来，我们将数据库中创建如下的表并通过个例子来展示在不同的事务隔离级别之下，会发生什么样的问题：

```sql
CREATE TABLE test(
    id INT NOT NULL,
    UNIQUE(id)
);
```

#### 脏读  

> 在一个事务中，读取了其他事务未提交的数据。

当事务的隔离级别为 `READ UNCOMMITED` 时，我们在 `SESSION 2` 中插入的**未提交**数据在 `SESSION 1` 中是可以访问的。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/e4696fae4a417bdd70dd04f0786647ed.png)

#### 不可重复读  

> 在一个事务中，同一行记录被访问了两次却得到了不同的结果。

当事务的隔离级别为 `READ COMMITED` 时，虽然解决了脏读的问题，但是如果在 `SESSION 1`先查询了**一行**数据，在这之后 `SESSION 2` 中修改了同一行数据并且提交了修改，在这时，如果 `SESSION 1` 中再次使用相同的查询语句，就会发现两次查询的结果不一样。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/d2d41261df71879fab0eb54771688d78.png)

不可重复读的原因就是，在 `READ COMMITED` 的隔离级别下，存储引擎不会在查询记录时添加行锁，锁定 `id = 3` 这条记录。

#### 幻读  

> 在一个事务中，同一个范围内的记录被读取时，其他事务向这个范围添加了新的记录。

重新开启了两个会话 `SESSION 1` 和 `SESSION 2`，在 `SESSION 1` 中我们查询全表的信息，没有得到任何记录；在 `SESSION 2` 中向表中插入一条数据并提交；由于 `REPEATABLE READ` 的原因，再次查询全表的数据时，我们获得到的仍然是空集，但是在向表中插入同样的数据却出现了错误。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/b356bfdde7d52c6993a697c4529d2f6b.png)

这种现象在数据库中就被称作幻读，虽然我们使用查询语句得到了一个空的集合，但是插入数据时却得到了错误，好像之前的查询是幻觉一样。

在标准的事务隔离级别中，幻读是由更高的隔离级别 `SERIALIZABLE` 解决的，但是它也可以通过 MySQL 提供的 `Next-Key` 锁解决：

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/8d3094a3893ae4d1806dfcb3a93b7dff.png)

`REPEATABLE READ` 和 `READ UNCOMMITED` 其实是矛盾的，如果保证了前者就看不到已经提交的事务，如果保证了后者，就会导致两次查询的结果不同，MySQL 为我们提供了一种折中的方式，能够在 `REPEATABLE READ` 模式下加锁访问已经提交的数据，其本身并不能解决幻读的问题，而是通过文章前面提到的 `Next-Key` 锁来解决。



### 分库分表  

#### 垂直拆分  

**垂直分表** 也就是 *大表拆小表*，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到 *扩展表*。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的 off-page 问题。

**垂直分库** 针对的是一个系统中的不同业务进行拆分。将多个业务系统的数据放在单个数据库中（**服务化**拆分），这会让数据库的单库处理能力成为瓶颈。将单个数据库，按业务进行拆分，同一业务领域的数据表放到同一数据库中。并且多个数据库分布在多个机器上，防止由于单机的磁盘、内存、IO等资源造成 MySQL 性能下降。

数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破 IO、连接数等单机硬件资源的瓶颈。

#### 水平拆分  

目前绝大多数应用采取的两种分库分表规则

- `离散映射`：如 mod 或 dayofweek ， 这种类型的映射能够很好的解决热点问题，但带来了数据迁移和历史数据问题。
- `连续映射`；如按 id 或 gmt_create_time 的连续范围做映射。这种类型的映射可以避免数据迁移，但又带来热点问题。

随着数据量的增大，每个表或库的数据量都是各自增长。当一个表或库的数据量增长到了一个极限，要加库或加表的时候，介于这种分库分表算法的离散性，必需要做 **数据迁移** 才能完成。

考虑到数据增长的特点，如果我们以代表时间增长的字段，按递增的范围分库，则可以避免数据迁移。这样的方式下，在数据量再增加达到前几个库/表的上限时，则继续水平增加库表，原先的数据就不需要迁移了。但是这样的方式会带来一个 **热点问题**：当前的数据量达到某个库表的范围时，所有的插入操作，都集中在这个库/表了。

结合离散分库/分表和连续分库/分表的优点，可使要热点和新数据均匀分配在每个库，同时又保证易于水平扩展。分库分表的主要经历以下三个阶段：

##### 阶段一  

一个数据库，两个表，`rule0 = id % 2`

```
分库规则dbRule: “DB0″
分表规则tbRule: “t” + (id % 2)
```

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/5-mysql-3a686.png)

##### 阶段二  

当单库的数据量接近 1千万，单表的数据量接近 500 万时，进行扩容（数据量只是举例，具体扩容量要根据数据库和实际压力状况决定）：增加一个数据库 `DB1`，将 `DB0.t0` 整表迁移到新库 `DB1.t1`。每个库各增加1个表，未来10M-20M的数据mod2分别写入这2个表：`t0_1，t1_1`：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/5-mysql-6885c.png)

分库规则dbRule:

```
“DB” + (id % 2)
```

分表规则tbRule:

```java
if(id < 1千万){
    return "t"+ (id % 2);   //1千万之前的数据，仍然放在t0和t1表。t1表从DB0搬迁到DB1库
}else if(id < 2千万){
    return "t"+ (id % 2) +"_1"; //1千万之后的数据，各放到两个库的两个表中: t0_1,t1_1
}else{
    throw new IllegalArgumentException("id outof range[20000000]:" + id);
}
```

这样 `10M` 以后的新生数据会均匀分布在 `DB0` 和 `DB1`; 插入更新和查询热点仍然能够在每个库中均匀分布。每个库中同时有老数据和不断增长的新数据。每表的数据仍然控制在 `500万`以下。

##### 阶段三  

当两个库的容量接近上限继续水平扩展时，进行如下操作：

- 新增加两个库：`DB2`和`DB3`，以`id % 4`分库。余数`0、1、2、3`分别对应`DB`的下标. `t0`和`t1`不变，
- 将`DB0.t0_1`整表迁移到`DB2`; 将`DB1.t1_1`整表迁移到`DB3`

`20M-40M`的数据 mod4 分为 4 个表：`t0_2，t1_2，t2_2，t3_2`，分别放到4个库中：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/5-mysql-3f186.png)

新的分库分表规则如下：

分库规则dbRule:

```java
if(id < 2千万){
    //2千万之前的数据，4个表分别放到4个库
    if(id < 1千万){
        return "db"+  (id % 2);     //原t0表仍在db0, t1表仍在db1
    }else{
        return "db"+ ((id % 2) +2); //原t0_1表从db0搬迁到db2; t1_1表从db1搬迁到db3
    }
}else if(id < 4千万){
    return "db"+ (id % 4);          //超过2千万的数据，平均分到4个库
}else{
    throw new IllegalArgumentException("id out of range. id:"+id);
}
```

分表规则tbRule:

```java
if(id < 2千万){        //2千万之前的数据，表规则和原先完全一样，参见阶段二
    if(id < 1千万){
        return "t"+ (id % 2);       //1千万之前的数据，仍然放在t0和t1表
    }else{
        return "t"+ (id % 2) +"_1"; //1千万之后的数据，仍然放在t0_1和t1_1表
    }
}else if(id < 4千万){
    return "t"+ (id % 4)+"_2";      //超过2千万的数据分为4个表t0_2，t1_2，t2_2，t3_2
}else{
    throw new IllegalArgumentException("id out of range. id:"+id);
}
```

随着时间的推移，当第一阶段的`t0/t1`，第二阶段的`t0_1/t1_1`逐渐成为历史数据，不再使用时，可以直接`truncate`掉整个表。省去了历史数据迁移的麻烦。

分库分表规则的设计和配置，长远说来必须满足以下要求

- 可以动态推送修改
- **规则可以分层级叠加**，旧规则可以在新规则下继续使用，新规则是旧规则在更宽尺度上的拓展，以此支持新旧规则的兼容，避免数据迁移
- 用 `mod` 方式时，最好选 2 的指数级倍分库分表，这样方便以后切割。

#### 数据迁移  

在上述的水平扩容方案中，如何进行数据迁移，是在扩容中需要考虑的问题。一般情况下，数据迁移分为：停机迁移、双写迁移。

**停机迁移** 是最简单、最安全、最快速的迁移方案，但一般线上业务系统很少允许停机迁移。在停机迁移中，首先停掉数据库 A 的写入请求，复制 A 数据到 B，待复制完成后，切换线上数据源。

**双写迁移** 方案就是同时写两个库，一个是老库，一个是新库。也就是在线上系统里面，除了对所有老库的增删改地方，同时对新库同样执行增删改。主要经历以下三个阶段：

1. 导入历史数据，数据库双写（事务成功以老数据源为准），查询走老数据源，通过定时任务补全新老差异数据
2. 新老数据无差异，依旧双写（事务成功以新数据源为准），查询走新数据源
3. 稳定运行无误后，下线老数据源

#### Join  

在拆分之前，系统中很多列表和详情页所需的数据是可以通过 Join 来完成的。而拆分后，数据库可能是分布式在不同实例和不同的主机上，Join 将变得非常麻烦。首先要考虑下垂直分库的设计问题，如果可以调整，那就优先调整。如果无法调整的情况，可以考虑以下解决方案：

- **全局表**：就是有可能系统中所有模块都可能会依赖到的一些表。为了避免跨库 join 查询，我们可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心 *一致性* 问题；
- **字段冗余**：字段冗余能带来便利，是一种 *空间换时间* 的体现。但其适用场景也比较有限，比较适合依赖字段较少的情况。最复杂的还是数据一致性问题，这点很难保证；
- **系统层组装**：在系统层面，通过调用不同模块的组件或者服务，获取到数据并进行字段拼装；

### 主从复制  

MySQL 主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点。

- **Log Dump Thread**：当从节点连接主节点时，主节点会创建一个 log dump 线程，用于发送 bin-log 的内容。在读取 bin-log 中的操作时，此线程会对主节点上的 bin-log 加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。
- **I/O Thread**：当从节点上执行 `start slave` 命令之后，从节点会创建一个 I/O 线程用来连接主节点，请求主库中更新的 bin-log。I/O线程接收到主节点 binlog dump 进程发来的更新之后，保存在本地 relay-log 中。
- **SQL Thread**：负责读取 relay log 中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。

一个 slave 节点可同时从多个 master 进行数据复制，在这种情况下，不同 master 的 bin-log 存储在不同的 relay log中。

#### 同步模式  

**异步模式（mysql async-mode）**：MySQL增删改操作会全部记录在 binary log 中，当 slave 节点连接 master 时，会主动从 master 处获取最新的 bin log 文件。

**半同步模式(mysql semi-sync)**：这种模式下主节点只需要接收到其中一台从节点的返回信息，就会 `commit` ；否则需要等待直到超时时间然后切换成异步模式再提交；这样做的目的可以使主从数据库的数据延迟缩小，可以提高数据安全性，确保了事务提交后，binlog 至少传输到了一个从节点上，不能保证从节点将此事务更新到 db 中。性能上会有一定的降低，响应时间会变长。

**全同步模式** 是指主节点和从节点全部执行了commit并确认才会向客户端返回成功。

#### 主从复制的延迟问题  

进行主从同步的过程中，如果使用异步或半异步模式，均会有主从节点数据不一致的窗口时间。同时，从节点上的 `SQL Thread` 只能串行执行 `relay-log` 中的记录，当某条 DDL/DML 耗时较长时，会加剧这个窗口时间；再者在某些场景下会使用 slave 节点进行数据读取，这也可能导致数据加锁等待。基于以上原因在处理主从复制延迟问题上有以下几种方向：

1. 优化主从节点之间的网络延迟
2. 降低 master 负载，以减少 TPS
3. 降低 slave 负载，slave 只做备份使用，不提供服务
4. 调整 slave 参数：关闭 slave bin-log 等
5. 多线程的主从复制：不同 schema 下的表并发提交时的数据不会相互影响，即 slave 节点可以用对 relay log 中不同的 schema 各分配一个SQL Thread，来重放 relay log 中主库已经提交的事务

### 全局ID  

- 数据库自增 id
- 设置数据库 sequence 或者表自增字段步长
- UUID
- Snowflake 算法

#### Snowflake  

twitter 开源的分布式 id 生成算法，采用 `Scala` 语言实现，是把一个 `64` 位的 `long` 型的 `id` ，`1` 个 `bit` 是不用的，用其中的 `41` `bit` 作为毫秒数，用 `10` `bit` 作为工作机器 `id`，`12` `bit` 作为序列号。

```
|–1位符号位–|--41位时间戳–|--10位机器ID–|--12位序列号–|
```

- **1 bit**：不用，为啥呢？因为二进制里第一个 `bit` 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
- **41 bit**：表示的是时间戳，单位是毫秒。`41 bit` 可以表示的数字多达 `2^41 - 1`，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示`69`年的时间。
- **10 bit**：记录工作机器 `id`，代表的是这个服务最多可以部署在 `2^10`台机器上哪，也就是`1024`台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 `2^5`个机房（32个机房），每个机房里可以代表 `2^5` 个机器（32台机器）。
- **12 bit**：这个是用来记录同一个毫秒内产生的不同 id，`12 bit` 可以代表的最大正整数是 `2^12 - 1 = 4096`，也就是说可以用这个 `12 bit` 代表的数字来区分同一个毫秒内的 `4096` 个不同的 id。

##### Snowflake 的问题  

Snowflake 这样依赖时间的 ID 生成算法注定存在一个问题：**时间的准确度问题**。这一算法有一个默认前提：分布式环境下时间获取总是准确的，即时间总是递增的。而现实环境中，这样的条件很难满足。总会因为硬件、软件、人的原因造成时间变化。如果你的硬件时间本身就比正常时间快，而你接入了一个 NTP 服务，每当进行 NTP 时间校准时，你的机器时间总会向后 **回拨** 一段时间，这时悲剧就来了：有极大可能性生成重复ID。

针对上面提到的两个问题，可如下改进：

1. 时间戳由毫秒变为秒
2. 使用环形列表对时间戳对应的序列进行缓存
3. 使用 CAS 操作避免大粒度悲观锁

为了 **缓解** 时钟回拨问题，对之前的序列进行缓存，而原生算法很显然是不利于缓存的，最坏的情况下每秒需要缓存 1000 个值，这显然对内存很不友好。于是我将时间戳改为秒为单位，同时可以把省出来的位交给序列。此时缓存一个小时的数据（即可以容忍一个小时的时钟回拨）也就只需要缓存 3600 个序列，完全可以接受。改进后的 Snowflake 生成的ID是这样组成的：

```
|–1位符号位–|--32位时间戳–|--10位机器ID–|--21位序列号–|
```

> 环形列表：即整个列表的容量是一定的，当列表满了以后再加入的元素会按照入列的先后顺序覆盖之前的元素。



## Redis  

### 线程模型  

Redis 在处理网络请求是使用单线程模型，并通过 IO 多路复用来提高并发。但是在其他模块，比如：持久化，会使用多个线程。

Redis 内部使用文件事件处理器 `file event handler`，**这个文件事件处理器是单线程的，所以 `Redis` 才叫做单线程的模型**。它采用 IO 多路复用机制同时监听多个 `socket` ，将产生事件的 `socket` 压入内存队列中，事件分派器根据 `socket` 上的事件类型来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 `socket` 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 `IO` 多路复用程序会监听多个 `socket` ，会将产生事件的 `socket` 放入队列中排队，事件分派器每次从队列中取出一个 `socket` ，根据 `socket` 的事件类型交给对应的事件处理器进行处理。

客户端与 Redis 的一次通信过程：

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/f0dacdd3779b836ad75fe6b886af1fff.png)

#### 为啥 Redis 单线程模型也能效率这么高？  

- 纯内存操作
- 核心是基于非阻塞的 IO 多路复用机制
- 单线程反而避免了多线程的频繁上下文切换问题

### 持久化  

#### RDB  

RDB 持久化机制，是对 Redis 中的数据执行周期性的持久化。

- RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，**非常适合做冷备**
- RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。
- 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。
- 一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟的数据。
- RDB 每次在 `fork` 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。

#### AOF  

AOF 机制对每条写入命令作为日志，以 `append-only` 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集

- AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 `fsync` 操作，最多丢失 1 秒钟的数据。
- AOF 日志文件以 `append-only` 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。
- AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 **`rewrite log`** 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 `merge` 后的日志文件 `ready` 的时候，再交换新老日志文件即可。
- AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常 **适合做灾难性的误删除的紧急恢复**。比如某人不小心用 `flushall` 命令清空了所有数据，只要这个时候后台 `rewrite` 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 `flushall` 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。
- 对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。
- **AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低**，因为 AOF 一般会配置成每秒 `fsync` 一次日志文件，当然，每秒一次 `fsync` ，性能也还是很高的。（如果实时写入，那么 QPS 会大降，Redis 性能会大大降低）
- 以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。

#### RDB 和 AOF 到底该如何选择  

1. 不要仅仅使用 RDB，因为那样会导致你丢失很多数据；
2. 也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；
3. Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。

### 一致性哈希算法  

一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 `K/n` 个关键字重新映射，其中 `K` 是关键字的数量，`n` 是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。

> 一致哈希也可用于实现健壮缓存来减少大型 Web 应用中系统部分失效带来的负面影响

#### 需求  

在使用 `n` 台缓存服务器时，一种常用的负载均衡方式是，对资源 `o` 的请求使用 `hash(o)= o mod n` 来映射到某一台缓存服务器。当增加或减少一台缓存服务器时这种方式可能会改变所有资源对应的 `hash` 值，也就是所有的缓存都失效了，这会使得缓存服务器大量集中地向原始内容服务器更新缓存。

因此需要一致哈希算法来避免这样的问题。 一致哈希尽可能使同一个资源映射到同一台缓存服务器。这种方式要求增加一台缓存服务器时，新的服务器尽量分担存储其他所有服务器的缓存资源。减少一台缓存服务器时，其他所有服务器也可以尽量分担存储它的缓存资源。

一致哈希算法的主要思想是将每个缓存服务器与一个或多个哈希值域区间关联起来，其中区间边界通过计算缓存服务器对应的哈希值来决定。如果一个缓存服务器被移除，则它所对应的区间会被并入到邻近的区间，其他的缓存服务器不需要任何改变。

#### 实现  

一致哈希将每个对象映射到圆环边上的一个点，系统再将可用的节点机器映射到圆环的不同位置。查找某个对象对应的机器时，需要用一致哈希算法计算得到对象对应圆环边上位置，沿着圆环边上查找直到遇到某个节点机器，这台机器即为对象应该保存的位置。

当删除一台节点机器时，这台机器上保存的所有对象都要移动到下一台机器。添加一台机器到圆环边上某个点时，这个点的下一台机器需要将这个节点前对应的对象移动到新机器上。更改对象在节点机器上的分布可以通过调整节点机器的位置来实现。

### [实践](https://yikun.github.io/2016/06/09/一致性哈希算法的理解与实践/)  

> 假设有1000w个数据项，100个存储节点，请设计一种算法合理地将他们存储在这些节点上。

看一看普通Hash算法的原理：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/1c5e07626a9cadd5f1ea8acd85838067.png)

```
for item in range(ITEMS):
    k = md5(str(item)).digest()
    h = unpack_from(">I", k)[0]
    # 通过取余的方式进行映射
    n = h % NODES
    node_stat[n] += 1
```

普通的Hash算法均匀地将这些数据项打散到了这些节点上，并且分布最少和最多的存储节点数据项数目小于 `1%`。之所以分布均匀，主要是依赖 Hash 算法（实现使用的MD5算法）能够比较随机的分布。

然而，我们看看存在一个问题，由于 **该算法使用节点数取余的方法，强依赖 `node` 的数目**，因此，当是 `node` 数发生变化的时候，`item` 所对应的 `node` 发生剧烈变化，而发生变化的成本就是我们需要在 `node` 数发生变化的时候，数据需要迁移，这对存储产品来说显然是不能忍的。

##### 一致性哈希  

普通 `Hash` 算法的劣势，即当 `node` 数发生变化（增加、移除）后，数据项会被重新“打散”，导致大部分数据项不能落到原来的节点上，从而导致大量数据需要迁移。

那么，一个亟待解决的问题就变成了：当 `node` 数发生变化时，如何保证尽量少引起迁移呢？即当增加或者删除节点时，对于大多数 item ，保证原来分配到的某个 node ，现在仍然应该分配到那个 node ，将数据迁移量的降到最低。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/3de376ea57386b890483b27cf131f24d.png)

```
for n in range(NODES):
    h = _hash(n)
    ring.append(h)
    ring.sort()
    hash2node[h] = n
for item in range(ITEMS):
    h = _hash(item)
    n = bisect_left(ring, h) % NODES
    node_stat[hash2node[ring[n]]] += 1
```

**虽然一致性Hash算法解决了节点变化导致的数据迁移问题，但是，数据项分布的均匀性很差**。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/5e6b9afd23ff44415b434d05ed0449ce.png)

主要是因为这 100 个节点 Hash 后，在环上分布不均匀，导致了每个节点实际占据环上的区间大小不一造成的。

##### 改进 – 虚节点  

当我们将 node 进行哈希后，这些值并没有均匀地落在环上，因此，最终会导致，这些节点所管辖的范围并不均匀，最终导致了数据分布的不均匀。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/c807b7a0af060a874fdb27abf5caf289.png)

```
for n in range(NODES):
    for v in range(VNODES):
        h = _hash(str(n) + str(v))
        # 构造ring
        ring.append(h)
        # 记录hash所对应节点
        hash2node[h] = n
ring.sort()
for item in range(ITEMS):
    h = _hash(str(item))
    # 搜索ring上最近的hash
    n = bisect_left(ring, h) % (NODES*VNODES)
    node_stat[hash2node[ring[n]]] += 1
```

通过增加虚节点的方法，使得每个节点在环上所“管辖”更加均匀。这样就既保证了在节点变化时，尽可能小的影响数据分布的变化，而同时又保证了数据分布的均匀。也就是靠增加“节点数量”加强管辖区间的均匀。

### 集群  

#### 主从复制  

单机的 Redis ，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构做成 **主从(Master-Slave)架构** ，一主多从，主负责写，并且将数据复制到其它的 Slave 节点，从节点负责读。所有的读请求全部走从节点。这样也可以很轻松实现水平扩容，支撑读高并发。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/redis-master-slave.png)

Redis 默认采用异步方式复制数据到 Slave Node，同时 Slave Node 会周期性地确认自己每次复制的数据量：

1. 当 Master 和 Slave 网络连接顺畅时，Master 会持续向 Slave 推送命令，以保持在 Master 数据集合上执行的：客户端写、Key 过期、Key 淘汰等均在 Slave 数据集合上执行。
2. 当 Master 和 Slave 网络连接由于网络问题、超时等中断时， Slave 会尝试重连并进行连接断开期间的命令 **部分同步（partial resynchronization）**。
3. 当部分同步不可用时，Slave 会请求全量同步。在这个过程中，Master 会创建当前所有数据的镜像，发送给 Slave 并继续推送命令。

Redis 主从复制包含以下几个要点：

1. 一个 Master 可以有多个 Slave
2. Slave 支持级联结构，即 Slave 可以连接到其他 Slave 上
3. Redis 在复制过程中，不阻塞 Master ，不论是全量同步还是部分同步
4. 在大部分时间里，复制也不会阻塞 Slave 。当 Slave 在进行初始化同步时，Slave 会先使用旧的数据集提供服务。但当初始化同步完成时，会删除旧数据集，这时 Slave 会拒绝服务。
5. Redis 主从复制可以用来做水平扩容，以提供读写分离，或作为数据备份和高可用
6. 在主从复制的情况下，可以通过配置避免数据持久化，将 Slave 作为数据的备份或开启 Slave 的 AOF。但是这种情况下也会有风险：当 Master 重启后数据集将清空，这时如果 Slave 同步 Master 就会导致数据也被清空

##### 当 Master 不进行持久化如何保证数据安全  

在生产环境中，强烈建议开启 Redis 持久化，不论是在 Master 还是在 Slave。如果由于磁盘速度等问题，不能开启持久化，那么需要 **避免 Redis 进程的自动重启**。

#### 哨兵  

`Sentinel` 是 Redis 官方推荐的 **高可用性( `HA` )解决方案**，当用 Redis 做主从复制的高可用方案时，假如 Master 宕机了， Redis 本身都没有实现自动进行主备切换，而哨兵本身也是一个独立运行的进程，它能监控多个节点，发现 Master 宕机后能进行自动切换。

它的主要功能有以下几点

- 集群监控：负责监控 Redis Master 和 Slave 进程是否正常工作。
- 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
- 故障转移：如果 Master node 挂掉了，会自动转移到 Slave node 上。
- 配置中心：如果故障转移发生了，通知 client 客户端新的 Master 地址。

##### 哨兵的核心知识  

1. 哨兵至少需要 3 个实例，来保证自己的健壮性。
2. 哨兵 + Redis 主从的部署架构，是 **不保证数据零丢失** 的，只能保证 Redis 集群的高可用性。
3. 对于哨兵 + Redis 主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。
4. 哨兵的个数与集群节点个数无关，每个哨兵都会 Check 所有节点
5. 当启用哨兵后，客户端的连接是通过哨兵连接到 Node 的

哨兵集群必须部署 2 个以上节点，如果哨兵集群仅仅部署了 2 个哨兵实例，`Quorum` = 1。

```log
+----+         +----+
| M1 |---------| R1 |
| S1 |         | S2 |
+----+         +----+
```

如果 Master 宕机， `S1` 和 `S2` 中只要有 1 个哨兵认为 Master 宕机了，就可以进行切换，同时 `S1` 和 `S2` 会选举出一个哨兵来执行故障转移。但是同时这个时候，需要 `Majority` ，也就是超过半数的哨兵都是运行的。

如果此时仅仅是 `M1` 进程宕机了，哨兵 `s1` 正常运行，那么故障转移是 OK 的。但是如果是整个 `M1` 和 `S1` 运行的机器宕机了，那么哨兵只有 1 个，此时就没有 `Majority` 来允许执行故障转移，虽然另外一台机器上还有一个 R1，但是故障转移不会执行。

经典的 3 节点哨兵集群是这样的：

```log
       +----+
       | M1 |
       | S1 |
       +----+
          |
+----+    |    +----+
| R2 |----+----| R3 |
| S2 |         | S3 |
+----+         +----+
```

配置 `Quorum=2`，如果 `M1` 所在机器宕机了，那么三个哨兵还剩下 2 个， `S2` 和 `S3` 可以一致认为 Master 宕机了，然后选举出一个来执行故障转移，同时 3 个哨兵的 `Majority` 是 2，所以还剩下的 2 个哨兵运行着，就可以允许执行故障转移。

##### Slave 选主算法  

如果一个 Master 被认为宕机，而且 `Majority` 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 Slave 来，会考虑 Slave 的一些信息：

- 跟 Master 断开连接的时长
- Slave 优先级
- 复制 offset
- run id

接下来会对 Slave 进行排序：

- 按照 Slave 优先级进行排序，Slave Priority 越低，优先级就越高。
- 如果 Slave Priority 相同，那么看 Replica Offset，哪个 Slave 复制了越多的数据，Offset 越靠后，优先级就越高。
- 如果上面两个条件都相同，那么选择一个 run id 比较小的那个 Slave。

#### Redis Cluster  

Redis Cluster 是一种服务器 `Sharding` 技术，提供内置的高可用支持，部分 master 不可用时，还可以继续工作。Redis Cluster 功能强大，直接集成了 **主从复制** 和 **哨兵** 的功能。

- **高性能**：在 Cluster 集群中没有代理，主从之间使用异步复制，并且不会对 Key 进行合并操作；
- **可接受的写入安全**：当客户端连接到 majority master 时集群尽最大努力保留所有客户端的写操作。通常情况下，在一小段窗口时间内写请求会被丢失，当客户端连接到 minority master 时这个窗口时间会很大；
- **可用性**：当 Redis Cluster 中大部分 master 是可达的，并且不可达 master 均有一个可用的 slave 时，Redis Cluster 能够在 `NODE_TIMEOUT` 时间后进行故障转移，使 Cluster 重新可用。此外，Cluster 还提供 **副本迁移（replicas migration）**，当 master 没有 slave 时，可从其他 master 下重新分配一个 slave ；

> majority master：能与大多数 master 连通的 master minority master：未能与大多数 master 连通的 master

##### 内部节点通信  

在 Cluster 架构下，每个 Redis 都需要开启额外的端口来进行节点间通信，这种机制被称之为 **Cluster Bus**。

Redis 维护集群元数据采用 **gossip 协议**，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。

gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。

##### 寻址算法  

Redis Cluster 有固定的 16384 个 Hash Slot，对每个 key 计算 `CRC16` 值，然后对 `16384`取模，可以获取 key 对应的 Hash Slot。Redis Cluster 中**每个 Master 都会持有部分 Slot**，Slot 的分配在 Cluster 未进行重配置（reconfiguration）时是稳定的。当 Cluster 稳定时，一个 Hash Slot 只在一个 master 上提供服务。不过一个 master 会有一个或多个 slave ，以在发生网络分区或故障时，替换 master。这些 slave 还可以缓解 master 的读请求的压力。

> 重配置：Hash Slot 从一个节点转移到另一个节点

Keys hash tags 可以破坏上述的分配规则，Hash tags 是一种保证多个键被分配到同一个槽位的方法。

##### 重定向  

Redis Cluster 为了提高性能，不会提供代理，而是使用重定向的方式让 client 连接到正确的节点。

###### MOVED  

Redis 客户端可以向集群的任意一个节点发送查询请求，节点接收到请求后会对其进行解析，如果是操作单个 key 的命令或者是包含多个在相同槽位 key 的命令，那么该节点就会去查找这个 key 是属于哪个槽位的。如果 key 所属的槽位由该节点提供服务，那么就直接返回结果。否则就会返回一个 `MOVED` 错误：

```log
GET x
-MOVED 3999 127.0.0.1:6381
```

这个错误包括了对应的 key 属于哪个槽位（3999）以及该槽位所在的节点的 IP 地址和端口号。client 收到这个错误信息后，就将这些信息存储起来以便可以更准确的找到正确的节点。

当客户端收到 `MOVED` 错误后，可以使用 `CLUSTER NODES` 或 `CLUSTER SLOTS` 命令来更新整个集群的信息，因为当重定向发生时，很少会是单个槽位的变更，一般都会是多个槽位一起更新。因此，在收到 `MOVED` 错误时，客户端应该尽早更新集群的分布信息。当集群达到稳定状态时，客户端保存的槽位和节点的对应信息都是正确的，cluster 的性能也会达到非常高效的状态。

###### ASK  

对于 Redis Cluster 来讲， `MOVED` 重定向意味着请求的 slot 永久的由另一个节点提供服务，而 `ASK` 重定向仅代表将当前查询重定向到指定节点，不影响后续查询。在 Redis Cluster 迁移的时候会用到 ASK 重定向，下面看下 ASK 的处理流程：

1. Client 向节点 A 查询数据  `x`，A 发现数据 `x` 所在的 slot 状态为 `MIGRATING`，如果 `x` 存在则返回，否则返回 `ASK` 重定向；
2. Client 向 `ASK` 重定向节点 B 发送 `ASKING` ，再查询数据 `x`；
3. B 查找 `x` 发现其所在 slot 状态为 `IMPORTING`，则 B 会进行查询。若第二步未发送 `ASKING` ，则 B 会返回 `MOVED`命令，重定向到 A；

Redis Cluster 的迁移是以槽位单位的，一个槽位从节点 A 迁移到节点 B 需要经过以下步骤：

1. 节点 A 将待迁移 slot 设置为 `MIGRATING` 状态，将 B 节点 slot 设置为 `IMPORTING` 状态
2. A 获取 slot 中的 key，逐个调用 `MIGRATE` 命令
3. `MIGRATE` 会将特定的 key 从 A 迁移到 B，这个过程是原子操作（A、B均会进行加锁）

##### 容错能力  

Redis Cluster和大多数集群一样，是通过心跳来判断一个节点是否存活的。心跳包的内容可以分为 header 和 gossip 消息两部分，其中header包含以下信息：

- NODE ID 节点在集群中的唯一标识
- currentEpoch 和 configEpoch 字段
- node flag，标识节点是 master 还是 slave ，另外还有一些其他的标识位
- 节点提供服务的 hash slot 的 bitmap
- 发送者的 TCP 端口
- 发送者认为的集群状态（down or ok）
- 如果是slave，则包含 master 的 NODE ID

gossip包含了该节点认为的其他节点的状态，不过不是集群的全部节点。具体有以下信息：

- NODE ID
- 节点的IP和端口
- NODE flags

###### 故障检测  

故障检测用于识别集群中的不可达节点是否已下线，如果一个 master 下线，则会将它的 slave提 升为master。如果无法提升，则集群会处于错误状态。在 gossip 消息中，`NODE flags` 的值包括两种 PFAIL 和 FAIL。

如果一个节点发现另外一个节点不可达的时间超过 `NODE_TIMEOUT` ，则会将这个节点标记为 PFAIL，也就是 Possible failure。 PFAIL 标志只是一个节点本地的信息，为了使 slave 提升为 master ，需要将 PFAIL 升级为 FAIL 。当集群中大部分节点都将某个节点标记为 PFAIL 时，则可升级为 FAIL。

FAIL 状态是单向的，只能从 PFAIL 升级为 FAIL ，当节点重新可达时，可清除 FAIL 标记。

### 数据结构  

Redis 的数据结构包含两个层面，首先是 API 层面，即 Redis Client 操作的数据结构。另外就是 Redis 在实现 API 层面的数据结构使用的底层数据结构。

Redis API 层面的数据结构主要包括：`String`、`List`、`Set`、`Sorted Set`、`Hash`、`BitMap`，这些数据结构在 [Redis 官方文档](https://redis.io/topics/data-types-intro)中有详细介绍。

下面我们主要介绍 Redis 底层数据结构，包括 `SDS`、`dict`、`ziplist`、`quicklist`、`skiplist`。

#### SDS  

Redis 没有直接使用 C 语言传统的字符串表示（以空字符结尾的字符数组，以下简称 C 字符串）， 而是自己构建了一种名为 **简单动态字符串（simple dynamic string，SDS）**的抽象类型， 并将 SDS 用作 Redis 的默认字符串表示。

在 Redis 里面， C 字符串只会作为字符串字面量（string literal）， 用在一些无须对字符串值进行修改的地方， 比如打印日志。

当 Redis 需要的不仅仅是一个字符串字面量， 而是一个可以被修改的字符串值时， Redis 就会使用 SDS 来表示字符串值： 比如在 Redis 的数据库里面， 包含字符串值的键值对在底层都是由 SDS 实现的。

| C字符串                                          | SDS                                              |
| ------------------------------------------------ | ------------------------------------------------ |
| 获取字符串长度的复杂度为 O(N) 。                 | 获取字符串长度的复杂度为 O(1) 。                 |
| API 是不安全的，可能会造成缓冲区溢出。           | API 是安全的，不会造成缓冲区溢出。               |
| 修改字符串长度 N 次必然需要执行 N 次内存重分配。 | 修改字符串长度 N 次最多需要执行 N 次内存重分配。 |
| 只能保存文本数据。                               | 可以保存文本或者二进制数据。                     |
| 可以使用所有 <string.h> 库中的函数。             | 可以使用一部分 <string.h> 库中的函数。           |

##### 缓冲区溢出  

因为 C 字符串不记录自身的长度， 所以 `strcat` 假定用户在执行这个函数时， 已经为 `dest` 分配了足够多的内存， 可以容纳 `src` 字符串中的所有内容， 而一旦这个假定不成立时， 就会产生缓冲区溢出。

举个例子， 假设程序里有两个在内存中紧邻着的 C 字符串 `s1` 和 `s2` ， 其中 s1 保存了字符串 `"Redis"` ， 而 s2 则保存了字符串 `"MongoDB"` ， 如图所示。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/a9832e14ba184a4049f979e521ef050b.png)

如果一个程序员决定通过执行：

```
strcat(s1, " Cluster");
```

将 `s1` 的内容修改为 `"Redis Cluster"` ， 但粗心的他却忘了在执行 `strcat` 之前为 `s1`分配足够的空间， 那么在 `strcat` 函数执行之后， `s1` 的数据将溢出到 `s2` 所在的空间中， 导致 `s2` 保存的内容被意外地修改， 如图所示。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/cc9ac0419ae3f5059076c2d66f867931.png)

与 `C` 字符串不同， `SDS` 的空间分配策略完全杜绝了发生缓冲区溢出的可能性： **当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求**， 如果不满足的话， API 会自动将 `SDS` 的空间扩展至执行修改所需的大小， 然后才执行实际的修改操作， 所以使用 `SDS` 既不需要手动修改 `SDS` 的空间大小， 也不会出现前面所说的缓冲区溢出问题。

##### 减少修改字符串时带来的内存重分配次数  

- 空间预分配：解决 append 问题
- 惰性空间释放：解决 strim 问题

##### 二进制安全  

C 字符串中的字符必须符合某种编码（比如 `ASCII`）， 并且 **除了字符串的末尾之外， 字符串里面不能包含空字符**， 否则最先被程序读入的空字符将被误认为是字符串结尾 —— 这些限制使得 C 字符串只能保存文本数据， 而不能保存像图片、音频、视频、压缩文件这样的二进制数据。

#### dict  

在 Redis 中， dict 也是一个基于哈希表的算法。和传统的哈希算法类似，它采用哈希函数从 key 计算得到在哈希表中的位置，采用 **拉链法** 解决冲突，并在装载因子（load factor）超过预定值时自动扩展内存，引发重哈希（rehashing）。

Redis 的 dict 实现最显著的一个特点，就在于它的重哈希。它采用了一种称为 **增量式重哈希（incremental rehashing）** 的方法，在需要扩展内存时避免一次性对所有 key 进行重哈希，而是将重哈希操作分散到对于 dict 的各个增删改查的操作中去。这种方法能做到每次只对一小部分 key 进行重哈希，而每次重哈希之间不影响 dict 的操作。

> dict 之所以这样设计，是为了避免重哈希期间单个请求的响应时间剧烈增加。

为了实现增量式重哈希（incremental rehashing），dict的数据结构里包含 **两个哈希表**。在重哈希期间，数据从一个哈希表向另一个哈希表迁移。

#### ziplist  

ziplist 是一个经过特殊编码的 **双向链表**，它的设计目标就是为了提高存储效率。 ziplist 可以用于存储字符串或整数，其中整数是按真正的二进制表示进行编码的，而不是编码成字符串序列。它能以 O(1)*O*(1) 的时间复杂度在表的两端提供 `push` 和 `pop` 操作。

一个普通的双向链表，链表中每一项都占用独立的一块内存，各项之间用地址指针（或引用）连接起来。这种方式会带来大量的内存碎片，而且地址指针也会占用额外的内存。而 ziplist 却是将表中每一项存放在前后 **连续的地址空间** 内，一个 ziplist 整体占用一大块内存。它是一个表（list），但其实不是一个链表（linked list）。

另外，ziplist 为了在细节上节省内存，对于值的存储采用了 **变长编码方式**，大概意思是说，对于大的整数，就多用一些字节来存储，而对于小的整数，就少用一些字节来存储。ziplist 的底层结构如下所示：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/redis_ziplist_struct.png)

- **zlbytes**: 32bit，表示 ziplist 占用的字节总数。
- **zltail**: 32bit，表示 ziplist 表中最后一项（entry）在 ziplist 中的偏移字节数。
- **zllen**: 16bit， 表示 ziplist 中数据项（entry）的个数。 zllen 可以表达的最大值为 2^{16}-1216−1 。当 ziplist 长度超过 2^{16}-1216−1 时， zllen 不表示长度，长度需要进行遍历计算。
- **entry**: 表示真正存放数据的数据项，长度不定。一个数据项（entry）也有它自己的内部结构。
- **zlend**: ziplist 最后1个字节，是一个结束标记，值固定等于 255。

当ziplist变得很大的时候，它有如下几个缺点：

- 每次插入或修改引发的 realloc 操作会有更大的概率造成内存拷贝，从而降低性能。
- 一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。
- 当 ziplist 数据项过多的时候，在它上面查找指定的数据项就会性能变得很低，因为 ziplist 上的查找需要进行遍历。

总之， ziplist 本来就设计为各个数据项挨在一起组成连续的内存空间，这种结构并不擅长做修改操作。一旦数据发生改动，就会引发内存realloc，可能导致内存拷贝。

#### quicklist  

quicklist 是由 ziplist 为节点组成的双向链表。 ziplist 本身也是一个能维持数据项先后顺序的列表（按插入位置），而且是一个内存紧缩的列表（各个数据项在内存上前后相邻）。比如，一个包含 3 个节点的 quicklist ，如果每个节点的 ziplist 又包含 4 个数据项，那么对外表现上，这个 list 就总共包含 12 个数据项。

quicklist 的结构为什么这样设计呢？总结起来，大概又是一个空间和时间的折中：

- 双向链表便于在表的两端进行 push 和 pop 操作，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针；其次，双向链表的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。
- ziplist 由于是一整块连续内存，所以存储效率很高。但是 **不利于修改操作**，每次数据变动都会引发一次内存的 realloc （扩容）。特别是当 ziplist 长度很长的时候，一次 realloc 可能会导致大批量的数据拷贝，进一步降低性能。

quicklist 节点上的 ziplist 要保持一个合理的长度。那到底多长合理呢？这可能取决于具体应用场景。实际上，Redis提供了一个配置参数`list-max-ziplist-size` ，就是为了让使用者可以来根据自己的情况进行调整。

#### skiplist  

**跳跃表（skiplist）** 是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。

**Redis 只在两个地方用到了跳跃表， 一个是实现有序集合键， 另一个是在集群节点中用作内部数据结构**， 除此之外， 跳跃表在 Redis 里面没有其他用途。

#### intset  

intset 是一个由整数组成的 **有序集合**，从而便于在上面进行二分查找，用于快速地判断一个元素是否属于这个集合。它在内存分配上与 ziplist 有些类似，是连续的一整块内存空间，而且对于大整数和小整数（按绝对值）采取了不同的编码，尽量对内存的使用进行了优化。

对于小集合使用 intset 来存储，主要的原因是节省内存。特别是当存储的元素个数较少的时候， dict 所带来的内存开销要大得多（包含两个哈希表、链表指针以及大量的其它元数据）。所以，当存储大量的小集合而且集合元素都是数字的时候，用 intset 能节省下一笔可观的内存空间。

实际上，从时间复杂度上比较， intset 的平均情况是没有 dict 性能高的。以查找为例，intset 是 O(\lg^n)*O*(lg*n*) 的，而 dict 可以认为是 O(1)*O*(1) 的。但是，由于使用 intset 的时候集合元素个数比较少，所以这个影响不大。

#### API数据结构的实现  

| API数据结构 | 限制                     | 底层数据结构                          |
| ----------- | ------------------------ | ------------------------------------- |
| string      | 512 MB                   | SDS                                   |
| list        | 最大长度 2^{32}-1232−1   | quicklist                             |
| set         | 最大容量 2^{32}-1232−1   | - intset（小整数集） - dict           |
| sort set    | 最大容量 2^{32}-1232−1   | - ziplist（小集合） - dict + skiplist |
| hash        | 最大KV容量 2^{32}-1232−1 | - ziplist（小集合） - dict            |
| bitmap      | 512 MB                   | SDS                                   |

### 缓存穿透、缓存击穿、缓存雪崩  

#### 缓存穿透  

访问一个不存在的key，缓存不起作用，请求会穿透到 DB，流量大时 DB 会挂掉。

##### 解决方案  

- 采用布隆过滤器，使用一个足够大的`bitmap`，用于存储可能访问的 `key`，不存在的key直接被过滤；
- 访问key未在DB查询到值，也将空值写进缓存，但可以设置较短过期时间。

#### 缓存雪崩  

大量的 key 设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。

##### 解决方案  

可以给缓存设置过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。

#### 缓存击穿  

对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一 key 缓存，前者则是很多key。

缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端 DB 压垮。

##### 解决方案  

在缓存失效的时候（判断拿出来的值为空），不是立即去 `load db` ，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的 `SETNX`）去 `set` 一个 `mutex key` ，当操作返回成功时，再进行 `load db` 的操作并回设缓存；否则，就重试整个 `get` 缓存的方法。

### 数据淘汰机制  

#### 对象过期  

Redis回收过期对象的策略：定期删除+惰性删除

- **惰性删除**：当读/写一个已经过期的key时，会触发惰性删除策略，直接删除掉这个过期key
- **定期删除**：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key

#### 内存淘汰  

Redis提供了下面几种淘汰策略供用户选择，其中默认的策略为noeviction策略：

- `noeviction`：当内存使用达到阈值的时候，所有引起申请内存的命令会报错。
- `allkeys-lru`：在主键空间中，优先移除最近未使用的key。
- `volatile-lru`：在设置了过期时间的键空间中，优先移除最近未使用的key。
- `allkeys-random`：在主键空间中，随机移除某个key。
- `volatile-random`：在设置了过期时间的键空间中，随机移除某个key。
- `volatile-ttl`：在设置了过期时间的键空间中，具有更早过期时间的key优先移除。

> 这里补充一下主键空间和设置了过期时间的键空间，举个例子，假设我们有一批键存储在Redis中，则有那么一个哈希表用于存储这批键及其值，如果这批键中有一部分设置了过期时间，那么这批键还会被存储到另外一个哈希表中，这个哈希表中的值对应的是键被设置的过期时间。设置了过期时间的键空间为主键空间的子集。

##### 非精准的LRU  

上面提到的LRU（Least Recently Used）策略，实际上 **Redis 实现的 LRU 并不是可靠的 LRU**，也就是名义上我们使用LRU算法淘汰键，但是实际上被淘汰的键并不一定是真正的最久没用的，这里涉及到一个权衡的问题，如果需要在全部键空间内搜索最优解，则必然会增加系统的开销，Redis是单线程的，也就是同一个实例在每一个时刻只能服务于一个客户端，所以耗时的操作一定要谨慎。

为了在一定成本内实现相对的LRU，早期的 Redis 版本是 **基于采样的 LRU** ，也就是放弃全部键空间内搜索解改为采样空间搜索最优解。自从 Redis3.0 版本之后，Redis 作者对于基于采样的 LRU 进行了一些优化，目的是在一定的成本内让结果更靠近真实的 LRU。



## 密码学  

### 对称加密  

对称加密算法的加密和解密使用的密匙是相同的，也就是说如果通讯两方如果使用对称加密算法来加密通讯数据，那么通讯双方就需要都知道这个密匙，收到通讯数据后用这个密匙来解密数据。

这类算法在加密和解密时使用相同的密钥，或是使用两个可以简单地相互推算的密钥。事实上，这组密钥成为在两个或多个成员间的共同秘密，以便维持专属的通信联系。与非对称加密相比，要求双方获取相同的密钥是对称密钥加密的主要缺点之一。常见的对称加密算法有 `DES、3DES、AES、Blowfish、IDEA、RC5、RC6`。

**对称加密的速度比公钥加密快很多，在很多场合都需要对称加密**。

### 非对称加密  

它需要两个密钥，**一个是公开密钥，另一个是私有密钥；一个用作加密的时候，另一个则用作解密**。使用其中一个密钥把明文加密后所得的密文，只能用相对应的另一个密钥才能解密得到原本的明文；甚至连最初用来加密的密钥也不能用作解密。由于加密和解密需要两个不同的密钥，故被称为非对称加密；

虽然两个密钥在数学上相关，但如果知道了其中一个，并不能凭此计算出另外一个；因此其中一个可以公开，称为 **公钥**，任意向外发布；不公开的密钥为 **私钥** ，必须由用户自行严格秘密保管，绝不透过任何途径向任何人提供，也不会透露给要通信的另一方，即使他被信任。

> 公钥 & 私钥 均可以作为加密密钥

### 数字签名  

数字签名是一种类似写在纸上的签名，但是使用了 **公钥加密领域的技术实现** ，用于鉴别数字信息的方法。在网络上，我们可以使用“数字签名”来进行身份确认。数字签名是一个独一无二的数值，若公钥能通过验证，那我们就能确定对应的公钥的正确性，数字签名兼具这两种双重属性：“可确认性"及"不可否认性（不需要笔迹专家验证）"。

数字签名就是将公钥密码反过来使用。签名者将讯息用私钥加密（**这是一种反用，因为通常非对称加密中私钥用于解密**），然后公布公钥;验证者使用公钥将加密讯息解密并比对消息（一般签名对象为消息的散列值）。

### 密码散列函数  

密码散列函数（英语：`Cryptographic hash function`），又译为加密散列函数、密码散列函数、加密散列函数，是散列函数的一种。它被认为是一种 **单向函数**，也就是说极其难以由散列函数输出的结果，回推输入的数据是什么。这种散列函数的输入数据，通常被称为消息（ `message` ），而它的输出结果，经常被称为消息摘要（ `message digest` ）或摘要（ `digest` ）。



# JavaSE

## 面向对象基础  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/oop.gif)

面向对象三要素：封装、继承、多态

- `封装`：封装的意义，在于明确标识出允许外部使用的所有成员函数和数据项，或者叫接口。

- `继承`：
  - 继承基类的方法，并做出自己的扩展；
  - 声明某个子类兼容于某基类（或者说，接口上完全兼容于基类），外部调用者可无需关注其差别（内部机制会自动把请求派发`dispatch`到合适的逻辑）。

- `多态`：基于对象所属类的不同，外部对同一个方法的调用，实际执行的逻辑不同。**很显然，多态实际上是依附于继承的第二种含义的**。

### 多态  

方法签名：`方法名 + 参数列表(参数类型、个数、顺序)`

#### 重写  

子类重写父类方法，**只有实例方法可以被重写**，重写后的方法必须仍为实例方法。**成员变量和静态方法都不能被重写，只能被隐藏**。

重写实例方法：超类Parent中有实例方法A，子类child定义了与A **相同签名和子集返回类型**的实例方法B，子类对象ChildObj只能调用自己的实例方法B。

> 方法的重写（override）两同两小一大原则：

> 1. 方法名相同，参数类型相同

> 1. 子类返回类型小于等于父类方法返回类型

> 1. 子类抛出异常小于等于父类方法抛出异常

> 1. 子类访问权限大于等于父类方法访问权限

注意：

- 不能重写static静态方法。(形式上可以写，但本质上不是重写，属于下面要讲的隐藏)
- 重写方法可以改变其它的方法修饰符，如`final`,`synchronized`,`native`。不管被重写方法中有无final修饰的参数，重写方法都可以增加、保留、去掉这个参数的 final 修饰符(**参数修饰符不属于方法签名**)。

#### 重载  

在同一个类中，有多个方法名相同，参数列表不同（参数个数不同，参数类型不同），与方法的返回值无关，与权限修饰符无关。**编译器通过对方法签名的识别即可静态编译出不同的方法。这也是java中重载与重写的区别之一**。

> 重载只是一种语言特性，与多态无关，与面向对象也无关。**多态是为了实现接口重用**。

Java中方法是可以和类名同名的，和构造方法唯一的区别就是，**构造方法没有返回值**。

#### 隐藏  

隐藏与覆盖在形式上极其类似(语法规则)，但有着本质的区别：只有成员变量(不管是不是静态)和静态方法可以被隐藏。

##### 成员变量  

超类 Parent 中有成员变量 A ，子类 Child 定义了与 A 同名的成员变量 B ，子类对象 ChildObj 调用的是自己的成员变量 B。如果把子类对象 ChildObj 转换为超类对象 ParentObj ，ParentObj 调用的是超类的成员变量 A ！

1. 隐藏成员变量时，只要同名即可，可以更改变量类型(无论基本类型还是隐藏类型)
2. 不能隐藏超类中的 private 成员变量，换句话说，只能隐藏可以访问的成员变量。
3. 隐藏超类成员变量 A 时，可以降低或提高子类成员变量B的访问权限，只要A不是 private。
4. 隐藏成员变量与是否静态无关！静态变量可以隐藏实例变量，实例变量也可以隐藏静态变量。
5. 可以隐藏超类中的final成员变量。

##### 静态方法  

超类 Parent 有静态方法 A ，子类 Child 定义了与 A *相同签名和子集返回类型* 的静态方法 B ，子类对象 ChildObj 调用的是自己的静态方法 B 。如果把子类对象 ChildObj 转换为超类对象 ParentObj ，ParentObj 调用的是超类的静态方法 A ！

> 隐藏后的方法必须仍为静态方法



## 序列化  

### ProtoBuffer  

`Protocol Buffers` 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 `RPC` 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。

#### Protobuf 的优点  

- **Protobuf 更小、更快、也更简单**。你可以定义自己的数据结构，然后使用代码生成器生成的代码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构。只需使用 `Protobuf` 对数据结构进行一次描述，即可利用各种不同语言或从各种不同数据流中对你的结构化数据轻松读写。
- **“向后”兼容性好**，人们不必破坏已部署的、依靠“老”数据格式的程序就可以对数据结构进行升级。这样您的程序就可以不必担心因为消息结构的改变而造成的大规模的代码重构或者迁移的问题。因为添加新的消息中的 `field` 并不会引起已经发布的程序的任何改变。
- **Protobuf 语义更清晰**，无需类似 XML 解析器的东西（因为 `Protobuf` 编译器会将 `.proto` 文件编译生成对应的数据访问类以对 `Protobuf` 数据进行序列化、反序列化操作）。
- **Protobuf 的编程模式比较友好**，简单易学，同时它拥有良好的文档和示例，对于喜欢简单事物的人们而言，Protobuf 比其他的技术更加有吸引力。

#### Protobuf 的不足  

由于文本并不适合用来描述数据结构，所以 `Protobuf` 也不适合用来对基于文本的标记文档（如 HTML）建模。另外，由于 XML 具有某种程度上的自解释性，它可以被人直接读取编辑，在这一点上 `Protobuf` 不行，它以二进制的方式存储，除非你有 `.proto` 定义，否则你没法直接读出 `Protobuf` 的任何内容。



## 运算符优先级  

优先级从上到下依次递减，最上面具有最高的优先级，逗号操作符具有最低的优先级。

相同优先级中，按结合顺序计算。**大多数运算是从左至右计算，只有三个优先级是从右至左结合的，它们是单目运算符、条件运算符、赋值运算符**。

基本的优先级需要记住：

- 指针最优，单目运算优于双目运算。如正负号。
- 先乘除（模），后加减。
- 先算术运算，后移位运算，最后位运算。请特别注意：`1 << 3 + 2 & 7`等价于 `(1 << (3 + 2)) & 7`.
- 逻辑运算最后计算。

### 优先级表  

| 运算符                                  | 结合性   |
| --------------------------------------- | -------- |
| `[ ] . ( )` (方法调用)                  | 从左向右 |
| `! ~ ++ -- +`(一元运算) -(一元运算)     | 从右向左 |
| `* / %`                                 | 从左向右 |
| `+ -`                                   | 从左向右 |
| `<< >> >>>`                             | 从左向右 |
| `< <= > >= instanceof`                  | 从左向右 |
| `== !=`                                 | 从左向右 |
| `&`                                     | 从左向右 |
| `^`                                     | 从左向右 |
| `|`                                     | 从左向右 |
| `&&`                                    | 从左向右 |
| `||`                                    | 从左向右 |
| `?:`                                    | 从右向左 |
| `= += -= *= /= %= &= |= ^= <<= >>= >>=` | 从右向左 |
| `,`                                     | 从左到右 |

> 无符号右移运算符 `>>>`，无符号右移的规则只记住一点：**忽略了符号位扩展，0 补最高位**。无符号右移规则和右移运算是一样的，只是填充时不管左边的数字是正是负都用 0 来填充，无符号右移运算只针对负数计算，因为对于正数来说这种运算没有意义。无符号右移运算符 `>>>` 只是对 32 位和 64 位的值有意义



## Java异常  

Java中有Error和Exception，它们都是继承自Throwable类。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/error.png)

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/exception.png)

### 二者的不同之处  

Exception：

- 可以是可被控制(checked) 或不可控制的(unchecked)。
- 表示一个由程序员导致的错误。
- 应该在应用程序级被处理。

Error：

- 总是不可控制的(unchecked)。
- 经常用来用于表示系统错误或低层资源的错误。
- 如何可能的话，应该在系统级被捕捉。

### 异常的分类  

- **Checked exception**: 这类异常都是Exception的子类。异常的向上抛出机制进行处理，假如子类可能产生A异常，那么在父类中也必须throws A异常。可能导致的问题：代码效率低，耦合度过高。
- **Unchecked exception**: **这类异常都是RuntimeException的子类，虽然RuntimeException同样也是Exception的子类，但是它们是非凡的，它们不能通过client code来试图解决**，所以称为Unchecked exception 。



### 为什么使用泛型  

简而言之，泛型可以使类型（类和接口）在定义类、接口和方法时进行参数化。与在方法定义的形参类似，类型参数化能让不同的输入使用同一份代码。差别在于，形参传入的是值，而类型参数化传入的是类型。

在使用泛型相比于直接使用 `Object` 有以下几个好处：

1. **强制的类型检查**：Java 编译器会对泛型代码进行强制类型检查，如果违反类型安全则会抛出错误。在编译阶段解决类型错误，能更有效的减少 Bug
2. **消除类型强制转换**：如果不使用泛型，则在进行代码编写是需要手动进行类型转换
3. **允许程序员实现通用算法**：通过泛型，程序员能在不同类型的集合上实现通用算法

### 泛型类型  

泛型类型是指被参数化的类或接口，首先我们来看看一个简单的类：`Box`。其方法接收和返回的都是 `Object` 类型，因此可以除基本类型外的其他任何类型。这样也导致在编译期间不能进行任何校验。如果 `Box` 期望的是一个 `Integer` 类型，然而外部调用时，传入 `String`类型，这就会在程序运行时抛出异常。

```java
public class Box {
    private Object object;

    public void set(Object object) { this.object = object; }
    public Object get() { return object; }
}
```

下面我们来看看泛型类型版本的 `Box`：

```java
/**
 * Generic version of the Box class.
 * @param <T> the type of the value being boxed
 */
public class Box<T> {
    // T stands for "Type"
    private T t;

    public void set(T t) { this.t = t; }
    public T get() { return t; }
}
```

如上面代码所示，所有 `Object` 都被替换为了 `T`，`T` 是一个可以代表除基本类型外的所有类型：任意类、任意接口、任意数组类型甚至还可以是其他的类型参数（eg: `List<T>`）。

#### 原始类型  

原始类型是泛型类型没有类型参数的形式，例如上面的 `Box<T>` ，其原始类型就是 `Box`，但 **非泛型类类型不是原始类型**。原始类型的出现，只是为兼容 JDK5 之前的历史代码，比如：`Collections`。因此，将一个泛型类型赋值给原始类型是可以的：

```java
Box<String> stringBox = new Box<>();
Box rawBox = stringBox;               // OK
```

如果将原始类型赋值给泛型类型，编译器会报告一个警告：

```java
Box rawBox = new Box();           // rawBox is a raw type of Box<T>
Box<Integer> intBox = rawBox;     // warning: unchecked conversion
```

同样的，如果将一个原始类型参数传递给泛型方法，也会报告一个警告：

```java
Box<String> stringBox = new Box<>();
Box rawBox = stringBox;
rawBox.set(8);  // warning: unchecked invocation to set(T)
```

### 泛型方法  

泛型方法与泛型类型类似，只不过泛型方法拥有自己的参数化类型，并且其作用域只限制在声明的方法中。泛型方法可以是静态的、非静态以及构造函数。泛型方法的声明必须在返回参数之前，即：

```java
public class Util {
    public static <K, V> boolean compare(Pair<K, V> p1, Pair<K, V> p2) {
        return p1.getKey().equals(p2.getKey()) &&
               p1.getValue().equals(p2.getValue());
    }
}

public class Pair<K, V> {

    private K key;
    private V value;

    //泛型方法
    public Pair(K key, V value) {
        this.key = key;
        this.value = value;
    }

    //泛型方法
    public void setKey(K key) { this.key = key; }
    public void setValue(V value) { this.value = value; }
    public K getKey()   { return key; }
    public V getValue() { return value; }
}
```

### 有界类型参数  

当一个方法进行数字计算，并且想接收所有 `Number` 类型及其子类时，就需要用到有界类型参数。要声明一个有界类型参数，先列出该类型参数的名称，然后是 `extends` 关键字，然后是其上界，在这里是 `Number`。

> 在这里 `extends` 即可以表示 `extends`，也可以表示 `implements`。

```java
public <U extends Number> void inspect(U u){
    System.out.println("T: " + t.getClass().getName());
    System.out.println("U: " + u.getClass().getName());
}
```

在进行有界类型参数定义后，可使用在上界类型中定义的方法，在这里就可以调用 `Number`内的所有方法，例如：`intValue`。

#### 多上界  

前面的示例说明了使用带单个界限的类型参数，但是类型参数可以具有多个界限：

```java
<T extends B1 & B2 & B3>
```

有多个上界时，如果上界中包含类型（Class），则需要放在第一位。

### 泛型&继承&子类型  

如 Java 语言规范所描述，只要类型兼容，就可以将一种类型的对象分配给另一种类型的对象。例如：我们可以将 `Integer` 对象赋值给 `Object` ，因为 `Object` 是 `Integer` 的父类之一。

```java
Object someObject = new Object();
Integer someInteger = new Integer(10);
someObject = someInteger;   // OK
```

用面向对象的术语来说，这是一种 `is a` 的关系。因为，`Integer` 是一种 `Object` ，这样的赋值也是允许的。同时，`Integer` 也是一种 `Number` 所以以下代码均正确：

```java
public void someMethod(Number n) { /* ... */ }

someMethod(new Integer(10));   // OK
someMethod(new Double(10.1));   // OK
```

这种关系同样可以在泛型中使用：

```java
Box<Number> box = new Box<Number>();
box.add(new Integer(10));   // OK
box.add(new Double(10.1));  // OK
```

但是在泛型方法上会有所不同，比如以下方法：

```java
public void boxTest(Box<Number> n) { /* ... */ }
```

这个方法能够接收什么类型的参数呢？是否能够将 `Box<Integer>` 或者 `Box<Double>` 类型的对象传入呢？答案是 “否”，因为 `Box<Integer>` 和 `Box<Double>` 均不是 `Box<Number>`的子类型。

> 这是一个常见的误解

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/generics_method_type.png)

不论 `Integer` 和 `Number` 是什么关系，`Box<Integer>` 和 `Box<Number>` 的共同父类均是 `Object`。

#### 子类型  

可以通过 `extends` 或者 `implement` 创建泛型类型的子类型，他们之间的关系只依赖与被 `extends` 或者被 `implements`。我们可以看看 `Collections` 的相关类型，`ArrayList<E>`实现 `List<E>` 并且 `List<E>` 继承自 `Collection<E>`，所以，`ArrayList<String>` 是 `List<String>` 的子类型，`List<String>` 是 `Collection<String>` 的子类型。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/generics_subtype_1.png)

现在我们需要自己定义一个 list 接口：`PayloadList`，它拥有一个可选的泛型类型 `P`：

```java
interface PayloadList<E,P> extends List<E> {
  void setPayload(int index, P val);
  ...
}
```

以下所有的 `PayloadList` 都是 `List<String>` 的子类型:

```java
PayloadList<String,String>
PayloadList<String,Integer>
PayloadList<String,Exception>
```

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/generics_subtype_2.png)

### 通配符  

在泛型中，使用 `?` 做为通配符，代表未知类型。有界类型参数在上面已有介绍： `List<? extends Number>`。类似的，通配符可以没有上界，即 `List<?>`，这被称之为未知类型的List。这种未知类型的泛型在下面两个场景中很适用：

1. 泛型类型中只使用 Object 中声明的方法
2. 泛型类型中的代码不依赖与类型参数，例如：`List.size`、`List.clear`

另外，通配符还可声明类型参数的下界：`List<? super Integer>`。

#### 通配符&子类型  

当有了通配符后，泛型的继承关系又有新的规则。尽管 Integer 是 Number 的子类型，但 `List<Integer>` 不是 `List<Number>` 的子类型，实际上，这两种类型无关。 `List<Number>` 和 `List<Integer>` 的公共父类是 `List<?>`。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/generics_wildcards_subtype_1.png)

```java
List<? extends Integer> intList = new ArrayList<>();
List<? extends Number>  numList = intList;  // OK. List<? extends Integer> is a subtype of List<? extends Number>
```

因为 `Integer` 是 `Number` 的子类型，并且 `numList` 是 `Number` 对象的列表，所以 `intList` （一个 Integer 对象的列表）和 `numList` 之间存在关系。下图显示了使用上下界通配符声明的几个 List 类之间的关系。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/generics_wildcards_subtype_2.png)

### 类型擦除  

Java 语言引入了泛型，以在编译时提供更严格的类型检查并支持泛型编程。为实现泛型 Java 编译器会进行类型擦除：

1. 替换所有类型参数为他们的上界或者 `Object`，因此，字节码仅包含普通的类，接口和方法。
2. 必要时插入类型转换，以保持类型安全。
3. 生成桥接方法以在扩展的泛型类型中保留多态。

类型擦除可确保不会为参数化类型创建新的类；因此，泛型不会产生运行时开销。

#### 泛型类型的擦除  

在类型擦除过程中，Java 编译器将擦除所有类型参数，如果类型参数是有界的，则将每个参数替换为其第一个边界；如果类型参数是无界的，则将其替换为 `Object`。

```java
public class Node<T> {

    private T data;
    private Node<T> next;

    public Node(T data, Node<T> next) {
        this.data = data;
        this.next = next;
    }

    public T getData() { return data; }
    // ...
}
```

由于 `T` 是无界的，所以其类型擦除后的代码为：

```java
public class Node {

    private Object data;
    private Node next;

    public Node(Object data, Node next) {
        this.data = data;
        this.next = next;
    }

    public Object getData() { return data; }
    // ...
}
```

而对于以下代码的擦除又不一样：

```java
public class Node<T extends Comparable<T>> {

    private T data;
    private Node<T> next;

    public Node(T data, Node<T> next) {
        this.data = data;
        this.next = next;
    }

    public T getData() { return data; }
    // ...
}
```

擦除后：

```java
public class Node {

    private Comparable data;
    private Node next;

    public Node(Comparable data, Node next) {
        this.data = data;
        this.next = next;
    }

    public Comparable getData() { return data; }
    // ...
}
```

#### 泛型方法擦除  

泛型方法的擦除规则和泛型类型的擦除规则类似：

```java
// Counts the number of occurrences of elem in anArray.
public static <T> int count(T[] anArray, T elem) {
    int cnt = 0;
    for (T e : anArray)
        if (e.equals(elem))
            ++cnt;
        return cnt;
}
public static <T extends Shape> void draw(T shape) { /* ... */ }
```

擦除后：

```java
public static int count(Object[] anArray, Object elem) {
    int cnt = 0;
    for (Object e : anArray)
        if (e.equals(elem))
            ++cnt;
        return cnt;
}
public static void draw(Shape shape) { /* ... */ }
```

#### 桥接方法  

对于以下两个类：

```java
public class Node<T> {

    public T data;

    public Node(T data) { this.data = data; }

    public void setData(T data) {
        System.out.println("Node.setData");
        this.data = data;
    }
}

public class MyNode extends Node<Integer> {
    public MyNode(Integer data) { super(data); }

    public void setData(Integer data) {
        System.out.println("MyNode.setData");
        super.setData(data);
    }
}
```

类型擦除：

```java
public class Node {

    public Object data;

    public Node(Object data) { this.data = data; }

    public void setData(Object data) {
        System.out.println("Node.setData");
        this.data = data;
    }
}

public class MyNode extends Node {

    public MyNode(Integer data) { super(data); }

    public void setData(Integer data) {
        System.out.println("MyNode.setData");
        super.setData(data);
    }
}
```

在类型擦除后，方法的签名不匹配，导致重写的方法不生效，`Node.setData(T)` 变成了 `Node.setData(Object)`。为解决这个问题，Java 编译器在子类型中生成桥接方法，对于 `MyNode` 其生成的方法如下：

```java
class MyNode extends Node {

    // Bridge method generated by the compiler
    //
    public void setData(Object data) {
        setData((Integer) data);
    }

    public void setData(Integer data) {
        System.out.println("MyNode.setData");
        super.setData(data);
    }

    // ...
}
```

这样，在类型擦除之后，`MyNode` 具有与 `Node` 的 `setData(Object)` 方法相同的方法签名的桥接方法，并将其委托给的 `setData(Integer)` 方法。

#### 未擦除的泛型  

类型擦除只局限于 **泛型类型** 和 **泛型方法**，对于 `MyNode` 这种非泛型类型，泛型信息并不会擦除。在 `MyNode` 内同样可以通过反射获取到它父类的泛型信息。

```java
public static void main(String[] args) throws Exception {
  ParameterizedTypeImpl superclass = (ParameterizedTypeImpl) MyNode.class.getGenericSuperclass();
  System.out.println(Arrays.toString(superclass.getActualTypeArguments()));//[class java.lang.Integer]
}
```



## Object  

### getClass  

返回该对象运行时的 `class` 对象，返回的 `Class` 对象是由所表示的类的静态同步方法锁定的对象。

### hashCode  

返回该对象的 `hashcode`，该方法对hash表提供支持，例如 `HashMap`。 对于该方法有几点需要注意：

- 在运行中的Java应用，如果用在 `equals` 中进行比较的信息没有改变，那么不论何时调用都需要返回一致的int值。这个hash值在应用的两次执行中不需要保持一致。
- 如果两个对象根据 `equals` 方法认为是相等的，那么这两个对象也应该返回相等的 `hashcode`。
- 不要求两个不相等的对象，在调用 `hashCode` 方法返回的结果是必须是不同的。然而，程序员应该了解不同的对象产生不同的 `hashcode` 能够提升哈希表的效率。 Object的`hashcode`对不同的对象，尽可能返回不同的 `hashcode` 。这通常通过将对象的内部地址转换为整数来实现，但Java编程语言不需要此实现技术。

#### Arrays.hashCode  

Arrays.hashCode 是一个数组的浅哈希码实现，深哈希可以使用 `deepHashCode`。并且当数组长度为1时，`Arrays.hashCode(object) = object.hashCode` 不一定成立

#### 31  

不论是String、Arrays在计算多个元素的哈希值的时候，都会有31这个数字。主要有以下两个原因：

- 31是一个不大不小的质数，是作为 hashCode 乘子的优选质数之一。

  > 另外一些相近的质数，比如37、41、43等等，也都是不错的选择。那么为啥偏偏选中了31呢？请看第二个原因。

- 31可以被 JVM 优化， 31 * i = (i << 5) - i31∗*i*=(*i*<<5)−*i* 。

上面两个原因中，第一个需要解释一下，第二个比较简单，就不说了。一般在设计哈希算法时，会选择一个特殊的质数。至于为啥选择质数，我想应该是可以降低哈希算法的冲突率。

### equals  

判定两个对象是否相等。`equals`和`hashCode`需要同时被`overwrite`

### clone  

创建一个该对象的副本，并且对于对象 x 应当满足以下表达式：

```
x.clone() != x
x.clone().getClass() == x.getClass()
x.clone().equals(x)
```

### toString  

### wait  

当前线程等待知道其他线程调用该对象的 `notify` 或者 `notifyAll`方法。当前线程必须拥有该对象的 `monitor`。线程释放该对象`monitor`的拥有权，并且等待到别的线程通知等待在该对象`monitor`上的线程苏醒。然后线程重新拥有`monitor`并继续执行。在某些jdk版本中，中断和虚假唤醒是存在的，所以`wait`方法需要放在循环中。

```
synchronized (obj) {
    while (<condition does not hold>)
        obj.wait();
    ... // Perform action appropriate to condition
}
```

该方法只能被拥有该对象`monitor`的线程调用。

#### 虚假唤醒（spurious wakeup）  

虚假唤醒就是一些`obj.wait()`会在除了`obj.notify()`和`obj.notifyAll()`的其他情况被唤醒，而此时是不应该唤醒的。

> 注意 Lock 的 Conditon.await 也有虚假唤醒的问题

解决的办法是基于while来反复判断进入正常操作的临界条件是否满足

> 同时也可以使用同步数据结构：BlokingQueue

##### 解释  

虚假唤醒（`spurious wakeup`）是一个表象，即在多处理器的系统下发出 wait 的程序有可能在没有 notify 唤醒的情形下苏醒继续执行。

以运行在 Linux 的 hotspot 虚拟机上的 java 程序为例， `wait` 方法在 jvm 执行时实质是调用了底层 `pthread_cond_wait/pthread_cond_timedwait` 函数，挂起等待条件变量来达到线程间同步通信的效果，而底层 `wait` 函数在设计之初为了不减慢条件变量操作的效率并没有去保证每次唤醒都是由 `notify` 触发，而是把这个任务交由上层应用去实现，即使用者需要定义一个循环去判断是否条件真能满足程序继续运行的需求，当然这样的实现也可以避免因为设计缺陷导致程序异常唤醒的问题。

### notify  

唤醒一个等待在该对象`monitor`上的线程。如果有多个线程等待，则会随机选择一个线程唤醒。线程等待是通过调用`wait`方法。

唤醒的线程不会立即执行，直到当前线程放弃对象上的锁。唤醒的线程也会以通常的方式和竞争该对象锁的线程进行竞争。也就是说，唤醒的线程在对该对象的加锁中没有任何优先级。

该方法只能被拥有该对象`monitor`的线程调用。线程拥有`monitor`有下面三种方式：

- 执行该对象的 `synchronized` 方法
- 执行以该对象作为同步语句的`synchronized`方法体
- 对于class对象，可以执行该对象的`static synchronized`方法

在同一时间只能有一个线程能够拥有该对象`monitor`

### finalize  

当 GC 认为该对象已经没有任何引用的时候，该方法被GC收集器调用。子类可以 `overwrite` 该方法来关闭系统资源或者其他清理任务。

`finalize` 的一般契约是，如果 Java 虚拟机确定不再有任何方法可以通过任何尚未死亡的线程访问此对象，除非由于某个操作，它将被调用通过最终确定准备完成的其他一些对象或类来完成。 `finalize` 方法可以采取任何操作，包括使该对象再次可用于其他线程；但是，`finalize` 的通常目的是在对象被不可撤销地丢弃之前执行清理操作。例如，表示输入/输出连接的对象的 `finalize` 方法可能会执行显式 `I/O` 事务，以在永久丢弃对象之前断开连接。

类 Object 的 finalize 方法不执行任何特殊操作;它只是正常返回。 Object 的子类可以覆盖此定义。

Java 编程语言不保证哪个线程将为任何给定对象调用 `finalize` 方法。但是，可以保证，调用 finalize 时，调用 finalize 的线程不会持有任何用户可见的同步锁。如果 `finalize` 方法抛出未捕获的异常，则忽略该异常并终止该对象的终止。在为对象调用 `finalize` 方法之后，在 Java 虚拟机再次确定不再有任何方法可以通过任何尚未死亡的线程访问此对象之前，不会采取进一步操作，包括可能的操作通过准备完成的其他对象或类，此时可以丢弃该对象。

对于任何给定对象，Java 虚拟机永远不会多次调用 `finalize` 方法。 `finalize` 方法抛出的任何异常都会导致暂停此对象的终结，但会被忽略。

#### 缺陷  

- 一些与 `finalize` 相关的方法，由于一些致命的缺陷，已经被废弃了，如 `System.runFinalizersOnExit()` 方法、`Runtime.runFinalizersOnExit()`方法。
- `System.gc()` 与 `System.runFinalization()` 方法增加了finalize方法执行的机会，但不可盲目依赖它们。
- Java 语言规范并不保证 `finalize` 方法会被及时地执行、而且根本不会保证它们会被执行。
- `finalize` 方法可能会带来性能问题。因为JVM通常在单独的低优先级线程中完成finalize的执行。
- 对象再生问题： `finalize` 方法中，可将待回收对象赋值给GC Roots可达的对象引用，从而达到对象再生的目的。
- `finalize` 方法至多由GC执行一次(用户当然可以手动调用对象的 `finalize` 方法，但并不影响GC对 `finalize` 的行为)。



## StringBuilder  

`StringBuilder`类也封装了一个字符数组，定义如下：

```
    char[] value;
```

与`String`不同，它不是`final`的，可以修改。另外，与`String`不同，字符数组中不一定所有位置都已经被使用，它有一个实例变量，表示数组中已经使用的字符个数，定义如下：

```
    int count;
```

`StringBuilder`继承自`AbstractStringBuilder`，它的默认构造方法是：

```
    public StringBuilder() {
        super(16);
    }
```

调用父类的构造方法，父类对应的构造方法是：

```
    AbstractStringBuilder(int capacity) {
        value = new char[capacity];
    }
```

也就是说，`new StringBuilder()`这句代码，内部会创建一个长度为16的字符数组，count的默认值为0。

### append的实现  

```
    public AbstractStringBuilder append(String str) {
        if (str == null) str = "null";
        int len = str.length();
        ensureCapacityInternal(count + len);
        str.getChars(0, len, value, count);
        count += len;
        return this;
    }
```

`append`会直接拷贝字符到内部的字符数组中，如果字符数组长度不够，会进行扩展，实际使用的长度用`count`体现。具体来说，`ensureCapacityInternal(count+len)`会确保数组的长度足以容纳新添加的字符，`str.getChars`会拷贝新添加的字符到字符数组中，`count+=len`会增加实际使用的长度。

`ensureCapacityInternal`的代码如下：

```
    private void ensureCapacityInternal(int minimumCapacity) {

        if (minimumCapacity - value.length > 0)
            expandCapacity(minimumCapacity);
    }
```

如果字符数组的长度小于需要的长度，则调用`expandCapacity`进行扩展，`expandCapacity`的代码是：

```
    void expandCapacity(int minimumCapacity) {
        int newCapacity = value.length * 2 + 2;
        if (newCapacity - minimumCapacity < 0)
            newCapacity = minimumCapacity;
        if (newCapacity < 0) {
            if (minimumCapacity < 0)
                throw new OutOfMemoryError();
            newCapacity = Integer.MAX_VALUE;
        }
        value = Arrays.copyOf(value, newCapacity);
    }
```

扩展的逻辑是，分配一个足够长度的新数组，然后将原内容拷贝到这个新数组中，最后让内部的字符数组指向这个新数组，这个逻辑主要靠下面这句代码实现：

```
    value = Arrays.copyOf(value, newCapacity);
```

### toString实现  

字符串构建完后，我们来看toString代码：

```
    public String toString() {
        return new String(value, 0, count);
    }
```



## 代理  

### Java 代理  

我们常说的代理分为静态代理和动态代理。

- 静态代理：代码中显式指定代理
- 动态代理：类比静态代理，可以发现，代理类不需要实现原接口了，而是实现InvocationHandler。

#### 静态代理  

因为需要对一些函数进行二次处理，或是某些函数不让外界知道时，可以使用代理模式，通过访问第三方，间接访问原函数的方式，达到以上目的。

##### 弊端  

如果要想为多个类进行代理，则需要建立多个代理类，维护难度加大。

仔细想想，为什么静态代理会有这些问题，是因为代理在编译期就已经决定，如果代理发生在运行期，这些问题解决起来就比较简单，所以动态代理的存在就很有必要了。

#### 动态代理  

当动态生成的代理类调用方法时，会触发 `invoke` 方法，在 `invoke` 方法中可以对被代理类的方法进行增强。

```
// 1. 首先实现一个InvocationHandler，方法调用会被转发到该类的invoke()方法。
class LogInvocationHandler implements InvocationHandler{
    ...
    private Hello hello;
    public LogInvocationHandler(Hello hello) {
        this.hello = hello;
    }
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        if("sayHello".equals(method.getName())) {
            logger.info("You said: " + Arrays.toString(args));
        }
        return method.invoke(hello, args);
    }
}
// 2. 然后在需要使用Hello的时候，通过JDK动态代理获取Hello的代理对象。
Hello hello = (Hello)Proxy.newProxyInstance(
    getClass().getClassLoader(), // 1. 类加载器
    new Class<?>[] {Hello.class}, // 2. 代理需要实现的接口，可以有多个
    new LogInvocationHandler(new HelloImp()));// 3. 方法调用的实际处理者
System.out.println(hello.sayHello("I love you!"));
```

通过动态代理可以很明显的看到它的好处，在使用静态代理时，如果不同接口的某些类想使用代理模式来实现相同的功能，将要实现多个代理类，但在动态代理中，只需要一个代理类就好了。

除了省去了编写代理类的工作量，动态代理实现了可以在原始类和接口还未知的时候，就确定代理类的代理行为，当代理类与原始类脱离直接联系后，就可以很灵活地重用于不同的应用场景中。

- 继承了Proxy类，实现了代理的接口，由于java不能多继承，这里已经继承了Proxy类了，不能再继承其他的类，所以JDK的动态代理不支持对实现类的代理，只支持接口的代理。
- 提供了一个使用InvocationHandler作为参数的构造方法。
- 生成静态代码块来初始化接口中方法的Method对象，以及Object类的equals、hashCode、toString方法

##### 弊端  

代理类和委托类需要都实现同一个接口。也就是说只有实现了某个接口的类可以使用Java动态代理机制。但是，事实上使用中并不是遇到的所有类都会给你实现一个接口。因此，对于没有实现接口的类，就不能使用该机制。

#### 动态代理与静态代理的区别  

- Proxy类的代码被固定下来，不会因为业务的逐渐庞大而庞大；
- 代理对象是在程序运行时产生的，而不是编译期；
- 可以实现AOP编程，这是静态代理无法实现的；
- 解耦，如果用在web业务下，可以实现数据层和业务层的分离。
- 动态代理的优势就是实现无侵入式的代码扩展。
- 静态代理这个模式本身有个大问题，如果类方法数量越来越多的时候，代理类的代码量是十分庞大的。所以引入动态代理来解决此类问题

### [CGLib](http://blog.csdn.net/danchu/article/details/70238002)  

cglib 是针对类来实现代理的，他的 **原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对 final 修饰的类进行代理**。同样的，**final 方法是不能重载的**，所以也不能通过CGLIB代理，遇到这种情况不会抛异常，而是会跳过 `final`方法只代理其他方法。

CGLIB 代理主要通过对字节码的操作，为对象引入间接级别，以控制对象的访问。 CGLIB 底层使用了ASM（一个短小精悍的字节码操作框架）来操作字节码生成新的类。

### CGLIB和Java动态代理的区别  

- Java 动态代理只能够对接口进行代理，不能对普通的类进行代理（因为所有生成的代理类的父类为 Proxy，Java 类继承机制不允许多重继承）；CGLIB能够代理普通类；
- Java 动态代理使用 Java 原生的反射 API 进行操作，在生成类上比较高效；CGLIB 使用 ASM 框架直接对字节码进行操作，在类的执行过程中比较高效



## 注解  

注解(`Annotation`)是 Java1.5 中引入的一个重大修改之一，为我们在代码中添加信息提供了一种形式化的方法，使我们可以在稍后某个时刻非常方便的使用这些数据。注解在一定程度上是把元数据与源代码结合在一起，而不是保存在外部文档中。注解的含义可以理解为 java 中的元数据。元数据是描述数据的数据。

注解是一个继承自`java.lang.annotation.Annotation`的接口

### 可见性  

根据注解在程序不同时期的可见性，可以把注解区分为：

- `source`：注解会在编译期间被丢弃，不会编译到 class 文件
- `class`：注解会被编译到 class 文件中，但是在运行时不能获取
- `runtime`：注解会被编译到 class 文件中，并且能够在运行时通过反射获取

### 继承  

|                                        | 有@Inherited | 没有@Inherited |
| -------------------------------------- | ------------ | -------------- |
| 子类的类上能否继承到父类的类上的注解？ | 否           | 能             |
| 子类实现了父类上的抽象方法             | 否           | 否             |
| 子类继承了父类上的方法                 | 能           | 能             |
| 子类覆盖了父类上的方法                 | 否           | 否             |

`@Inherited` 只是可控制对类名上注解是否可以被继承。不能控制方法上的注解是否可以被继承。

### 注解的实现机制  

1. 注解是继承自：`java.lang.annotation.Annotation` 的接口

```
...
  Compiled from "TestAnnotation.java"
public interface TestAnnotation extends java.lang.annotation.Annotation
...
```

1. 注解内部的属性是在编译期间确定的

```
...
SourceFile: "SimpleTest.java"
RuntimeVisibleAnnotations:
  0: #43(#44=s#45)
...
```

1. 注解在运行时会生成 `Proxy` 代理类，并使用 `AnnotationInvocationHandler.memberValues` 来进行数据读取

```
...
default:
    //从 Map 中获取数据
    Object var6 = this.memberValues.get(var4);
    if (var6 == null) {
        throw new IncompleteAnnotationException(this.type, var4);
    } else if (var6 instanceof ExceptionProxy) {
        throw ((ExceptionProxy)var6).generateException();
    } else {
        if (var6.getClass().isArray() && Array.getLength(var6) != 0) {
            var6 = this.cloneArray(var6);
        }

        return var6;
    }
}
...
```



### NIO vs BIO  

`NIO`为所有的原始类型提供(Buffer)缓存支持，字符集编码解码解决方案。 提供多路(non-bloking) 非阻塞式的高伸缩性网络I/O 。

| IO     | NIO      |
| ------ | -------- |
| 面向流 | 面向缓冲 |
| 阻塞IO | 非阻塞IO |
| 无     | 选择器   |

### Channel  

Java NIO的通道类似流，但又有些不同：

1. 既可以从通道中读取数据，又可以写数据到通道。但流的读写通常是单向的。
2. 通道可以异步地读写。
3. 通道中的数据总是要先读到一个Buffer，或者总是要从一个Buffer中写入。

### Selector  

Selector（选择器）是Java NIO中能够检测一到多个NIO通道，并能够知晓通道是否为诸如读写事件做好准备的组件。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接。 Channel 可以向 Selector 注册监听四种不同类型的事件：

1. Connect
2. Accept
3. Read
4. Write

一旦向 Selector 注册了一或多个通道，就可以调用几个重载的 `select()` 方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣， `select()` 方法会返回读事件已经就绪的那些通道。

#### select 方法空转  

若 Selector 的轮询结果为空，也没有 wakeup 或新消息处理，则发生空轮询，CPU使用率 100%，Netty的解决办法：对 Selector 的 select 操作周期进行统计，每完成一次空的 select 操作进行一次计数。若在某个周期内连续发生N次空轮询，则触发了 epoll 死循环 bug 。**重建 Selector** 判断是否是其他线程发起的重建请求，若不是则将原 SocketChannel 从旧的 Selector 上去除注册，重新注册到新的 Selector 上，并将原来的 Selector 关闭。

### SelectionKey  

当向 Selector 注册 Channel 时，`Channel.register()` 方法会返回一个 SelectionKey 对象，这个对象代表了注册到该 Selector 和 Channel 的关联关系，并提供了一组方法来操作。当 Channel 注册的事件来到时，这个对象会在 `Selector.selectedKeys()` 中返回，直到 Channel 或者 Selector 被关闭。

1. isAcceptable
2. isReadable
3. channel
4. selector

```java
Set<SelectionKey> selectedKeys = selector.selectedKeys();
Iterator<SelectionKey> keyIterator = selectedKeys.iterator();
while(keyIterator.hasNext()) {
    SelectionKey key = keyIterator.next();
    if(key.isAcceptable()) {
        // a connection was accepted by a ServerSocketChannel.
    } else if (key.isConnectable()) {
        // a connection was established with a remote server.
    } else if (key.isReadable()) {
        // a channel is ready for reading
    } else if (key.isWritable()) {
        // a channel is ready for writing
    }
    keyIterator.remove();
}
```

注意每次迭代末尾的 `keyIterator.remove()` 调用。Selector 不会自己从已选择键集中移除 SelectionKey 实例。必须在处理完通道时自己移除。下次该通道变成就绪时， Selector 会再次将其放入已选择键集中。

### Buffer  

缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成 NIO Buffer 对象，并提供了一组方法，用来方便的访问该块内存。为了理解Buffer的工作原理，需要熟悉它的三个属性： `capacity` 、 `position` 、 `limit`。

`position` 和 `limit` 的含义取决于 Buffer 处在读模式还是写模式。不管 Buffer 处在什么模式， `capacity` 的含义总是一样的。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/buffers-modes.png)

**capacity**：作为一个内存块，Buffer有一个固定的大小值。你只能往里写 capacity 个byte、long，char等类型。一旦 Buffer 满了，需要将其清空（通过读数据或者清除数据）才能继续写数据往里写数据。

- `flip()`：方法将 Buffer **从写模式切换到读模式**。调用 `flip()` 方法会将 `position` 设回 0 ，并将 `limit` 设置成之前 `position` 的值。
- `clear()`： `position` 将被设回0， `limit` 被设置成 `capacity` 的值
- `compact()`：将所有未读的数据拷贝到 Buffer 起始处。然后将 `position` 设到最后一个未读元素正后面。 `limit` 属性依然像 `clear()` 方法一样，设置成 `capacity` 。
- `rewind()`：将 position 设回0，所以你可以重读 Buffer 中的所有数据，limit保持不变。

#### 堆内内存（HeapByteBuffer）  

HeapByteBuffer 是在 Java Heap 上分配的，但是Java NIO在读写到相应的 Channel 的时候，会先将 Java Heap 的 buffer 内容拷贝至直接内存 —— Direct Memory。这样的话，无疑 DirectByteBuffer 的 IO 性能肯定强于使用 HeapByteBuffer ，它省去了临时 buffer 的拷贝开销。

#### 堆外内存（DirectByteBuffer）  

DirectByteBuffer 底层的数据其实是维护在 JVM 堆外的用户空间中， DirectByteBuffer 里维护了一个引用 address 指向了数据，从而操作数据。虽然 GC 仍然管理着 DirectBuffer 的回收，但它是使用 `PhantomReference` 来达到的，在平常的 Young GC 或者 mark and compact 的时候却不会在内存里搬动。如果IO的数量比较大，比如在网络发送很大的文件，那么 GC 的压力下降就会很明显。**只有在 Full GC 以及调用 `System.gc` 的时候才会进行回收。**

DirectByteBuffer Java 堆内只会占用一个对象的指针引用的大小，堆外的的空间只有当 java 对象被回收时，才会被回收，这里会发现一个明显的不对称现象，就是堆外可能占用了很多，而堆内没占用多少，导致还没触发 GC ，那就很容易出现 Direct Memory 造成物理内存耗光。

### EchoNIOServer  

```java
@Slf4j
public class NIOServer {
  private static final ByteBuffer buffer = ByteBuffer.allocate(32);

  public static void main(String[] args) throws Exception {
    ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();
    serverSocketChannel.bind(new InetSocketAddress(8080));
    serverSocketChannel.configureBlocking(false);

    Selector selector = Selector.open();
    serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);

    while (true) {
      if (selector.select() == 0) {
        log.warn("selector.select() == 0");
        TimeUnit.MILLISECONDS.sleep(100);
        continue;
      }

      Iterator<SelectionKey> iterator = selector.selectedKeys().iterator();
      while (iterator.hasNext()) {
        SelectionKey selectedKey = iterator.next();
        if (selectedKey.isAcceptable()) {
          handleAccept(selectedKey);
        } else if (selectedKey.isReadable()) {
          handleRead(selectedKey);
        } else {
          log.warn("{}", selectedKey);
        }
        iterator.remove();
      }
    }
  }

  private static void handleRead(SelectionKey selectedKey) throws Exception {
    SocketChannel channel = (SocketChannel) selectedKey.channel();

    int readSize = channel.read(buffer);
    if (readSize == -1) {
      channel.close();
      return;
    }

    buffer.flip();
    byte[] readed = Arrays.copyOf(buffer.array(), readSize);
    log.info("from:{} read data:{}", channel, new String(readed));
    buffer.clear();

    buffer.put("echo:".getBytes());
    buffer.put(readed);
    buffer.flip();
    channel.write(buffer);
    buffer.compact();
  }

  private static void handleAccept(SelectionKey selectionKey) throws Exception {
    ServerSocketChannel serverSocketChannel = (ServerSocketChannel) selectionKey.channel();
    SocketChannel socketChannel = serverSocketChannel.accept();
    socketChannel.configureBlocking(false);
    socketChannel.register(selectionKey.selector(), SelectionKey.OP_READ);

    log.info("handleAccept from:{}", socketChannel);
  }
```



#### 面向对象的特征有哪些方面？  

- **抽象**：抽象是将一类对象的共同特征总结出来构造类的过程，包括数据抽象和行为抽象两方面。抽象只关注对象有哪些属性和行为，并不关注这些行为的细节是什么。
- **继承**：继承是从已有类得到继承信息创建新类的过程。继承让变化中的软件系统有了一定的延续性，同时继承也是封装程序中可变因素的重要手段。
- **封装**：通常认为封装是把数据和操作数据的方法绑定起来，对数据的访问只能通过已定义的接口。面向对象的本质就是将现实世界描绘成一系列完全自治、封闭的对象。
- **多态**：多态性是指允许不同子类型的对象对同一消息作出不同的响应。

#### 访问修饰符 `public` 、 `private` 、 `protected` 以及不写时的区别？  

类的成员不写访问修饰时默认为 `package`。默认对于同一个包中的其他类相当于公开（public），对于不是同一个包中的其他类相当于私有（private）。受保护（protected）对子类相当于公开，对不是同一包中的没有父子关系的类相当于私有。Java中，外部类的修饰符只能是 public 或默认，类的成员（包括内部类）的修饰符可以是以上四种。

#### String是最基本的数据类型吗？  

不是，Java中的基本数据类型只有8个：`byte`、`short`、`int`、`long`、`float`、`double`、`char`、`boolean`；除了基本类型（primitive type），剩下的都是引用类型（reference type），Java 5以后引入的枚举类型也算是一种比较特殊的引用类型。

#### `float f=3.4;`是否正确？  

不正确。3.4是双精度数，将双精度型（double）赋值给浮点型（float）属于下转型会造成精度损失，因此需要强制类型转换 `float f =(float)3.4;` 或者写成 `float f =3.4F;`。

#### `short s1 = 1; s1 = s1 + 1;`有错吗? `short s1 = 1; s1 += 1;` 有错吗？ 

对于 `short s1 = 1; s1 = s1 + 1;` 由于 1 是 int 类型，因此 `s1+1` 运算结果也是int 型，需要强制转换类型才能赋值给 short 型，编译不通过。

而 `short s1 = 1; s1 += 1;` 可以正确编译，因为 `s1+= 1;` 相当于 `s1 = (short)(s1 + 1);` 其中有隐含的强制类型转换。

#### Java有没有goto？  

goto 是Java中的保留字，但在目前版本的Java中没有使用。

#### int 和 Integer 有什么区别？  

Java为每一个基本数据类型都引入了对应的包装类型（wrapper class）， `int` 的包装类就是 `Integer` ，从 Java 5 开始引入了自动装箱/拆箱机制，使得二者可以相互转换。

```java
public static void main(String[] args) {
    Integer f1 = 100, f2 = 100, f3 = 150, f4 = 150;
    System.out.println(f1 == f2);//true
    System.out.println(f3 == f4);//false
}
```

当我们给一个 Integer 对象赋一个 int 值的时候，会调用 Integer 类的静态方法 `valueOf` ，如果看看 `valueOf` 的源代码就知道发生了什么。

```java
public static Integer valueOf(int i) {
    if (i >= IntegerCache.low && i <= IntegerCache.high)
        return IntegerCache.cache[i + (-IntegerCache.low)];
    return new Integer(i);
}
```

如果整型（byte、short、int、long）字面量的值在 `-128` 到 `127` 之间，那么不会 new 新的 Integer 对象，而是直接引用常量池中的 Integer 对象。

#### & 和 && 的区别？  

`&` 运算符有两种用法：按位与；逻辑与。`&&` 运算符是短路与运算。

逻辑与跟短路与的差别是非常巨大的，虽然二者都要求运算符左右两端的布尔值都是 `true`整个表达式的值才是 `true` 。 `&&` 之所以称为短路运算是因为，如果 `&&` 左边的表达式的值是 `false` ，右边的表达式会被直接短路掉，不会进行运算。

> 逻辑或运算符 `|` 和短路或运算符 `||` 的差别也是如此。

#### `Math.round(11.5)` 等于多少？`Math.round(-11.5)` 等于多少？  

`Math.round(11.5)` 的返回值是 `12` ，`Math.round(-11.5)` 的返回值是 `-11`。四舍五入的原理是在参数上加 `0.5` 然后进行下取整。

#### switch是否能作用在 byte 上，是否能作用在 long 上，是否能作用在 String 上？  

在 Java 5 以前， `switch(expr)` 中， `expr` 只能是 `byte` 、`short`、`char`、`int`；从 Java 5 开始，Java 中引入了枚举类型，`expr` 也可以是 enum 类型；从 Java 7 开始， `expr` 还可以是字符串 `String` ，但是长整型 `long` 在目前所有的版本中都是不可以的。

#### 用最有效率的方法计算 2 乘以 8 ？  

`2 << 3`（左移3位相当于乘以2的3次方，右移3位相当于除以2的3次方）。

#### 数组有没有 `length()` 方法？ `String` 有没有 `length()` 方法？  

数组没有 `length()` 方法，有length的属性。String有 `length()` 方法。

#### 在Java中，如何跳出当前的多重嵌套循环？  

在最外层循环前加一个标记如A，然后用break A;可以跳出多重循环。

#### 构造器（constructor）是否可被重写（override）？  

构造器不能被继承，因此不能被重写，但可以被重载。

#### 两个对象 `x.equals(y) == true`，但却可有不同的 `hash code` ？  

不对，如果两个对象 x 和 y 满足 `x.equals(y) == true`，它们的哈希码（hash code）应当相同

#### 重载（Overload）和重写（Override）的区别。重载的方法能否根据返回类型进行区分？  

方法的重载和重写都是实现多态的方式，区别在于 **重载是编译时的多态性**，而 **重写是运行时的多态性**。

重载发生在一个类中，**同名的方法如果有不同的参数列表**（参数类型不同、参数个数不同或者二者都不同）则视为重载。

重写发生在子类与父类之间，重写要求子类被重写方法与父类被重写方法有相同的返回类型（或子类型），不能比父类被重写方法声明更多的异常（里氏代换原则）。

#### char 型变量中能不能存贮一个中文汉字，为什么？  

char 类型可以存储一个中文汉字，因为 Java 中使用的编码是 Unicode （不选择任何特定的编码，直接使用字符在字符集中的编号，这是统一的唯一方法），**一个 char 类型占2个字节**，所以放一个中文是没问题的。

#### 抽象类（abstract class）和接口（interface）有什么异同？  

- 抽象类和接口都不能够实例化，但可以定义抽象类和接口类型的引用。
- 一个类如果继承了某个抽象类或者实现了某个接口都需要对其中的抽象方法全部进行实现，否则该类仍然需要被声明为抽象类。
- 接口比抽象类更加抽象，因为抽象类中可以定义构造器，可以有抽象方法和具体方法，而接口中不能定义构造器而且其中的方法全部都是抽象方法。
- 抽象类中的成员可以是 `private`、默认、 protected 、public的，而接口中的成员全都是public的
- 抽象类中可以定义成员变量，而接口中定义的成员变量实际上都是常量
- 有抽象方法的类必须被声明为抽象类，而抽象类未必要有抽象方法

#### 静态内部类（Static Nested Class）和内部类（Inner Class）的不同  

Static Nested Class是被声明为静态（static）的内部类，它可以不依赖于外部类实例被实例化。而通常的 **内部类需要在外部类实例化后才能实例化**：`new Outer().new Inner();`

#### 抽象的（abstract）方法是否可同时是静态的（static），是否可同时是本地方法（native），是否可同时被 synchronized 修饰？  

都不能。抽象方法需要子类重写，而静态的方法是无法被重写的，因此二者是矛盾的。

本地方法是由本地代码（如C代码）实现的方法，而抽象方法是没有实现的，也是矛盾的。

synchronized 和方法的实现细节有关，抽象方法不涉及实现细节，因此也是相互矛盾的。

#### 阐述静态变量和实例变量的区别  

静态变量是被static修饰符修饰的变量，也称为类变量，它属于类，不属于类的任何一个对象，一个类不管创建多少个对象，静态变量在内存中有且仅有一个拷贝；实例变量必须依存于某一实例，需要先创建对象然后通过对象才能访问到它。静态变量可以实现让多个对象共享内存。

#### 如何实现对象克隆？  

有两种方式：

1. 实现 `Cloneable` 接口并重写 Object 类中的 `clone()` 方法；
2. 实现 `Serializable` 接口，通过对象的序列化和反序列化实现克隆，可以实现真正的深度克隆。

#### `String s = new String("xyz");`创建了几个字符串对象？  

两个对象，一个是常量池的 `"xyz"` ，一个是用 `new` 创建在堆上的对象。

#### 接口是否可继承（extends）接口？抽象类是否可实现（implements）接口？抽象类是否可继承具体类（concrete class）？  

接口可以继承接口，而且支持多重继承。抽象类可以实现(implements)接口，抽象类可继承具体类也可以继承抽象类。

#### Error和Exception有什么区别？  

Error表示系统级的错误和程序不必处理的异常，是恢复不是不可能但很困难的情况下的一种严重问题；比如内存溢出，不可能指望程序能处理这样的情况；Exception表示需要捕捉或者需要程序进行处理的异常，是一种设计或实现问题；也就是说，它表示如果程序运行正常，从不会发生的情况。

#### 运行时异常与受检异常有何异同？  

运行时异常表示虚拟机的通常操作中可能遇到的异常，是一种常见运行错误，只要程序设计得没有问题通常就不会发生。

受检异常跟程序运行的上下文环境有关，即使程序设计无误，仍然可能因使用的问题而引发。

#### `try{}` 里有一个 `return` 语句，那么紧跟在这个 `try` 后的 `finally{}` 里的代码会不会被执行？如果 `finally{}` 里也进行了 `return` 最终返回的哪个值？  

```
finally` 会执行，在方法返回调用者前执行。如果 `finally{}` 里也进行了 `return` 最终返回 `finally` 里的 `return
```

#### List、Set、Map是否继承自Collection接口？  

List、Set 是，Map 不是。Map是键值对映射容器，与List和Set有明显的区别

#### Thread类的 `sleep()` 方法和对象的 `wait()` 方法都可以让线程暂停执行，它们有什么区别？  

`sleep()`方法是线程类（Thread）的静态方法，调用此方法会让当前线程暂停执行指定的时间，将执行机会（CPU）让给其他线程，但是对象的锁依然保持，因此休眠时间结束后会自动恢复。

`wait()`是Object类的方法，调用对象的 `wait()` 方法导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的 `notify()` 方法（或 `notifyAll()` 方法）时才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进入就绪状态。

#### 线程的 sleep() 方法和 yield() 方法有什么区别？  

1. `sleep()`方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；`yield()`方法只会给相同优先级或更高优先级的线程以运行的机会；
2. 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态；
3. `sleep()`方法声明抛出InterruptedException，而yield()方法没有声明任何异常；
4. `sleep()`方法比 yield() 方法（跟操作系统CPU调度相关）具有更好的可移植性。



# 集合框架

## [HashMap](https://yikun.github.io/2015/04/01/Java-HashMap工作原理及实现/)  

在get和put的过程中，计算下标时，先对hashCode进行hash操作，然后再通过hash值进一步计算下标，如下图所示：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2-HashMap-4d03d.png)

在对`hashCode()`计算hash时具体实现是这样的：

```
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

> 可以看到这个函数大概的作用就是：高16bit不变，低16bit和高16bit做了一个异或。

在设计hash函数时，因为目前的table长度n为2的幂，而计算下标的时候，是这样实现的(使用&位操作，而非%求余)。设计者认为这方法很容易发生碰撞。为什么这么说呢？不妨思考一下，在`n - 1`为`15(0x1111)`时，其实散列真正生效的只是低`4bit`的有效位，当然容易碰撞了。

因此，设计者想了一个顾全大局的方法(综合考虑了速度、作用、质量)，就是把高`16bit`和低`16bit`异或了一下。设计者还解释到因为现在大多数的 `hashCode` 的分布已经很不错了，就算是发生了碰撞也用`O(logn)`的tree去做了。仅仅异或一下，既减少了系统的开销，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。

如果还是产生了频繁的碰撞，会发生什么问题呢？作者注释说，他们使用树来处理频繁的碰撞(we use trees to handle large sets of collisions in bins)，在JEP-180中，描述了这个问题：

> Improve the performance of java.util.HashMap under high hash-collision conditions by using balanced trees rather than linked lists to store map entries. Implement the same improvement in the LinkedHashMap class.

之前已经提过，在获取HashMap的元素时，基本分两步：

- 首先根据 `hashCode()` 做 hash ，然后确定 bucket 的 index ；
- 如果 bucket 的节点的 key 不是我们需要的，则通过 `keys.equals()` 在链中找。

在Java 8之前的实现中是用链表解决冲突的，在产生碰撞的情况下，进行 get 时，两步的时间复杂度是 O(1)+O(n)*O*(1)+*O*(*n*) 。因此，当碰撞很厉害的时候n很大， O(n)*O*(*n*) 的速度显然是影响速度的。因此在Java 8中，如果一个 bucket 中碰撞冲突的元素超过某个限制(默认是8)，则使用红黑树来替换链表，这样复杂度就变成了 O(1)+O(logn)*O*(1)+*O*(*l**o**g**n*) 了，这样在 n 很大的时候，能够比较理想的解决这个问题。

### Resize  

当`put`时，如果发现目前的bucket占用程度已经超过了`Load Factor`所希望的比例，那么就会发生`resize`。在`resize`的过程，简单的说就是把`bucket`扩充为2倍，之后重新计算`index`，把节点再放到新的`bucket`中。`resize`的注释是这样描述的：

> Initializes or doubles table size. If null, allocates in accord with initial capacity target held in field threshold. Otherwise, because we are using power-of-two expansion, the elements from each bin must either stay at same index, or move with a power of two offset in the new table.

大致意思就是说，当超过限制的时候会`resize`，然而又因为我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。例如我们从16扩展为32时，具体的变化如下所示：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2-HashMap-7bdc9.png)

因此元素在重新计算 hash 之后，因为n变为2倍，那么 n-1 的 mask 范围在高位多1bit(红色)，因此新的index就会发生这样的变化：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2-HashMap-03719.png)

因此，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“`原索引+oldCap`”。可以看看下图为16扩充为32的resize示意图：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2-HashMap-4fb68.png)

这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。

### 并发问题  

[疫苗：JAVA HASHMAP的死循环](https://coolshell.cn/articles/9606.html)

在 `HashMap` 并发进行 Resize 的过程中会出现环形链表，导致 `get()` 操作死循环。

## [ConcurrentHashmap](https://crossoverjie.top/2018/07/23/java-senior/ConcurrentHashMap/)  

### JDK1.7  

`ConcurrentHashMap` 的锁分段技术：假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是 `ConcurrentHashMap` 所使用的锁分段技术。首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。

`ConcurrentHashMap` 不允许 `Key` 或者 `Value` 的值为 `NULL`，主要原因是：如果 `map.get(key)` 返回 `null` ，则无法检测 key 是否显式映射为 `null` 或者 key 未映射。 在非并发映射中，您可以通过 `map.contains(key)` 进行检查，但在并发映射中，映射可能在调用之间发生了变化。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/ConcurrentHashMap.png)

### JDK1.8  

在JDK1.8中对 ConcurrentHashmap 进行了改进。取消`segments`字段，直接采用`transient volatile HashEntry<K,V>[] table`保存数据，**采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率**。

将原先 **table数组＋单向链表** 的数据结构，变更为 **table数组＋单向链表＋红黑树** 的结构。对于 hash 表来说，最核心的能力在于将 key hash 之后能均匀的分布在数组中。如果 hash 之后散列的很均匀，那么 table 数组中的每个队列长度主要为 0 或者 1 。但实际情况并非总是如此理想，虽然 `ConcurrentHashMap` 类默认的加载因子为 `0.75`，但是在数据量过大或者运气不佳的情况下，还是会存在一些队列长度过长的情况，如果还是采用单向列表方式，那么查询某个节点的时间复杂度为 O(n)*O*(*n*) ；因此，对于个数超过 8 (默认值)的链表，jdk1.8 中采用了红黑树的结构，那么查询的时间复杂度可以降低到 O(logN)*O*(*l**o**g**N*) ，可以改进性能。

#### PUT  

```
final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 得到 hash 值
    int hash = spread(key.hashCode());
    // 用于记录相应链表的长度
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        // 如果数组"空"，进行数组初始化
        if (tab == null || (n = tab.length) == 0)
            // 初始化数组，后面会详细介绍
            tab = initTable();

        // 找该 hash 值对应的数组下标，得到第一个节点 f
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 如果数组该位置为空，
            //    用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了
            //          如果 CAS 失败，那就是有并发操作，进到下一个循环就好了
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;                   // no lock when adding to empty bin
        }
        // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容
        else if ((fh = f.hash) == MOVED)
            // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了
            tab = helpTransfer(tab, f);

        else { // 到这里就是说，f 是该位置的头结点，而且不为空

            V oldVal = null;
            // 获取数组该位置的头结点的监视器锁
            synchronized (f) {
                if (tabAt(tab, i) == f) {
                    if (fh >= 0) { // 头结点的 hash 值大于 0，说明是链表
                        // 用于累加，记录链表的长度
                        binCount = 1;
                        // 遍历链表
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            // 如果发现了"相等"的 key，判断是否要进行值覆盖，然后也就可以 break 了
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            // 到了链表的最末端，将这个新值放到链表的最后面
                            Node<K,V> pred = e;
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    else if (f instanceof TreeBin) { // 红黑树
                        Node<K,V> p;
                        binCount = 2;
                        // 调用红黑树的插值方法插入新节点
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                       value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
            }

            if (binCount != 0) {
                // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8
                if (binCount >= TREEIFY_THRESHOLD)
                    // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换，
                    // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树
                    //    具体源码我们就不看了，扩容部分后面说
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    addCount(1L, binCount);
    return null;
}
```

#### GET  

get 不进行加锁，其只需要保证可见性，所以 `volatile` 就可以。

- 计算 hash 值
- 根据 hash 值找到数组对应位置: `(n - 1) & h`
- 根据该位置处结点性质进行相应查找
  - 如果该位置为 null ，那么直接返回 null 就可以了
  - 如果该位置处的节点刚好就是我们需要的，返回该节点的值即可
  - 如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树，后面我们再介绍 find 方法
  - 如果以上 3 条都不满足，那就是链表，进行遍历比对即可



## BlockingQueue  

`BlockingQueue` 支持当获取队列元素但是队列为空时，会阻塞等待队列中有元素再返回；也支持添加元素时，如果队列已满，那么等到队列可以放入新元素时再放入。

其提供了4种类型的方法：

|         | *Throws exception* | *Special value* | *Blocks*         | *Times out*          |
| ------- | ------------------ | --------------- | ---------------- | -------------------- |
| Insert  | add(e)             | offer(e)        | put(e)           | offer(e, time, unit) |
| Remove  | remove()           | poll()          | take()           | poll(time, unit)     |
| Examine | element()          | peek()          | *not applicable* | *not applicable*     |

`BlockingQueue`不接受 `null` 元素。所有实现应当抛出 `NullPointerException` 在所有的 `add`,`put`以及`offer`方法上。`null`被用来标记`poll`失败。

在任意时刻，当有界`BlockingQueue` 队列元素放满之后，所有的元素都将在放入的时候阻塞。无界`BlockingQueue` 没有任何容量限制，容量大小始终是`Integer.MAX_VALUE`。

`BlockingQueue`的实现是用于 `生产者-消费者` 的队列，同时也支持 `Collection` 接口。所以可通过`remove(x)`来移除队列里的一个元素。通常情况下，这样的操作效率不是很好，只在诸如队列消息被取消的情况下才会偶尔使用。

`BlockingQueue` 的实现都是线程安全的。所有 `queue` 的方法都需要通过内部锁机制或者其他形式来进行并发控制来实现其原子操作。然而，`Collection` 接口的方法，比如：**`addAll, containsAll, retainAll` 以及 `removeAll` 都没有必要进行原子操作**，除非实现类有特别说明。所以对于`addAll(c)`有可能在添加部分`c`元素后抛出异常。

`BlockingQueue` 本质上不支持任何的 `close` 或者 `shutdown` 操作，来表明不会有新的元素添加。如果需要这些特性，得实现类来支持。

### ArrayBlockingQueue  

`ArrayBlockingQueue` 是底层由数组存储的有界队列。遵循FIFO，所以在队首的元素是在队列中等待时间最长的，而在队尾的则是最短时间的元素。新元素被插入到队尾，队列的取出 操作队首元素。

这是一个经典的有界缓存，由一个长度确定的数组持有所有由生产者插入、由消费者取出的元素。一旦创建，整个队列的容量将不会改变。尝试向一个已满的队列 `put` 将会导致调用被阻塞，同样的向一个空队列 `take` 也会阻塞。

该队列支持队等待的生产者和消费者实施可选的公平策略。默认情况下，是非公平策略。可以通过构造函数来指定是否进行公平策略。一般情况下公平策略会减小吞吐量，但是也会降低可变性以及防止饥饿效应。

#### 实现  

`ArrayBlockingQueue` 内部使用了 `ReentrantLock` 以及两个 `Condition` 来实现。

```
/** Main lock guarding all access */
final ReentrantLock lock;
/** Condition for waiting takes */
private final Condition notEmpty;
/** Condition for waiting puts */
private final Condition notFull;
```

`PUT` 方法也很简单，就是 `Condition` 的应用。

```
public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
      //队列已满，wait 在 condition 上
        while (count == items.length)
            notFull.await();
        enqueue(e);
    } finally {
        lock.unlock();
    }
}
```

`take` 方法也同样的。

```
public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
      //队列为空，wait 在 condition 上
        while (count == 0)
            notEmpty.await();
        return dequeue();
    } finally {
        lock.unlock();
    }
}
```



# 并发

## Java线程  

### 线程定义  

**线程（Thread）是操作系统能够进行运算调度的最小单位**。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。

线程是独立调度和分派的基本单位。线程可以操作系统内核调度的内核线程，如Win32线程；由用户进程自行调度的用户线程，如Linux平台的`POSIX Thread`；或者由内核与用户进程，如Windows 7的线程，进行混合调度。

同一进程中的多条线程将共享该进程中的全部系统资源，如虚拟地址空间，文件描述符和信号处理等等。但同一进程中的多个线程有各自的调用栈（`call stack`），自己的寄存器环境（`register context`），自己的线程本地存储（`thread-local storage`）。

### 线程实现  

Java中的线程都是调用的原生系统的本地函数，Java线程模型是基于操作系统原生线程模型实现的，实现线程有三种方式：内核线程实现、用户线程实现、混合线程实现。

#### 内核线程实现  

直接由操作系统内核支持的线程，通过内核来完成进程切换。每个内核线程就是一个内核的分身，这样操作系统就可以同时处理多件事情，支持多线程的内核被称为多线程内核。

程序一般不直接使用内核线程，而是使用一种高级接口——轻量级进程，轻量级进程就是我们通常意义上的线程，可以获得内核线程的支持，与内核线程构成`1:1`的线程模型。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/kernel_thread.jpg)

由于得到内核线程的支持，每个轻量级进程都成为一个独立的调度单元，即时有一个轻量级进程在系统调用中阻塞，也不会影响整个进程，但也有其局限性：由于是基于内核线程实现的，各种操作，如创建、销毁及同步，都需要进行系统调用。而系统调用代价较高，需要在内核态和用户态来回切换。

#### 用户线程实现  

从广义上说，一个线程不是内核线程，就是用户线程，所以轻量级进程也属于用户线程。狭义的用户线程是指完全建立在用户空间上的，系统内核不能感知到其存在。

用户线程的创建、同步、销毁和调度都是在用户空间实现的，因此相对较快，代价相对较低。这种用户线程和进程是`N:1`的线程模型。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/user_thread.jpg)

由于用户线程没有内核的支持，线程的创建、切换和调度是需要自己实现的，而且由于操作系统只把CPU资源分配到进程，那诸如“阻塞如何处理”、“多处理器系统中如何将线程映射到其他处理器”这类问题解决起来异常复杂。

#### 混合实现  

这种实现模式将内核线程与用户线程一起使用，在这种方式下既存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间，因此用户线程的创建、切换等操作依旧低廉。而操作系统提供的轻量级进程则作为用户线程和内核线程的桥梁，这样就可以使用内核提供的线程调度及处理器映射。这种实现下，用户线程和轻量级进程是`M:N`的模式。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/mix_thread.jpg)

### Java线程调度  

线程调度分为协同式和抢占式。

- `协同式调度`：线程的执行时间由线程自己控制，这种的实现很简单，但是很可能造成很严重的后果。
- `抢占式调度`：由操作系统分配线程执行的时间，线程切换的决定权在操作系统。

有时候我们需要为某些线程多分配时间，这时我们就需要用到线程优先级的方法，Java提供了10种优先级。Java优先级是在操作系统的原生线程优先级上实现的，所以对于同一个优先级，不同的操作系统可能有不同的表现，也就是说 **Java线程优先级不是可靠的**。

### Java线程状态切换  

Java线程模型定义了 6 种状态，在任意一个时间点，一个线程有且只有其中一个状态：

- `新建（New）`：新建的Thread，尚未开始。
- `运行（Runable）`：包含操作系统线程状态中的Running、Ready，也就是处于正在执行或正在等待CPU分配时间的状态。
- `无限期等待（Waiting）`：处于这种状态的线程不会被分配CPU时间，等待其他线程唤醒。
- `限期等待（Timed Waiting）`：处于这种状态的线程不会被分配CPU时间，在一定时间后会由系统自动唤醒。
- `阻塞（Blocked）`：在等待获得排他锁。
- `结束（Terminated）`：已终止的线程。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/thread_status.jpg)

### 线程安全  

多线程访问同一代码，不会产生不确定的结果。

### Java 线程池  

线程池提供了一种限制和管理资源（包括执行一个任务）。 每个线程池还维护一些基本统计信息，例如已完成任务的数量。使用线程池的好处：

- **降低资源消耗**：通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**：当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- **提高线程的可管理性**：线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

在创建线程池时不允许使用 `Executors` 去创建，而是通过 `ThreadPoolExecutor` 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。`Executors`返回线程池对象的弊端如下：

- **FixedThreadPool** 和 **SingleThreadExecutor** ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。
- **CachedThreadPool** 和 **ScheduledThreadPool** ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。

`ThreadPoolExecutor` 构造函数重要参数：

- **corePoolSize** : 核心线程数线程数定义了最小可以同时运行的线程数量。
- **maximumPoolSize** : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- **workQueue**: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
- **keepAliveTime**：当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁；
- **unit** ：keepAliveTime 参数的时间单位。
- **threadFactory** ：executor 创建新线程的时候会用到。
- **handler** ：饱和策略。

#### 线程池提交任务  

为了搞懂线程池的原理，我们需要首先分析一下 `execute` 方法。我们使用 `executor.execute(worker)` 来提交一个任务到线程池中去，这个方法非常重要，下面我们来看看它的源码：

```java
   // 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)
   private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));

    private static int workerCountOf(int c) {
        return c & CAPACITY;
    }

    private final BlockingQueue<Runnable> workQueue;

    public void execute(Runnable command) {
        // 如果任务为null，则抛出异常。
        if (command == null)
            throw new NullPointerException();
        // ctl 中保存的线程池当前的一些状态信息
        int c = ctl.get();

        //  下面会涉及到 3 步 操作
        // 1.首先判断当前线程池中之行的任务数量是否小于 corePoolSize
        // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。
        if (workerCountOf(c) < corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        // 2.如果当前之行的任务数量大于等于 corePoolSize 的时候就会走到这里
        // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态才会被并且队列可以加入任务，该任务才会被加入进去
        if (isRunning(c) && workQueue.offer(command)) {
            int recheck = ctl.get();
            // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。
            if (!isRunning(recheck) && remove(command))
                reject(command);
                // 如果当前线程池为空就新创建一个线程并执行。
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
        //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。
        //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。
        else if (!addWorker(command, false))
            reject(command);
    }
```

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/thread_pool_commit_task.png)



## [Volatile原理](http://www.cnblogs.com/dolphin0520/p/3920373.html)  

### 计算机内存模型  

计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。**当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中**。举个简单的例子，比如下面的这段代码：

```
i = i + 1;
```

> 当线程执行这个语句时，会先从主存当中读取`i`的值，然后复制一份到高速缓存当中，然后 CPU 执行指令对`i`进行加1操作，然后将数据写入高速缓存，最后将高速缓存中`i`最新的值刷新到主存当中。

这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核 CPU 中，每条线程可能运行于不同的 CPU 中，因此 **每个线程运行时有自己的高速缓存**（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。比如同时有两个线程执行这段代码，假如初始时`i`的值为`0`，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？

可能出现这种情况：初始时，**两个线程分别读取`i`的值存入各自所在的 CPU 的高速缓存当中，然后 线程1 进行加1操作，然后把`i`的最新值1写入到内存。此时线程2的高速缓存当中`i`的值还是0，进行加1操作之后，`i`的值为1，然后线程2把i的值写入内存。最终结果`i`的值是1，而不是2。这就是著名的缓存一致性问题**。通常称这种被多个线程访问的变量为共享变量。

为了解决缓存不一致性问题，通常来说有以下两种解决方法：

- 通过在总线加`LOCK#`锁的方式
- 通过 **缓存一致性协议**

> 这两种方式都是硬件层面上提供的方式。

在早期的 CPU 当中，是通过在总线上加`LOCK#`锁的形式来解决缓存不一致的问题。因为 CPU 和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他 CPU 对其他部件访问（如内存），从而使得只能有一个 CPU 能使用这个变量的内存。比如上面例子中 如果一个线程在执行 `i = i +1`，如果在执行这段代码的过程中，在总线上发出了`LCOK#`锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。但是上面的方式会有一个问题，**由于在锁住总线期间，其他CPU无法访问内存，导致效率低下**。

所以就出现了缓存一致性协议。最出名的就是 Intel 的`MESI协议`，`MESI协议`保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：**当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取**。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/volatile_1.jpg)

### Java内存模型  

在Java虚拟机规范中试图定义一种Java内存模型（`Java Memory Model，JMM`）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了程序中变量的访问规则，往大一点说是定义了程序执行的次序。**注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题**。

**Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存**。

在Java中，执行下面这个语句：

```
i  = 10;
```

执行线程必须先在自己的工作线程中对变量`i`所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值`10`写入主存当中。那么Java语言本身对 原子性、可见性以及有序性提供了哪些保证呢？

#### 原子性  

> 即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

**在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行**。上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子，请分析以下哪些操作是原子性操作：

```
x = 10;        //语句1
y = x;         //语句2
x++;           //语句3
x = x + 1;     //语句4
```

咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。**其实只有`语句1`是原子性操作，其他三个语句都不是原子性操作**。

- `语句1`是直接将数值`10`赋值给`x`，也就是说线程执行这个语句的会直接将数值`10`写入到工作内存中。
- `语句2`实际上包含2个操作，它先要去读取`x`的值，再将`x`的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。
- 同样的，`x++`和 `x = x+1`包括3个操作：读取`x`的值，进行加`1`操作，写入新的值。

也就是说，**只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作**。不过这里有一点需要注意：**在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了**。

从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过`synchronize`d和`Lock`来实现。由于`synchronized`和`Lock`能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。

#### 可见性  

> 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

对于可见性，Java提供了`volatile`关键字来保证可见性。**当一个共享变量被`volatile`修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值**。而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。

另外，通过`synchronized`和`Lock`也能够保证可见性，`synchronized`和`Lock`能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。

#### 有序性  

> 即程序执行的顺序按照代码的先后顺序执行。

> 指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。

**处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行**。

在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。

在Java里面，可以通过`volatile`关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过`synchronized`和`Lock`来保证有序性，很显然，`synchronized`和`Lock`保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。

另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 `happens-before` 原则，**若线程 A 和线程 B 满足 happens-before 关系，则线程 A 执行操作的结果对线程 B 是可见的**。如果两个操作的执行次序无法从`happens-before`原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。

下面就来具体介绍下`happens-before`原则（先行发生原则）：

- **程序次序规则**：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作
- **锁定规则**：一个unLock操作先行发生于后面对同一个锁额lock操作
- **volatile变量规则**：对一个变量的写操作先行发生于后面对这个变量的读操作
- **传递规则**：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C
- **线程启动规则**：Thread对象的start()方法先行发生于此线程的每个一个动作
- **线程中断规则**：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
- **线程终结规则**：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
- **对象终结规则**：一个对象的初始化完成先行发生于他的finalize()方法的开始

对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。

第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。

第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。**直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作**。

第四条规则实际上就是体现`happens-before`原则具备传递性。

### 深入剖析Volatile关键字  

#### Volatile 的语义  

一旦一个共享变量（类的成员变量、类的静态成员变量）被`volatile`修饰之后，那么就具备了两层语义：

- 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的
- 禁止进行指令重排序

先看一段代码，假如线程1先执行，线程2后执行：

```
//线程1
boolean stop = false;
while(!stop){
    doSomething();
}

//线程2
stop = true;
```

这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。

下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么`线程1`在运行的时候，会将`stop`变量的值拷贝一份放在自己的工作内存当中。

那么当`线程2`更改了`stop`变量的值之后，但是还没来得及写入主存当中，`线程2`转去做其他事情了，那么`线程1`由于不知道`线程2`对`stop`变量的更改，因此还会一直循环下去。但是用`volatile`修饰之后就变得不一样了：

- 使用`volatile`关键字会强制将修改的值立即写入主存；
- 使用`volatile`关键字的话，当`线程2`进行修改时，会导致`线程1`的工作内存中缓存变量`stop`的缓存行无效（*反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效*）；
- 由于`线程1`的工作内存中缓存变量`stop`的缓存行无效，所以`线程1`再次读取变量`stop`的值时会去主存读取。
- 那么在`线程2`修改`stop`值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得`线程1`的工作内存中缓存变量`stop`的缓存行无效，然后`线程1`读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。

那么线程1读取到的就是最新的正确的值。

#### Volatile与原子性  

从上面知道`volatile`关键字保证了操作的可见性，但是`volatile`能保证对变量的操作是原子性吗？

下面看一个例子：

```
public class Test {
    public volatile int inc = 0;

    public void increase() {
        inc++;
    }

    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i<10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j<1000;j++)
                        test.increase();
                };
            }.start();
        }

        while(Thread.activeCount()>1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
```

大家想一下这段程序的输出结果是多少？**也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字**。可能有的朋友就会有疑问，不对啊，上面是对变量`inc`进行自增操作，由于`volatile`保证了可见性，那么在每个线程中对`inc`自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终`inc`的值应该是`1000*10=10000`。

**这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性**。

在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：

```
假如某个时刻变量inc的值为10，

线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；

然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。

然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。

那么两个线程分别进行了一次自增操作后，inc只增加了1。
```

解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的`happens-before`规则中的`volatile`变量规则，但是要注意，**线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值**。

**根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的**。解决的方法也就是对提供原子性的自增操作即可。

在`Java 1.5`的`java.util.concurrent.atomic`包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。`atomic`是利用CAS来实现原子性操作的（`Compare And Swap`），CAS实际上是利用处理器提供的 `CMPXCHG` 指令实现的，而处理器执行 `CMPXCHG` 指令是一个原子性操作。

#### Volatile与有序性  

在前面提到`volatile`关键字能禁止指令重排序，所以`volatile`能在一定程度上保证有序性。`volatile`关键字禁止指令重排序有两层意思：

- 当程序执行到`volatile`变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见，在其后面的操作肯定还没有进行；
- **在进行指令优化时，不能将在对`volatile`变量访问的语句放在其后面执行，也不能把`volatile`变量后面的语句放到其前面执行**。

可能上面说的比较绕，举个简单的例子：

```
//x、y为非volatile变量
//flag为volatile变量

x = 2;        //语句1
y = 0;        //语句2
flag = true;  //语句3
x = 4;         //语句4
y = -1;       //语句5
```

由于flag变量为`volatile`变量，那么在进行指令重排序的过程的时候，不会将`语句3`放到`语句1`、`语句2`前面，也不会讲`语句3`放到`语句4`、`语句5`后面。但是要注意`语句1`和`语句2`的顺序、`语句4`和`语句5`的顺序是不作任何保证的。

并且`volatile`关键字能保证，执行到`语句3`时`，语句1`和`语句2`必定是执行完毕了的，且`语句1`和`语句2`的执行结果对`语句3`、`语句4`、`语句5`是可见的。

#### Volatile的原理和实现机制  

前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。下面这段话摘自《深入理解Java虚拟机》：

> 观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令

lock前缀指令实际上相当于一个 **内存屏障**（也成内存栅栏），内存屏障会提供3个功能：

- 它 **确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面**；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
- 它会 **强制将对缓存的修改操作立即写入主存**；



### AtomicInteger  

`AtomicInteger` 是 Java 中常见的原子类，每种基础类型都对应 `Atomic***`。`AtomicInteger` 中最重要的就属于原子更新操作，这里我们来分析下 `getAndAdd` 的实现。

```java
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;

    static {
        try {
            //获取 value 的偏移量
            valueOffset = unsafe.objectFieldOffset
                (AtomicInteger.class.getDeclaredField("value"));
        } catch (Exception ex) { throw new Error(ex); }
    }

    private volatile int value;

    public final int getAndAdd(int delta) {
        //调用 unsafe.getAndAddInt
        return unsafe.getAndAddInt(this, valueOffset, delta);
    }
```

`getAndAdd` 中直接调用 `unsafe.getAndAddInt`，原子更新的逻辑都在 `UnSafe` 类中：

```java
  public final int getAndAddInt(Object var1, long var2, int var4) {
    int var5;
    //循环 CAS
    do {
      //获取 volatile 字段值
      var5 = this.getIntVolatile(var1, var2);
    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));

    return var5;
  }
```

`getAndAdd` 就是通过循环CAS，来执行原子更新的逻辑。

### ABA 问题  

CAS 并不是万能的，CAS 更新有 ABA 问题。即 T1 读取内存变量为 `A` ,T2 修改内存变量为 `B` ,T2 修改内存变量为 `A` ,这时 T1 再 CAS 操作 `A` 时是可行的。但实际上在 T1 第二次操作 `A` 时，已经被其他线程修改过了。举一个现实情况下的例子：

小明账户上有100元。现在小明取钱，小强汇钱，诈骗分子盗刷三个动作同时进行。

1. 小明取50元。
2. 诈骗分子盗刷50元。
3. 小强给小明汇款50元。

此时，银行交易系统出问题，每笔交易无法通过短信告知小明。ABA问题就是：

1. 小明验证账户上有100元后，取出50元。—— 账上有50元。
2. 小强不会验证小明账户的余额，直接汇款50元。—— 账上有100元。
3. 诈骗分子验证账户有100元后，取出50元。—— 账上有50元。

小强没有告诉小明自己汇钱，小明也没收到短信，那么小明就一直以为只有自己取款操作，最后损失了50元。

### AtomicStampedReference  

对于 ABA 问题，比较有效的方案是引入版本号，内存中的值每发生一次变化，版本号都 `+1`；在进行CAS操作时，不仅比较内存中的值，也会比较版本号，只有当二者都没有变化时，CAS才能执行成功。 `AtomicStampedReference` 便是使用版本号来解决ABA问题的。类似的还有 `AtomicMarkableReference` ， `AtomicStampedReference` 是使用 pair 的 `int stamp` 作为计数器使用， `AtomicMarkableReference` 的 pair 使用的是 `boolean mark`。



## Synchronized原理  

### 基础  

在多线程并发编程中 `Synchronized` 一直是元老级角色，很多人都会称呼它为重量级锁，但是随着 `Java SE1.6` 对 `Synchronized` 进行了各种优化，引入了 **偏向锁** 和 **轻量级锁**。所以在 Java SE1.6 里锁一共有四种状态，`无锁状态`，`偏向锁状态`，`轻量级锁状态`和`重量级锁状态`，它会随着竞争情况逐渐升级。**锁可以升级但不能降级**，意味着偏向锁升级成轻量级锁后不能降级成偏向锁，但是偏向锁状态可以被重置为无锁状态（锁撤销）。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。

| 锁状态   | 优点                                   | 缺点                                 | 适用场景                           |
| -------- | -------------------------------------- | ------------------------------------ | ---------------------------------- |
| 偏向锁   | 加锁、解锁无额外消耗，和非同步方式近似 | 如果竞争线程多，会有额外锁撤销的消耗 | 基本没有线程竞争的场景             |
| 轻量级锁 | 竞争线程不会阻塞，使用自旋等待         | 如果长时间不能获取锁，会消耗CPU      | 少量线程竞争，且线程持有锁时间不长 |
| 重量级锁 | 竞争线程被阻塞，减少CPU空转            | 线程阻塞，响应时间长                 | 很多线程竞争，锁持有时间长         |

Java中的每一个对象都可以作为锁。

- 对于同步方法，锁是当前实例对象。
- 对于静态同步方法，锁是当前对象的Class对象。
- 对于同步方法块，锁是`Synchonized`括号里配置的对象。

当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。

### 锁的升级  

目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。

#### 偏向锁  

大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得。偏向锁是为了在只有一个线程执行同步块时提高性能。

![biased_lock](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/biased_lock.svg)

#### 轻量级锁  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/light_lock.svg)

这里解释下其中几个重要的步骤：

- 复制 Mark Word 到锁记录：拷贝对象头中的 Mark Word 到锁记录中。
- 更新 Mark Word 指针：拷贝成功后，虚拟机将使用 CAS 操作尝试将对象的 Mark Word 更新为指向 Lock Record 指针，并将 Lock Record 里的 owner 指针指向对象的 Mark Word。

#### 重量级锁  

在重量级锁的状态下， JVM 基于进入和退出 `Monitor` 对象来实现方法同步和代码块同步，`Monitor` 的引用存储在对象头中。

`Monitor` 本身是依赖与操作系统的互斥锁（mutex lock）实现的。由于 JVM 线程是映射到操作系统的原生线程之上的，如果要阻塞或唤醒一条线程，都需要操作系统来帮忙完成，这就需要从用户态转换到核心态中，因此这种转换需要耗费很多的 CPU 时间。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/monitor_lock.svg)

### 锁粗化  

同步块的作用范围应该尽可能小，仅在共享数据的实际作用域中才进行同步，这样做的目的是为了使需要同步的操作数量尽可能缩小，缩短阻塞时间，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。 

但是加锁解锁也需要消耗资源，如果存在一系列的连续加锁解锁操作，可能会导致不必要的性能损耗。 **锁粗化就是 JVM 将多个连续的加锁、解锁操作连接在一起**，扩展成一个范围更大的锁，避免频繁的加锁解锁操作。

### 锁消除  

Java 虚拟机在 JIT 编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，经过逃逸分析，**去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁**，可以节省毫无意义的请求锁时间

### Synchronized vs ReentrantLock  

1. synchronized 是 Java 关键字，ReentrantLock 是基于 AQS 的 API 层面的互斥锁
2. ReentrantLock 设置等待超时时间
3. ReentrantLock 可进行公平锁与非公平锁设置
4. ReentrantLock 可绑定多个 Condition
5. synchronized 不需要手动释放锁
6. synchronized 可以修饰方法、代码块



## AQS  

AQS 提供一个框架，用于实现依赖于先进先出（FIFO）`等待队列` 的阻塞锁和相关同步器（信号量，事件等）。对于大多数依赖单个原子 int 值表示状态的同步器，该类可以作为十分有用的基类。子类必须定义所有的`protected`方法（包括`tryAcquire`、`tryRelease`），来改变这个状态，并且定义哪些状态代表来对象被使用和被释放。鉴于这些，该类中其他的方法用来实现队列和阻塞的机制。子类可以维护其他状态字段，但是只有使用 `getState` 、`setState`以及 `compareAndSetState` 来原子的操作状态值。

子类需要定义非 `public` 的内部工具类用于实现其内部类的同步属性。`AbstractQueuedSynchronizer` 类不实现任何同步接口，相反，它定义了诸如`acquireInterruptibly`之类的方法，可以被具体的锁和相关的同步器适当地调用，以实现它们的公共方法。

该类支持默认的独占模式和共享模式。当一个线程处在独占模式下，其他试图 `acquire` 的线程都无法成功。共享模式可以同时被多个线程 `acquire`成功。在具体的应用场景中该类无法理解这些区别，当共享模式 `acquire` 成功之后，下一个线程（如果有一个存在）必须判定是否能够`acquire`。线程等待在不同的模式里但是会共享同一个FIFO队列。通常来说，子类只需要支持其中一种模式，但是如果都支持，可以参照`ReadWriteLock`。子类不需要定义不支持模式的方法。

该类定义`AbstractQueuedSynchronizer.ConditionObject`内部类，可以被子类使用的 `Condition` 实现，来支持独占模式 `isHeldExclusively` 判定当前线程的同步是否是独占模式，可用通过`release`方法与 `getState` 方法来完全释放当前对象，在将保存的状态值调用`acquire`，最终将此对象恢复到其先前获取的状态。`AbstractQueuedSynchronizer`没有方法来创建 `Condition`，所以如果无法满足这个约束，则不要使用它。`AbstractQueuedSynchronizer.ConditionObject` 的行为与具体的同步器实现有关。

该类为内部队列提供检查，检测和监视方法，以及 在`condition objects`上的类似方法。 这些方法可以根据需要使用 `AbstractQueuedSynchronizer` 用于它们的同步机制。该类的序列化仅存储 `atomic int` 的状态值，因此反序列化对象的线程队列为空。

### 使用  

为了使用该类去创建一个同步器，需要重新定义以下方法，并使用 `getState`, `setState`, `compareAndSetState` 方法来改变同步状态。

- tryAcquire
- tryRelease
- tryAcquireShared
- tryReleaseShared
- isHeldExclusively

上述所有方法默认实现都会抛出 `UnsupportedOperationException`。这个方法的具体实现必须保证内部的线程安全，并且应该快速并且不会阻塞。所有其他方法均为 `final`，因为他们不能独立变化。

也许你发现一些继承自 `AbstractOwnableSynchronizer` 的方法非常有助于线程保持拥有其独占同步器。同时我们也鼓励使用他们，有助于监控和诊断工具判定哪些线程持有来锁。

### [ReentrantLock](http://ifeve.com/java-special-troops-aqs/)  

> 公平锁相比与非公平锁在 `tryAcquire`中会多判定一个 `hasQueuedPredecessors`，如果为 `false`（队列头为当前线程–已获取锁 or 队列为空）并且成功修改状态值，则可以认为获取锁成功，这样才是重入，不然加到队尾就会有麻烦。

ReentrantLock 中通过两个子类 `FairSync` 和 `NoFairSync` 继承 AQS 来实现锁。在`Lock`方法中，直接调用 AQS 的 `acquire`，`acquire`会调用 `NoFairSync` 中的`tryAcquire`来尝试让当前线程直接获取锁。如果失败则会创建链表节点，将当前线程加入队列，并`park`。当`release`方法被调用后，会寻找队列下一个节点进行 `unpark`，这样他就有机会在`acquireQueued`中获取锁。

> 公平和非公平就体现在 `tryAcquire` 方法中，`FairSync`会判定当前线程是否已获取锁 or 队列为空，在这样的情况下才会尝试获取锁。而`NoFairSync`会直接来获取锁。

### [Condition](https://javadoop.com/post/AbstractQueuedSynchronizer-2/)  

`Condition` 因子将 `Object monitor` 方法（`wait, notify and notifyAll`）拆分为不同的对象，通过将它们与 `Lock` 相结合来实现每个对象具有多个等待集的效果。任何 `Lock` 可以替代 `synchronized` 关键字的地方，都可以用`Condition` 来替换`Object monitor` 方法。

`Conditions`（也称为 条件队列 或者 条件变量）提供了一种方法 – 让线程暂停执行，直到其他线程基于某种条件唤醒。在多个线程中访问一些共享的状态信息，是需要进行保护的，所以 `Lock` 与 `Condition` 有某种形式的关联。`Condition`提供的关键属性是它以原子方式释放关联的锁并挂起当前线程，就像`Object.wait`一样。

`Condition` 本质上是绑定到 `Lock`。可以通过 `Lock.newCondition()` 来获取一个 `Condition` 实例。

`Condition` 的实现可以提供相比于 `Object monitor`方法不一样的行为和语义，比如：被通知调起的顺序、在通知时不需要持有锁（**ReentrantLock 不允许**）。如果实现类提供了不一样的语义，必须在文档中进行说明。

`Condition` 实例只是普通的对象，可以用在同步语句中，并且有他们自己的 `Object monitor`的`wait`和 `notification` 方法。获取 `Condition` 对象的 `Object monitor` 或者使用其 `monitor` 方法，与`Lock` 中使用 `Condition` 的 `wait` 或者 `signal` 方法没有任何关系。为了避免混淆，不建议使用 `Condition` 的 `Object monitor` 方法，除非在它自己的实现里。

#### 实现类需要注意  

- 虚假唤醒（`spurious wakeup`）：开发者最好将条件 `wait` 方法放在循环中
- `Condition` 有3中 `wait` 形式（`interruptible, non-interruptible, and timed`），在不同平台的底层实现可能不同。因此，不需要对三种 `wait` 定义一致的语义，也不需要支持中断形式的线程暂停。

#### AbstractQueuedSynchronizer.ConditionObject  

```
/** First node of condition queue. */
private transient Node firstWaiter;
/** Last node of condition queue. */
private transient Node lastWaiter;
```

在 `ConditionObject` 的内部维护了一个队列：`条件队列`，与 `AbstractQueuedSynchronizer` 里的 `等待队列` 不同。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/4-AQS-cef7a.png)

基本上，把这张图看懂，你也就知道 condition 的处理流程了。

1. 条件队列和等待队列的节点，都是 Node 的实例，因为条件队列的节点是需要转移到等待队列中去的；
2. 我们知道一个 `ReentrantLock` 实例可以通过多次调用 `newCondition()` 来产生多个 `Condition` 实例，这里对应 `condition1` 和 `condition2`。注意，`ConditionObject`只有两个属性 `firstWaiter` 和 `lastWaiter；`
3. 每个 `condition` 有一个关联的条件队列，如线程 1 调用 `condition1.await()` 方法即可将当前`线程 1` 包装成 `Node` 后加入到`条件队列`中，然后阻塞在这里，不继续往下执行，条件队列是一个单向链表；
4. 调用`condition1.signal()` 触发一次唤醒，此时唤醒的是队头，会将`condition1` 对应的条件队列的 `firstWaiter`（队头） 移到`等待队列`的队尾，等待获取锁，获取锁后 `await` 方法才能返回，继续往下执行。

上面的 `2->3->4` 描述了一个最简单的流程，没有考虑中断、signalAll、还有带有超时参数的 await 方法等，不过把这里弄懂是这节的主要目的。



## CountDownLatch  

`CountDownLatch` 是可以使一个或者多个线程等待其他线程完成某些操作的同步器。`CountDownLatch` 通过一个给定的数字 `count` 进行初始化。调用 `await` 方法的线程会一直阻塞到其他线程调用 `countDown` 将 `count` 变为0，这时所有的线程都将释放，并且后续的 `await` 方法调用都会立即返回。`count` 值不能重置。如果你需要重置 `count` 请考虑使用 `CyclicBarrier`。

`CountDownLatch` 是一个能力很强的同步工具，可以用在多种途径。`CountDownLatch` 最重要的属性是其不要求 调用 `countDown` 的线程等待到 `count` 为0，只是要求所有 `await` 调用线程等待。

`CountDownLatch` 内部使用的是 AQS，AQS 里面的 state 是一个整数值，这边用一个 `int count` 参数其实初始化就是设置了这个值，所有调用了 `await` 方法的等待线程会挂起，然后有其他一些线程会做 `state = state - 1` 操作，当 `state` 减到 `0` 的同时，那个将 `state` 减为 `0` 的线程会负责唤醒 所有调用了 `await` 方法的线程。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/7-CountDownLatch-29ecd.png)

- `countDown()` 方法每次调用都会将 `state` 减 1，直到 `state` 的值为 0；而 `await` 是一个阻塞方法，当 `state` 减为 `0` 的时候，`await` 方法才会返回。`await` 可以被多个线程调用，读者这个时候脑子里要有个图：所有调用了 `await` 方法的线程阻塞在 `AQS`的阻塞队列中，等待条件满足（`state == 0`），将线程从队列中一个个唤醒过来。
- `await()` 方法，它代表线程阻塞，等待 `state` 的值减为 `0`。



## Threadlocal原理  

`ThreadLocal` 为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。当使用 ThreadLocal 维护变量时，ThreadLocal 为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。

每个线程中都保有一个`ThreadLocalMap`的成员变量，`ThreadLocalMap `内部采用`WeakReference`数组保存，数组的key即为`ThreadLocal `内部的Hash值。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2020-02-13-19-17-12.png)

### 内存泄漏  

`ThreadLocalMap` 使用 `ThreadLocal` 的弱引用作为 key ，如果一个 `ThreadLocal` 没有外部强引用来引用它，那么系统 GC 的时候，这个 `ThreadLocal` 势必会被回收，这样一来，`ThreadLocalMap` 中就会出现 `key` 为 `null` 的 `Entry` ，就没有办法访问这些 `key` 为 `null` 的 `Entry` 的 `value`，如果当前线程再迟迟不结束的话，这些 `key` 为 `null` 的 `Entry` 的 `value` 就会一直存在一条强引用链：`Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value` 永远无法回收，造成内存泄漏。

```
static class Entry extends WeakReference<ThreadLocal<?>> {
    /** The value associated with this ThreadLocal. */
    Object value;

    Entry(ThreadLocal<?> k, Object v) {
        super(k);
        value = v;
    }
}
```

其实，`ThreadLocalMap` 的设计中已经考虑到这种情况，也加上了一些防护措施：在 `ThreadLocal` 的 `get(),set(),remove()`的时候都会清除线程 `ThreadLocalMap` 里所有 `key` 为 `null` 的 `value`



## [线程中断](https://javadoop.com/post/AbstractQueuedSynchronizer-2/)  

中断不是类似 `linux` 里面的命令 `kill -9 pid`，不是说我们中断某个线程，这个线程就停止运行了。**中断代表线程状态，每个线程都关联了一个中断状态，是一个 true 或 false 的 boolean 值，初始值为 false**。

关于中断状态，我们需要重点关注 `Thread` 类中的以下几个方法：

```java
// Thread 类中的实例方法，持有线程实例引用即可检测线程中断状态
public boolean isInterrupted() {}

// Thread 中的静态方法，检测调用这个方法的线程是否已经中断
// 注意：这个方法返回中断状态的同时，会将此线程的中断状态重置为 false
// 所以，如果我们连续调用两次这个方法的话，第二次的返回值肯定就是 false 了
public static boolean interrupted() {}

// Thread 类中的实例方法，用于设置一个线程的中断状态为 true
public void interrupt() {}
```

我们说 **中断一个线程，其实就是设置了线程的 `interrupted status` 为 `true`**，至于说被中断的线程怎么处理这个状态，那是那个线程自己的事。如以下代码：

```java
while (!Thread.interrupted()) {
   doWork();
   System.out.println("我做完一件事了，准备做下一件，如果没有其他线程中断我的话");
}
```

> 这种代码就是会响应中断的，它会在干活的时候先判断下中断状态，不过，除了 JDK 源码外，其他用中断的场景还是比较少的，毕竟 JDK 源码非常讲究。

当然，中断除了是线程状态外，还有其他含义，否则也不需要专门搞一个这个概念出来了。如果线程处于以下三种情况，那么当线程被中断的时候，能自动感知到：

- 来自 `Object` 类的 `wait()、wait(long)、wait(long, int)`，来自 `Thread` 类的`join()、join(long)、join(long, int)、sleep(long)、sleep(long, int)`

  > 这几个方法的相同之处是，方法上都有: throws InterruptedException 如果线程阻塞在这些方法上（我们知道，这些方法会让当前线程阻塞），这个时候如果其他线程对这个线程进行了中断，那么这个线程会从这些方法中立即返回，抛出 InterruptedException 异常，同时重置中断状态为 false。

- 实现了 `InterruptibleChannel` 接口的类中的一些 I/O 阻塞操作，如 `DatagramChannel` 中的 `connect` 方法和 `receive` 方法等

  > 如果线程阻塞在这里，中断线程会导致这些方法抛出 ClosedByInterruptException 并重置中断状态。

- `Selector` 中的 `select` 方法

  > 一旦中断，方法立即返回

对于以上 3 种情况是最特殊的，因为他们能自动感知到中断（这里说自动，当然也是基于底层实现），并且在做出相应的操作后都会重置中断状态为 false。

那是不是只有以上 3 种方法能自动感知到中断呢？不是的，如果线程阻塞在 `LockSupport.park(Object obj)` 方法，也叫挂起，**这个时候的中断也会导致线程唤醒，但是唤醒后不会重置中断状态，所以唤醒后去检测中断状态将是 true**。

### InterruptedException 概述  

它是一个特殊的异常，不是说 JVM 对其有特殊的处理，而是它的使用场景比较特殊。通常，我们可以看到，像 `Object` 中的 `wait()` 方法，`ReentrantLock` 中的 `lockInterruptibly()` `方法，Thread` 中的 `sleep()` 方法等等，这些方法都带有 `throws InterruptedException`，我们通常称这些方法为阻塞方法（`blocking method`）。

阻塞方法一个很明显的特征是，它们需要花费比较长的时间（不是绝对的，只是说明时间不可控），还有它们的方法结束返回往往依赖于外部条件，如 `wait` 方法依赖于其他线程的 `notify`，`lock` 方法依赖于其他线程的 `unlock` 等等。

当我们看到方法上带有 `throws InterruptedException` 时，我们就要知道，这个方法应该是阻塞方法，我们如果希望它能早点返回的话，我们往往可以通过中断来实现。

除了几个特殊类（如 `Object，Thread`等）外，**感知中断并提前返回是通过轮询中断状态来实现的**。我们自己需要写可中断的方法的时候，就是通过在合适的时机（通常在循环的开始处）去判断线程的中断状态，然后做相应的操作（通常是方法直接返回或者抛出异常）。当然，我们也要看到，如果我们一次循环花的时间比较长的话，那么就需要比较长的时间才能感知到线程中断了。

### 处理中断  

一旦中断发生，我们接收到了这个信息，然后怎么去处理中断呢？本小节将简单分析这个问题。我们经常会这么写代码：

```java
try {
    Thread.sleep(10000);
} catch (InterruptedException e) {
    // ignore
}
// go on
```

当 sleep 结束继续往下执行的时候，我们往往都不知道这块代码是真的 `sleep` 了 `10` 秒，还是只休眠了 `1` 秒就被中断了。这个代码的问题在于，我们将这个异常信息吞掉了。（对于 `sleep` 方法，我相信大部分情况下，我们都不在意是否是中断了，这里是举例）

AQS 的做法很值得我们借鉴，我们知道 `ReentrantLock` 有两种 `lock` 方法：

```java
public void lock() {
    sync.lock();
}

public void lockInterruptibly() throws InterruptedException {
    sync.acquireInterruptibly(1);
}
```

前面我们提到过，`lock()` 方法不响应中断。如果 `thread1` 调用了 `lock()` 方法，过了很久还没抢到锁，这个时候 `thread2` 对其进行了中断，`thread1` 是不响应这个请求的，它会继续抢锁，当然它不会把“被中断”这个信息扔掉。我们可以看以下代码：

```java
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        // 我们看到，这里也没做任何特殊处理，就是记录下来中断状态。
        // 这样，如果外层方法需要去检测的时候，至少我们没有把这个信息丢了
        selfInterrupt();// Thread.currentThread().interrupt();
}
```

而对于 `lockInterruptibly()` 方法，因为其方法上面有 `throws InterruptedException`，这个信号告诉我们，如果我们要取消线程抢锁，直接中断这个线程即可，它会立即返回，抛出 `InterruptedException` 异常。

在并发包中，有非常多的这种处理中断的例子，提供两个方法，分别为响应中断和不响应中断，对于不响应中断的方法，记录中断而不是丢失这个信息。如 `Condition` 中的两个方法就是这样的：

```java
void await() throws InterruptedException;
void awaitUninterruptibly();
```

### 实例分析  

有以下代码：

```java
synchronized (this) {
    while (client == null) {
        try {
            this.wait();
        } catch (InterruptedException e) {
            LOGGER.error("InterruptedException:{}", e);
            Thread.currentThread().interrupt();
        }
    }
}
```

上面的代码会造成什么问题？仔细分析可以发现，代码中如果抛出 `InterruptedException`，就会陷入死循环中，导致异常日志打爆。为什么会这样呢？首先我们来看下这两个方法：

- `wait()`: if any thread interrupted the current thread before or while the current thread was waiting for a notification. The interrupted status of the current thread is cleared when this exception is thrown.
- `Thread.currentThread().interrupt()`: If none of the previous conditions hold then this thread’s interrupt status will be set.

`wait()` 在当前线程有中断标志位时抛出中断异常；而 `interrupt()` 如果当前线程没有在`wait()`等阻塞操作，则标记中断。这样就陷入死循环，无限的打印 ERROR 日志。正确的处理 `InterruptedException` 是很重要的。



#Java虚拟机

## JVM 架构  

Java 源码通过 javac 编译为 Java 字节码 ，Java 字节码是 Java 虚拟机执行的一套代码格式，其抽象了计算机的基本操作。大多数指令只有一个字节，而有些操作符需要参数，导致多使用了一些字节。

![jvm_architecture](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/jvm_architecture.svg)

JVM 的基本架构如上图所示，其主要包含三个大块：

- 类加载器：负责动态加载Java类到Java虚拟机的内存空间中。
- 运行时数据区：存储 JVM 运行时所有数据
- 执行引擎：提供 JVM 在不同平台的运行能力

### 线程  

在 JVM 中运行着许多线程，这里面有一部分是应用程序创建来执行代码逻辑的 **应用线程**，剩下的就是 JVM 创建来执行一些后台任务的 **系统线程**。

主要的系统线程有：

- **Compile Threads**：运行时将字节码编译为本地代码所使用的线程
- **GC Threads**：包含所有和 GC 有关操作
- **Periodic Task Thread**：JVM 周期性任务调度的线程，主要包含 JVM 内部的采样分析
- **Singal Dispatcher Thread**：处理 OS 发来的信号
- **VM Thread**：某些操作需要等待 JVM 到达 **安全点（Safe Point）**，即堆区没有变化。比如：GC 操作、线程 Dump、线程挂起 这些操作都在 VM Thread 中进行。

按照线程类型来分，在 JVM 内部有两种线程：

- `守护线程`：通常是由虚拟机自己使用，比如 GC 线程。但是，Java程序也可以把它自己创建的任何线程标记为守护线程（`public final void setDaemon(boolean on)`来设置，但必须在`start()`方法之前调用）。
- `非守护线程`：main方法执行的线程，我们通常也称为用户线程。

**只要有任何的非守护线程在运行，Java程序也会继续运行**。当该程序中所有的非守护线程都终止时，虚拟机实例将自动退出（守护线程随 JVM 一同结束工作）。

守护线程中不适合进行IO、计算等操作，因为守护线程是在所有的非守护线程退出后结束，这样并不能判断守护线程是否完成了相应的操作，如果非守护线程退出后，还有大量的数据没来得及读写，这将造成很严重的后果。



## 类加载器  

类加载器是 Java 运行时环境（Java Runtime Environment）的一部分，负责动态加载 Java 类到 Java 虚拟机的内存空间中。**类通常是按需加载，即第一次使用该类时才加载。** 由于有了类加载器，Java 运行时系统不需要知道文件与文件系统。每个 Java 类必须由某个类加载器装入到内存。

![jvm_classloader_architecture](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/jvm_classlaoder_architecture.svg)

类装载器除了要定位和导入二进制 class 文件外，还必须负责验证被导入类的正确性，为变量分配初始化内存，以及帮助解析符号引用。这些动作必须严格按一下顺序完成：

1. **装载**：查找并装载类型的二进制数据。
2. **链接**：执行验证、准备以及解析(可选) - **验证**：确保被导入类型的正确性 - **准备**：为类变量分配内存，并将其初始化为默认值。 - **解析**：把类型中的符号引用转换为直接引用。
3. **初始化**：把类变量初始化为正确的初始值。

### 装载  

#### 类加载器分类  

在Java虚拟机中存在多个类装载器，Java应用程序可以使用两种类装载器：

- **Bootstrap ClassLoader**：此装载器是 Java 虚拟机实现的一部分。由原生代码（如C语言）编写，不继承自 `java.lang.ClassLoader` 。负责加载核心 Java 库，启动类装载器通常使用某种默认的方式从本地磁盘中加载类，包括 Java API。
- **Extention Classloader**：用来在`<JAVA_HOME>/jre/lib/ext` ,或 `java.ext.dirs` 中指明的目录中加载 Java 的扩展库。 Java 虚拟机的实现会提供一个扩展库目录。
- **Application Classloader**：根据 Java应用程序的类路径（ `java.class.path` 或 `CLASSPATH` 环境变量）来加载 Java 类。一般来说，Java 应用的类都是由它来完成加载的。可以通过 `ClassLoader.getSystemClassLoader()` 来获取它。
- **自定义类加载器**：可以通过继承 `java.lang.ClassLoader` 类的方式实现自己的类加载器，以满足一些特殊的需求而不需要完全了解 Java 虚拟机的类加载的细节。

#### 全盘负责双亲委托机制  

在一个 JVM 系统中，至少有 3 种类加载器，那么这些类加载器如何配合工作？在 JVM 种类加载器通过 **全盘负责双亲委托机制** 来协调类加载器。

- **全盘负责**：指当一个 `ClassLoader` 装载一个类的时，除非显式地使用另一个 `ClassLoader` ，该类所依赖及引用的类也由这个 `ClassLoader` 载入。
- **双亲委托机制**：指先委托父装载器寻找目标类，只有在找不到的情况下才从自己的类路径中查找并装载目标类。

全盘负责双亲委托机制只是 Java 推荐的机制，并不是强制的机制。实现自己的类加载器时，如果想保持双亲委派模型，就应该重写 `findClass(name)` 方法；如果想破坏双亲委派模型，可以重写 `loadClass(name)` 方法。

#### 装载入口  

所有Java虚拟机实现必须在每个类或接口首次主动使用时初始化。以下六种情况符合主动使用的要求：

- 当创建某个类的新实例时(new、反射、克隆、序列化)
- 调用某个类的静态方法
- 使用某个类或接口的静态字段，或对该字段赋值(用final修饰的静态字段除外，它被初始化为一个编译时常量表达式)
- 当调用Java API的某些反射方法时。
- 初始化某个类的子类时。
- 当虚拟机启动时被标明为启动类的类。

除以上六种情况，所有其他使用Java类型的方式都是被动的，它们不会导致Java类型的初始化。

对于接口来说，只有在某个接口声明的非常量字段被使用时，该接口才会初始化，而不会因为事先这个接口的子接口或类要初始化而被初始化。

**父类需要在子类初始化之前被初始化**。当实现了接口的类被初始化的时候，不需要初始化父接口。然而，当实现了父接口的子类(或者是扩展了父接口的子接口)被装载时，父接口也要被装载。(只是被装载，没有初始化)

### 验证  

确认装载后的类型符合Java语言的语义，并且不会危及虚拟机的完整性。

- **装载时验证**：检查二进制数据以确保数据全部是预期格式、确保除 Object 之外的每个类都有父类、确保该类的所有父类都已经被装载。
- **正式验证阶段**：检查 final 类不能有子类、确保 final 方法不被覆盖、确保在类型和超类型之间没有不兼容的方法声明(比如拥有两个名字相同的方法，参数在数量、顺序、类型上都相同，但返回类型不同)。
- **符号引用的验证**：当虚拟机搜寻一个被符号引用的元素(类型、字段或方法)时，必须首先确认该元素存在。如果虚拟机发现元素存在，则必须进一步检查引用类型有访问该元素的权限。

### 准备  

在准备阶段，Java虚拟机为类变量分配内存，**设置默认初始值**。但在到到初始化阶段之前，类变量都没有被初始化为真正的初始值。

| 类型      | 默认值   |
| --------- | -------- |
| int       | 0        |
| long      | 0L       |
| short     | (short)0 |
| char      | ‘\u0000’ |
| byte      | (byte)0  |
| blooean   | false    |
| float     | 0.0f     |
| double    | 0.0d     |
| reference | null     |

### 解析  

解析的过程就是在类型的常量池总寻找类、接口、字段和方法的符号引用，**把这些符号引用替换为直接引用的过程**。

- `类或接口的解析`：判断所要转化成的直接引用是数组类型，还是普通的对象类型的引用，从而进行不同的解析。
- `字段解析`：对字段进行解析时，会先在本类中查找是否包含有简单名称和字段描述符都与目标相匹配的字段，如果有，则查找结束；如果没有，则会按照继承关系从上往下递归搜索该类所实现的各个接口和它们的父接口，还没有，则按照继承关系从上往下递归搜索其父类，直至查找结束，

### 初始化  

**所有的类变量(即静态量)初始化语句和类型的静态初始化器都被Java编译器收集在一起，放到一个特殊的方法中。** 对于类来说，这个方法被称作类初始化方法；对于接口来说，它被称为接口初始化方法。在类和接口的 class 文件中，这个方法被称为`<clinit>`。

1. 如果存在直接父类，且直接父类没有被初始化，先初始化直接父类。
2. 如果类存在一个类初始化方法，执行此方法。

这个步骤是递归执行的，即第一个初始化的类一定是`Object`。

**Java虚拟机必须确保初始化过程被正确地同步。** 如果多个线程需要初始化一个类，仅仅允许一个线程来进行初始化，其他线程需等待。

> 这个特性可以用来写单例模式。

#### Clinit 方法  

- 对于静态变量和静态初始化语句来说：执行的顺序和它们在类或接口中出现的顺序有关。
- **并非所有的类都需要在它们的`class`文件中拥有`<clinit>()`方法，** 如果类没有声明任何类变量，也没有静态初始化语句，那么它就不会有`<clinit>()`方法。如果类声明了类变量，但没有明确的使用类变量初始化语句或者静态代码块来初始化它们，也不会有`<clinit>()`方法。如果类仅包含静态`final`常量的类变量初始化语句，而且这些类变量初始化语句采用编译时常量表达式，类也不会有`<clinit>()`方法。**只有那些需要执行Java代码来赋值的类才会有`<clinit>()`**
- `final`常量：Java虚拟机在使用它们的任何类的常量池或字节码中直接存放的是它们表示的常量值。



## 运行时数据区  

运行时数据区用于保存 JVM 在运行过程中产生的数据，结构如图所示：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/runtime_data_area.svg)

### Heap  

Java 堆是可供各线程共享的运行时内存区域，是 Java 虚拟机所管理的内存区域中最大的一块。此区域非常重要，几乎所有的对象实例和数组实例都要在 Java 堆上分配，但随着 JIT 编译器及逃逸分析技术的发展，**也可能会被优化为栈上分配**。

Heap 中除了作为对象分配使用，还包含字符串字面量 **常量池（Internd Strings）** 。 除此之外 Heap 中还包含一个 **新生代（Yong Generation）**、一个 **老年代（Old Generation）**。

新生代分三个区，一个Eden区，两个Survivor区，**大部分对象在Eden区中生成**。Survivor 区总有一个是空的。

老年代中保存一些生命周期较长的对象，当一个对象经过多次的 GC 后还没有被回收，那么它将被移动到老年代。

### Methoad Area  

方法区的数据由所有线程共享，因此为安全的使用方法区的数据，需要注意线程安全问题。

方法区主要保存类级别的数据，包括：

- ClassLoader Reference
- Runtime Constant Pool
  - 数字常量
  - 类属性引用
  - 方法引用
- Field Data：每个类属性的名称、类型等
- Methoad Data：每个方法的名称、返回值类型、参数列表等
- Methoad Code：每个方法的字节码、本地变量表等

方法区的实现在不同的 JVM 版本有不同，在 JVM 1.8 之前，方法区的实现为 **永久代（PermGen）**，但是由于永久代的大小限制， 经常会出现内存溢出。于是在 JVM 1.8 方法区的实现改为 **元空间（Metaspace）**，元空间是在 Native 的一块内存空间。

### Stack  

对于每个 JVM 线程，当线程启动时，都会分配一个独立的运行时栈，用以保存方法调用。每个方法调用，都会在栈顶增加一个栈帧（Stack Frame）。

每个栈帧都保存三个引用：**本地变量表（Local Variable Array）**、 **操作数栈（Operand Stack）** 和 **当前方法所属类的运行时常量池（Runtime Constant Pool）**。由于本地变量表和操作数栈的大小都在编译时确定，所以栈帧的大小是固定的。

当被调用的方法返回或抛出异常，栈帧会被弹出。在抛出异常时 `printStackTrace()` 打印的每一行就是一个栈帧。同时得益于栈帧的特点，栈帧内的数据是线程安全的。

栈的大小可以动态扩展，但是如果一个线程需要的栈大小超过了允许的大小，就会抛出 `StackOverflowError`。

### PC Register  

对于每个 JVM 线程，当线程启动时，都会有一个独立的 **PC（Program Counter） 计数器**，用来保存当前执行的代码地址（方法区中的内存地址）。如果当前方法是 Native 方法，PC 的值为 NULL。一旦执行完成，PC 计数器会被更新为下一个需要执行代码的地址。

### Native Method Stack  

本地方法栈和 Java 虚拟机栈的作用相似，Java 虚拟机栈执行的是字节码，而本地方法栈执行的是 `native` 方法。本地方法栈使用传统的栈（C Stack）来支持 `native` 方法。

### Direct Memory  

[Native Memory Tracking](https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/tooldescr007.html)

在 JDK 1.4 中新加入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里的 `DirectByteBuffer` 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为 **避免了在 Java 堆和 Native 堆中来回复制数据**。



## 垃圾回收  

### 对象存活检测  

Java堆中存放着大量的Java对象实例，在垃圾收集器回收内存前，第一件事情就是确定哪些对象是活着的，哪些是可以回收的。

#### 引用计数算法  

引用计数算法是判断对象是否存活的基本算法：给每个对象添加一个引用计数器，没当一个地方引用它的时候，计数器值加1；当引用失效后，计数器值减1。但是这种方法有一个致命的缺陷，**当两个对象相互引用时会导致这两个都无法被回收**。

#### 根搜索算法  

引用计数是通过为堆中每个对象保存一个计数来区分活动对象和垃圾。根搜索算法实际上是追踪从根结点开始的 **引用图**。

在根搜索算法追踪的过程中，起点即 **GC Root**，GC Root 根据 JVM 实现不同而不同，但是总会包含以下几个方面（**堆外引用**）：

- 虚拟机栈（栈帧中的本地变量表）中引用的对象。
- 方法区中的类静态属性引用的变量。
- 方法区中的常量引用的变量。
- 本地方法 JNI 的引用对象。

根搜索算法是从 GC Root 开始的引用图，引用图是一个有向图，其中节点是各个对象，边为引用类型。JVM 中的引用类型分为四种：**强引用（StrongReference）**、**软引用（SoftReference）**、**弱引用（WeakReference）** 和 **虚引用（PhantomReference）**。

除强引用外，其他引用在Java 由 `Reference` 的子类封装了指向其他对象的连接：被指向的对象称为 **引用目标**。

若一个对象的引用类型有多个，那到底如何判断它的回收策略呢？其实规则如下：

- 单条引用链以链上最弱的一个引用类型来决定；
- 多条引用链以多个单条引用链中最强的一个引用类型来决定；

在引用图中，当一个节点没有任何路径可达时，我们认为它是可回收的对象。

##### StrongReference  

强引用在Java中是普遍存在的，类似 `Object o = new Object();` 。强引用和其他引用的区别在于：**强引用禁止引用目标被垃圾收集器收集，而其他引用不禁止**。

##### SoftReference  

对象可以从根节点通过一个或多个(未被清除的)软引用对象触及，垃圾收集器在要发生内存溢出前将这些对象列入回收范围中进行回收，如果该软引用对象和引用队列相关联，它会把该软引用对象加入队列。

**JVM 的实现需要在抛出 OutOfMemoryError 之前清除 SoftReference**，但在其他的情况下可以选择清理的时间或者是否清除它们。

##### WeakReference  

对象可以从 GC Root 开始通过一个或多个(未被清除的)弱引用对象触及， **垃圾收集器在 GC 的时候会回收所有的 WeakReference**，如果该弱引用对象和引用队列相关联，它会把该弱引用对象加入队列。

##### PhantomReference  

**垃圾收集器在 GC 不会清除 PhantomReference，所有的虚引用都必须由程序明确的清除**。同时也不能通过虚引用来取得一个对象的实例。

### 垃圾回收算法  

#### 复制回收算法  

将可用内存分为大小相等的两份，在同一时刻只使用其中的一份。当这一份内存使用完了，就将还存活的对象复制到另一份上，然后将这一份上的内存清空。复制算法能有效避免内存碎片，但是算法需要将内存一分为二，导致内存使用率大大降低。

#### 标记清除算法  

先暂停整个程序的全部运行线程，让回收线程以单线程进行扫描标记，并进行直接清除回收，然后回收完成后，恢复运行线程。**标记清除后会产生大量不连续的内存碎片**，造成空间浪费。

#### 标记整理算法  

和 *标记清除* 相似，不同的是，回收期间同时会将保留的存储对象搬运汇集到连续的内存空间，从而集成空闲空间。

#### 增量回收  

需要程序将所拥有的内存空间分成若干分区（Region）。程序运行所需的存储对象会分布在这些分区中，每次只对其中一个分区进行回收操作，从而避免程序全部运行线程暂停来进行回收，允许部分线程在不影响回收行为而保持运行，并且降低回收时间，增加程序响应速度。

#### 分代回收  

在 JVM 中不同的对象拥有不同的生命周期，因此对于不同生命周期的对象也可以采用不同的垃圾回收算法，以提高效率，这就是分代回收算法的核心思想。

##### 记忆集  

上面有说到进行 GC 的时候，会从 GC Root 进行搜索，做一个引用图。现有一个对象 C 在 Young Gen，其只被一个在 Old Gen 的对象 D 引用，其引用结构如下所示：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/gc_remembered_set.png)

这个时候要进行 Young GC，要确定 C 是否被堆外引用，就需要遍历 Old Gen，这样的代价太大。所以 JVM 在进行对象引用的时候，会有个 **记忆集（Remembered Set）** 记录从 Old Gen 到 Young Gen 的引用关系，并把记忆集里的 Old Gen 作为 GC Root 来构建引用图。这样在进行 Young GC 时就不需要遍历 Old Gen。

但是使用记忆集也会有缺点：C & D 其实都可以进行回收，但是由于记忆集的存在，不会将 C 回收。这里其实有一点 **空间换时间** 的意思。不过无论如何，它依然确保了垃圾回收所遵循的原则：**垃圾回收确保回收的对象必然是不可达对象，但是不确保所有的不可达对象都会被回收**。

### 垃圾回收触发条件  

#### 堆内内存  

针对 HotSpot VM 的实现，它里面的 GC 其实准确分类只有两大种：

1. Partial GC

   ：并不收集整个 GC 堆的模式

   1. **Young GC（Minor GC）**：只收集 Young Gen 的 GC
   2. **Old GC**：只收集 Old Gen 的 GC。只有 CMS的 Concurrent Collection 是这个模式
   3. **Mixed GC**：收集整个 Young Gen 以及部分 Old Gen 的 GC。只有 G1 有这个模式

2. **Full GC（Major GC）**：收集整个堆，包括 Young Gen、Old Gen、Perm Gen（如果存在的话）等所有部分的 GC 模式。

最简单的分代式GC策略，按 HotSpot VM 的 serial GC 的实现来看，触发条件是

- **Young GC**：当 Young Gen 中的 eden 区分配满的时候触发。把 Eden 区存活的对象将被复制到一个 Survivor 区，当这个 Survivor 区满时，此区的存活对象将被复制到另外一个 Survivor 区。

- Full GC

  ：

  - 当准备要触发一次 Young GC 时，如果发现之前 Young GC 的平均晋升大小比目前 Old Gen剩余的空间大，则不会触发 Young GC 而是转为触发 Full GC

    > 除了 CMS 的 Concurrent Collection 之外，其它能收集 Old Gen 的GC都会同时收集整个 GC 堆，包括 Young Gen，所以不需要事先触发一次单独的Young GC

  - 如果有 Perm Gen 的话，要在 Perm Gen分配空间但已经没有足够空间时

  - `System.gc()`

  - Heap dump

并发 GC 的触发条件就不太一样。以 CMS GC 为例，它主要是定时去检查 Old Gen 的使用量，当使用量超过了触发比例就会启动一次 GC，对 Old Gen做并发收集。

#### 堆外内存  

`DirectByteBuffer` 的引用是直接分配在堆得 `Old` 区的，因此其回收时机是在 `FullGC`时。因此，需要避免频繁的分配 `DirectByteBuffer` ，这样很容易导致 `Native Memory` 溢出。

`DirectByteBuffer` 申请的直接内存，不再GC范围之内，无法自动回收。JDK 提供了一种机制，可以为堆内存对象注册一个钩子函数(其实就是实现 `Runnable` 接口的子类)，当堆内存对象被GC回收的时候，会回调run方法，我们可以在这个方法中执行释放 `DirectByteBuffer` 引用的直接内存，即在run方法中调用 `Unsafe` 的 `freeMemory` 方法。注册是通过`sun.misc.Cleaner` 类来实现的。

### 垃圾收集器  

垃圾收集器是内存回收的具体实现，下图展示了 7 种用于不同分代的收集器，两个收集器之间有连线表示可以搭配使用，每种收集器都有最适合的使用场景。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/garbage_collector.svg)

#### Serial 收集器  

Serial 收集器是最基本的收集器，这是一个单线程收集器，它只用一个线程去完成垃圾收集工作。

虽然 Serial 收集器的缺点很明显，但是它仍然是 JVM 在 Client 模式下的默认新生代收集器。它有着优于其他收集器的地方：简单而高效（与其他收集器的单线程比较），Serial 收集器由于没有线程交互的开销，专心只做垃圾收集自然也获得最高的效率。在用户桌面场景下，分配给 JVM 的内存不会太多，停顿时间完全可以在几十到一百多毫秒之间，只要收集不频繁，这是完全可以接受的。

#### ParNew 收集器  

ParNew 是 Serial 的多线程版本，在回收算法、对象分配原则上都是一致的。ParNew 收集器是许多运行在Server 模式下的默认新生代垃圾收集器，其主要与 CMS 收集器配合工作。

#### Parallel Scavenge 收集器  

Parallel Scavenge 收集器是一个新生代垃圾收集器，也是并行的多线程收集器。

Parallel Scavenge 收集器更关注可控制的吞吐量，吞吐量等于运行用户代码的时间/(运行用户代码的时间+垃圾收集时间)。

#### Serial Old收集器  

Serial Old 收集器是 Serial 收集器的老年代版本，也是一个单线程收集器，采用“标记-整理算法”进行回收。

#### Parallel Old 收集器  

Parallel Old 收集器是 Parallel Scavenge 收集器的老年代版本，使用多线程进行垃圾回收，其通常与 Parallel Scavenge 收集器配合使用。

#### CMS 收集器  

CMS（Concurrent Mark Sweep）收集器是一种以获取最短停顿时间为目标的收集器， CMS 收集器采用 `标记--清除` 算法，运行在老年代。主要包含以下几个步骤：

- 初始标记（Stop the world）
- 并发标记
- 重新标记（Stop the world）
- 并发清除

其中初始标记和重新标记仍然需要 **Stop the world**。初始标记仅仅标记 GC Root 能直接关联的对象，并发标记就是进行 GC Root Tracing 过程，而重新标记则是为了修正并发标记期间，因用户程序继续运行而导致标记变动的那部分对象的标记记录。

由于整个过程中最耗时的并发标记和并发清除，收集线程和用户线程一起工作，所以总体上来说， CMS 收集器回收过程是与用户线程并发执行的。虽然 CMS 优点是并发收集、低停顿，很大程度上已经是一个不错的垃圾收集器，但是还是有三个显著的缺点：

- **CMS收集器对CPU资源很敏感**：在并发阶段，虽然它不会导致用户线程停顿，但是会因为占用一部分线程（CPU资源）而导致应用程序变慢。
- **CMS收集器不能处理浮动垃圾**：所谓的“浮动垃圾”，就是在并发标记阶段，由于用户程序在运行，那么自然就会有新的垃圾产生，这部分垃圾被标记过后，CMS 无法在当次集中处理它们，只好在下一次 GC 的时候处理，这部分未处理的垃圾就称为“浮动垃圾”。
- **GC 后产生大量内存碎片**：当内存碎片过多时，将会给分配大对象带来困难，这是就会进行 Full GC。

正是由于在垃圾收集阶段程序还需要运行，即还需要预留足够的内存空间供用户使用，因此 CMS 收集器不能像其他收集器那样等到老年代几乎填满才进行收集，需要预留一部分空间提供并发收集时程序运作使用。要是 CMS 预留的内存空间不能满足程序的要求，这是 JVM 就会启动预备方案：**临时启动 Serial Old 收集器来收集老年代**，这样停顿的时间就会很长。

#### G1收集器  

G1收集器与CMS相比有很大的改进：

- **标记整理算法**：G1 收集器采用标记整理算法实现
- **增量回收模式**：将 Heap 分割为多个 Region，并在后台维护一个优先列表，每次根据允许的时间，优先回收垃圾最多的区域

因此 G1 收集器可以实现在基本不牺牲吞吐量的情况下完成低停顿的内存回收，这是正是由于它极力的避免全区域的回收。

| 垃圾收集器        | 特性 | 算法     | 优点                                       | 缺点                                     |
| ----------------- | ---- | -------- | ------------------------------------------ | ---------------------------------------- |
| Serial            | 串行 | 复制     | 高效：无线程切换                           | 无法利用多核CPU                          |
| ParNew            | 并行 | 复制     | 可利用多核CPU、唯一能与CMS配合的并行收集器 |                                          |
| Parallel Scavenge | 并行 | 复制     | 高吞吐量                                   |                                          |
| Serial Old        | 串行 | 标记整理 | 高效                                       | 无法利用多核CPU                          |
| Parallel Old      | 并行 | 标记整理 | 高吞吐量                                   |                                          |
| CMS               | 并行 | 标记清除 | 低停顿                                     | CPU敏感、浮动垃圾、内存碎片              |
| G1                | 并行 | 增量回收 | 低停顿、高吞吐量                           | 内存使用效率低：分区导致内存不能充分使用 |



## Java分派机制  

在Java中，符合“编译时可知，运行时不可变”这个要求的方法主要是静态方法和私有方法。这两种方法都不能通过继承或别的方法重写，因此它们适合在类加载时进行解析。

Java虚拟机中有四种方法调用指令：

- `invokestatic`：调用静态方法。
- `invokespecial`：调用实例构造器方法，私有方法和super。
- `invokeinterface`：调用接口方法。
- `invokevirtual`：调用以上指令不能调用的方法（虚方法）。

只要能被`invokestatic`和`invokespecial`指令调用的方法，都可以在解析阶段确定唯一的调用版本，符合这个条件的有：静态方法、私有方法、实例构造器、父类方法，他们在类加载的时候就会把符号引用解析为改方法的直接引用。这些方法被称为非虚方法，反之其他方法称为虚方法（final方法除外）。

> 虽然final方法是使用`invokevirtual `指令来调用的，但是由于它无法被覆盖，多态的选择是唯一的，所以是一种非虚方法。

### 静态分派  

> 对于类字段的访问也是采用静态分派

```
People man = new Man()
```

**静态分派主要针对重载**，方法调用时如何选择。在上面的代码中，`People`被称为变量的引用类型，`Man`被称为变量的实际类型。**静态类型是在编译时可知的，而动态类型是在运行时可知的**，编译器不能知道一个变量的实际类型是什么。

**编译器在重载时候通过参数的静态类型而不是实际类型作为判断依据**。并且静态类型在编译时是可知的，所以编译器根据重载的参数的静态类型进行方法选择。

> 在某些情况下有多个重载，那编译器如何选择呢？ 编译器会选择"最合适"的函数版本，那么怎么判断"最合适“呢？越接近传入参数的类型，越容易被调用。

### 动态分派  

动态分派主要针对重写，使用`invokevirtual`指令调用。`invokevirtual`指令多态查找过程：

- 找到操作数栈顶的第一个元素所指向的对象的实际类型，记为C。
- 如果在类型C中找到与常量中的描述符合简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；如果权限校验不通过，返回java.lang.IllegalAccessError异常。
- 否则，按照继承关系从下往上一次对C的各个父类进行第2步的搜索和验证过程。
- 如果始终没有找到合适的方法，则抛出 java.lang.AbstractMethodError异常。

### 虚拟机动态分派的实现  

由于动态分派是非常繁琐的动作，而且动态分派的方法版本选择需要考虑运行时在类的方法元数据中搜索合适的目标方法，**因此在虚拟机的实现中基于性能的考虑，在方法区中建立一个虚方法表**（`invokeinterface `有接口方法表），来提高性能。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/dispatcher.bmp)

虚方法表中存放各个方法的实际入口地址。如果某个方法在子类没有重写，那么子类的虚方法表里的入口和父类入口一致，如果子类重写了这个方法，那么子类方法表中的地址会被替换为子类实现版本的入口地址。



## String 常量池  

在 `JAVA` 语言中有 8 中基本类型和一种比较特殊的类型 `String` 。这些类型为了使他们在运行过程中速度更快，更节省内存，都提供了一种常量池的概念。常量池就类似一个 JAVA 系统级别提供的缓存。

`String` 类型的常量池比较特殊。它的主要使用方法有两种：

- 直接使用双引号声明出来的 `String` 对象会直接存储在常量池中
- 如果不是用双引号声明的 `String` 对象，可以使用 `String` 提供的 `intern` 方法。 `intern` 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中

### intern  

```
    /**
     * Returns a canonical representation for the string object.
     * <p>
     * A pool of strings, initially empty, is maintained privately by the
     * class {@code String}.
     * <p>
     * When the intern method is invoked, if the pool already contains a
     * string equal to this {@code String} object as determined by
     * the {@link #equals(Object)} method, then the string from the pool is
     * returned. Otherwise, this {@code String} object is added to the
     * pool and a reference to this {@code String} object is returned.
     * <p>
     * It follows that for any two strings {@code s} and {@code t},
     * {@code s.intern() == t.intern()} is {@code true}
     * if and only if {@code s.equals(t)} is {@code true}.
     * <p>
     * All literal strings and string-valued constant expressions are
     * interned. String literals are defined in section 3.10.5 of the
     * <cite>The Java&trade; Language Specification</cite>.
     *
     * @return  a string that has the same contents as this string, but is
     *          guaranteed to be from a pool of unique strings.
     */
    public native String intern();
```

JAVA 使用 `jni` 调用 `c++` 实现的 `StringTable` 的 `intern` 方法, `StringTable` 跟 Java 中的 `HashMap` 的实现是差不多的, 只是 **不能自动扩容**。默认大小是 `1009` 。

要注意的是， `String` 的 `String Pool` 是一个固定大小的 `Hashtable` ，默认值大小长度是 `1009` ，如果放进 `String Pool` 的 `String` 非常多，就会造成 Hash 冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用 `String.intern` 时性能会大幅下降。

在 JDK6 中 `StringTable` 是固定的，就是 `1009` 的长度，所以如果常量池中的字符串过多就会导致效率下降很快。在 `jdk7` 中， `StringTable` 的长度可以通过一个参数指定：

```
-XX:StringTableSize=99991
```

> 在 JDK6 以及以前的版本中，字符串的常量池是放在堆的 Perm 区。在 JDK7 的版本中，字符串常量池已经从 Perm 区移到正常的 Java Heap 区域

```
public static void main(String[] args) {
    String s = new String("1");
    s.intern();
    String s2 = "1";
    System.out.println(s == s2);

    String s3 = new String("1") + new String("1");
    s3.intern();
    String s4 = "11";
    System.out.println(s3 == s4);
}
```

上述代码的执行结果：

- JDK6: `false false`
- JDK7: `false true`

```
public static void main(String[] args) {
    String s = new String("1");
    String s2 = "1";
    s.intern();
    System.out.println(s == s2);

    String s3 = new String("1") + new String("1");
    String s4 = "11";
    s3.intern();
    System.out.println(s3 == s4);
}
```

上述代码的执行结果：

- JDK6: `false false`
- JDK7: `false false`

由于 JDK7 将字符串常量池移动到 Heap 中，导致上述版本差异，下面具体来分析下。

#### JDK6  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2019-04-12-09-49-38.png)

> 图中绿色线条代表 string 对象的内容指向，黑色线条代表地址指向

在 `jdk6` 中上述的所有打印都是 `false` ，因为 `jdk6` 中的常量池是放在 `Perm` 区中的， `Perm` 区和正常的 `JAVA Heap` 区域是完全分开的。上面说过如果是使用引号声明的字符串都是会直接在字符串常量池中生成，而 `new` 出来的 `String` 对象是放在 `JAVA Heap` 区域。所以拿一个 `JAVA Heap` 区域的对象地址和字符串常量池的对象地址进行比较肯定是不相同的，**即使调用 `String.intern` 方法也是没有任何关系的**。

#### JDK7  

因为字符串常量池移动到 JAVA Heap 区域后，再来解释为什么会有上述的打印结果。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2019-04-12-10-01-01.png)

- 在第一段代码中，先看 `s3` 和 `s4` 字符串。`String s3 = new String("1") + new String("1");`，这句代码中现在生成了 2个 最终对象，是字符串常量池中的 `“1”` 和 `JAVA Heap` 中的 `s3` 引用指向的对象。中间还有 2个 匿名的 `new String("1")` 我们不去讨论它们。此时 `s3` 引用对象内容是 `”11”` ，但此时常量池中是没有 `“11”` 对象的。
- 接下来 `s3.intern();` 这一句代码，是将 `s3` 中的 `“11”` 字符串放入 `String` 常量池中，因为此时常量池中不存在 `“11”` 字符串，因此常规做法是跟 `jdk6` 图中表示的那样，在常量池中生成一个 `“11”` 的对象，关键点是 `jdk7` 中常量池不在 `Perm` 区域了，这块做了调整。**常量池中不需要再存储一份对象，可以直接存储堆中的引用**。这份引用指向 `s3` 引用的对象。 也就是说引用地址是相同的。
- 最后 `String s4 = "11";` 这句代码中 `”11”` 是显示声明的，因此会直接去常量池中创建，创建的时候发现已经有这个对象了，此时也就是指向 `s3` 引用对象的一个引用。所以 `s4` 引用就指向和 `s3` 一样了。因此最后的比较 `s3 == s4` 是 `true` 。
- 再看 `s` 和 `s2` 对象。 `String s = new String("1");` 第一句代码，生成了2个对象。常量池中的 `“1”` 和 `JAVA Heap` 中的字符串对象。`s.intern();` 这一句是 `s` 对象去常量池中寻找后发现 `“1”` 已经在常量池里了。
- 接下来 `String s2 = "1";` 这句代码是生成一个 `s2` 的引用指向常量池中的 `“1”` 对象。 结果就是 `s` 和 `s2` 的引用地址明显不同。

接下来是第二段代码：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2019-04-12-10-06-01.png)

- 第一段代码和第二段代码的改变就是 `s3.intern();` 的顺序是放在 `String s4 = "11";` 后了。这样，首先执行 `String s4 = "11";` 声明 `s4` 的时候常量池中是不存在 `“11”` 对象的，执行完毕后， `“11“` 对象是 `s4` 声明产生的新对象。然后再执行 `s3.intern();` 时，常量池中 `“11”` 对象已经存在了，因此 `s3` 和 `s4` 的引用是不同的。
- 第二段代码中的 `s` 和 `s2` 代码中，`s.intern();`，这一句往后放也不会有什么影响了，因为对象池中在执行第一句代码`String s = new String("1");` 的时候已经生成 `“1”` 对象了。下边的 `s2` 声明都是直接从常量池中取地址引用的。 `s` 和 `s2` 的引用地址是不会相等的。

#### 小结  

从上述的例子代码可以看出 `jdk7` 版本对 `intern` 操作和常量池都做了一定的修改。主要包括2点：

- 将 `String` 常量池 从 `Perm` 区移动到了 `Java Heap` 区
- `String#intern` 方法时，如果存在堆中的对象，会直接保存对象的引用，而不会重新创建对象。

#### 使用范例  

```
static final int MAX = 1000 * 10000;
static final String[] arr = new String[MAX];

public static void main(String[] args) throws Exception {
    Integer[] DB_DATA = new Integer[10];
    Random random = new Random(10 * 10000);
    for (int i = 0; i < DB_DATA.length; i++) {
        DB_DATA[i] = random.nextInt();
    }
	long t = System.currentTimeMillis();
    for (int i = 0; i < MAX; i++) {
        //arr[i] = new String(String.valueOf(DB_DATA[i % DB_DATA.length]));
         arr[i] = new String(String.valueOf(DB_DATA[i % DB_DATA.length])).intern();
    }

	System.out.println((System.currentTimeMillis() - t) + "ms");
    System.gc();
}
```

运行的参数是：`-Xmx2g -Xms2g -Xmn1500M` 上述代码是一个演示代码，其中有两条语句不一样，一条是使用 intern，一条是未使用 intern。

通过上述结果，我们发现不使用 `intern` 的代码生成了 `1000w` 个字符串，占用了大约 `640m` 空间。 使用了 `intern` 的代码生成了 `1345` 个字符串，占用总空间 `133k` 左右。其实通过观察程序中只是用到了 `10` 个字符串，所以准确计算后应该是正好相差 `100w` 倍。虽然例子有些极端，但确实能准确反应出 intern 使用后产生的巨大空间节省。

细心的同学会发现使用了 `intern` 方法后时间上有了一些增长。这是因为程序中每次都是用了 `new String` 后，然后又进行 `intern` 操作的耗时时间，这一点如果在内存空间充足的情况下确实是无法避免的，但我们平时使用时，内存空间肯定不是无限大的，不使用 `intern`占用空间导致 `jvm` 垃圾回收的时间是要远远大于这点时间的。 毕竟这里使用了 `1000w` 次 `intern` 才多出来1秒钟多的时间。

#### 不当使用  

`fastjson` 中对所有的 `json` 的 `key` 使用了 `intern` 方法，缓存到了字符串常量池中，这样每次读取的时候就会非常快，大大减少时间和空间。而且 `json` 的 `key` 通常都是不变的。这个地方没有考虑到大量的 `json key` 如果是变化的，那就会给字符串常量池带来很大的负担。

这个问题 `fastjson` 在`1.1.24`版本中已经将这个漏洞修复了。程序加入了一个最大的缓存大小，超过这个大小后就不会再往字符串常量池中放了



## 对象的生命周期  

一旦一个类被装载、连接和初始化，它就随时可以被使用。程序可以访问它的静态字段，调用它的静态方法，或者创建它的实例。作为Java程序员有必要了解Java对象的生命周期。

### 类实例化  

在Java程序中，类可以被明确或隐含地实例化。明确的实例化类有四种途径：

- 明确调用`new`。
- 调用`Class`或者`java.lang.reflect.Constructor`对象的`newInstance`方法。
- 调用任何现有对象的`clone`。
- 通过`java.io.ObjectInputStream.getObject()`反序列化。

隐含的实例化：

- 可能是保存命令行参数的`String`对象。
- 对于Java虚拟机装载的每个类，都会暗中实例化一个Class对象来代表这个类型
- 当Java虚拟机装载了在常量池中包含`CONSTANT_String_info`入口的类的时候，它会创建新的`String`对象来表示这些常量字符串。
- 执行包含字符串连接操作符的表达式会产生新的对象。

Java编译器为它编译的每个类至少生成一个实例初始化方法。在Java class文件中，这个方法被称为`<init>`。针对源代码中每个类的构造方法，Java编译器都会产生一个`<init>()`方法。如果类没有明确的声明任何构造方法，编译器会默认产生一个无参数的构造方法，它仅仅调用父类的无参构造方法。

一个`<init>()`中可能包含三种代码：调用另一个`<init>()`、实现对任何实例变量的初始化、构造方法体的代码。

如果构造方法明确的调用了同一个类中的另一个构造方法(`this()`)，那么它对应的`<init>()`由两部分组成：

- 一个同类的`<init>()`的调用。
- 实现了对应构造方法的方法体的字节码。

> 在它对应的`<init>()`方法中不会有父类的`<init>()`，但不代表不会调用父类的`<init>()`，因为`this()`中也会调用父类`<init>()`

如果构造方法不是通过一个`this()`调用开始的，而且这个对象不是`Object`，`<init>()`则有三部分组成：

- 一个父类的`<init>()`调用。*如果这个类是`Object`,则没有这个部分*
- 任意实例变量初始化方法的字节码。
- 实现了对应构造方法的方法体的字节码。

如果构造方法明确的调用父类的构造方法`super()`开始，它的`<init>()`会调用对应父类的`<init>()`。比如，如果一个构造方法明确的调用`super(int,String)`开始，对应的`<init>()`会从调用父类的`<init>(int,String)`方法开始。**如果构造方法没有明确地从`this()`或`super()`开始，对应的`<init>()`默认会调用父类的无参`<init>()`。**

### 垃圾收集和对象的终结  

程序可以明确或隐含的为对象分配内存，但不能明确的释放内存。一个对象不再为程序引用，虚拟机必须回收那部分内存。

### 卸载类  

在很多方面，Java虚拟机中类的生命周期和对象的生命周期很相似。当程序不再使用某个类的时候，可以选择卸载它们。

> 类的垃圾收集和卸载值所以在Java虚拟机中很重要，是因为Java程序可以在运行时通过用户自定义的类装载器装载类型来动态的扩展程序。所有被装载的类型都在方法区占据内存空间。

Java虚拟机通过判断类是否在被引用来进行垃圾收集。判断动态装载的类的`Class`实例在正常的垃圾收集过程中是否可触及有两种方式：

- 如果程序保持非`Class`实例的明确引用。
- 如果在堆中还存在一个可触及的对象，在方法区中它的类型数据指向一个`Class`实例。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/touch-class-instance.png)





# 框架

## Netty  

Netty 是一个 异步 事件驱动 的网络应用框架，用于快速开发高性能、可扩展协议的服务器和客户端

### [Reactor](https://www.infoq.cn/article/netty-threading-model)  

无论是 C++ 还是 Java 编写的网络框架，大多数都是基于 Reactor 模式进行设计和开发，Reactor 模式基于事件驱动，特别适合处理海量的 I/O 事件。

[反应器设计模式-维基百科](https://zh.wikipedia.org/wiki/反应器模式) – 反应器设计模式(`Reactor pattern`)是一种为处理服务请求并发 提交到一个或者多个服务处理程序的事件设计模式。当请求抵达后，服务处理程序使用解多路分配策略，然后同步地派发这些请求至相关的请求处理程序。

#### 单线程模型  

Reactor 单线程模型，指的是所有的 IO 操作都在同一个 NIO 线程上面完成，NIO 线程的职责如下：

1. 作为 NIO 服务端，接收客户端的 TCP 连接；
2. 作为 NIO 客户端，向服务端发起 TCP 连接；
3. 读取通信对端的请求或者应答消息；
4. 向通信对端发送消息请求或者应答消息。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/dc7ff89d78fc63558bd02d4515e42f38.png)

由于 `Reactor` 模式使用的是`异步非阻塞 IO`，所有的 `IO` 操作都不会导致阻塞，理论上一个线程可以独立处理所有 `IO` 相关的操作。从架构层面看，一个 `NIO` 线程确实可以完成其承担的职责。例如，通过 `Acceptor` 类接收客户端的 TCP 连接请求消息，链路建立成功之后，通过 `Dispatch` 将对应的 `ByteBuffer` 派发到指定的 `Handler` 上进行消息解码。用户线程可以通过消息编码通过 `NIO` 线程将消息发送给客户端。

对于一些小容量应用场景，可以使用单线程模型。但是 **对于高负载、大并发的应用场景却不合适**。

#### 多线程模型  

Rector 多线程模型与单线程模型最大的区别就是有一组 NIO 线程处理 IO 操作，它的原理图如下：

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2882a43ae27016cc885444b46a735801.png)

Reactor 多线程模型的特点：

1. 有专门一个 `NIO` 线程 `Acceptor` 线程用于监听服务端，接收客户端的 `TCP` 连接请求；
2. 网络 `IO` 操作 - 读、写等由一个 `NIO` 线程池负责，线程池可以采用标准的 `JDK` 线程池实现，它包含一个任务队列和 `N` 个可用的线程，由这些 `NIO` 线程负责消息的读取、解码、编码和发送；
3. 1 个 `NIO` 线程可以同时处理 N 条链路，但是 1 个链路只对应 1 个 `NIO` 线程，防止发生并发操作问题。

#### 主从多线程模型  

主从 `Reactor` 线程模型的特点是：服务端用于接收客户端连接的不再是个 `1` 个单独的 `NIO` 线程，而是一个独立的 `NIO` 线程池。 `Acceptor` 接收到客户端 `TCP` 连接请求处理完成后（可能包含接入认证等），将新创建的 `SocketChannel` 注册到 IO 线程池（`sub reactor` 线程池）的某个 IO 线程上，由它负责 `SocketChannel` 的读写和编解码工作。 `Acceptor` 线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端 `subReactor` 线程池的 `IO` 线程上，由 `IO` 线程负责后续的 `IO` 操作。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/8674352e3cb3638da5807ef88b8f225d.png)

它的工作流程总结如下：

1. 从主线程池中随机选择一个 `Reactor` 线程作为 `Acceptor` 线程，用于绑定监听端口，接收客户端连接；
2. Acceptor 线程接收客户端连接请求之后创建新的 `SocketChannel` ，将其注册到主线程池的其它 Reactor 线程上，由其负责接入认证、IP 黑白名单过滤、握手等操作；
3. 步骤 2 完成之后，业务层的链路正式建立，将 `SocketChannel` 从主线程池的 `Reactor`线程的多路复用器上摘除，重新注册到 `Sub` 线程池的线程上，用于处理 I/O 的读写操作。

### Netty 的优势  

- 多路复用，并在 NIO 的基础上进行更高层次的抽象
- 事件机制
- 功能强大，预置了多种编解码功能，支持多种主流协议
- 定制能力强，可以通过ChannelHandler对通信框架进行灵活的扩展

#### Netty 为什么性能好？  

1. 纯异步：`Reactor` 线程模型
2. IO 多路复用
3. GC 优化：更少的分配内存、池化（Pooling）、复用、选择性的使用 `sun.misc.Unsafe`
4. 更多的硬件相关优化（mechanical sympathy）
5. 内存泄漏检测
6. “Zero Copy”

#### Zero Copy  

Netty 的 Zero-copy 体现在如下几个个方面:

- `Netty` 提供了 `CompositeByteBuf` 类, 它可以将多个 `ByteBuf` 合并为一个逻辑上的 `ByteBuf` , 避免了各个 `ByteBuf` 之间的拷贝.
- 通过 `wrap` 操作, 我们可以将 `byte[]` `数组、ByteBuf` 、 `ByteBuffer` 等包装成一个 `Netty ByteBuf` 对象, 进而避免了拷贝操作.
- `ByteBuf` 支持 `slice` 操作, 因此可以将 `ByteBuf` 分解为多个共享同一个存储区域的 `ByteBuf`, 避免了内存的拷贝.
- 通过 `FileRegion` 包装的 `FileChannel.tranferTo` 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 `Channel` , 避免了传统通过循环 `write` 方式导致的内存拷贝问题.

#### 垃圾回收  

Netty 里 `HeapByteBuffer` 底下的 `byte[]` 能够依赖JVM GC自然回收；而 DirectByteBuffer 底下是 Java 堆外内存，除了等JVM GC，最好也能主动进行回收；所以，Netty ByteBuf需要在 JVM 的 GC 机制之外，有自己的引用计数器和回收过程。

> 原生的 JVM GC 很难回收掉 DirectByteBuffer 所占用的 Native Memory

Netty 中采用引用计数对 DirectByteBuffer 进行对象可达性检测，当 DirectByteBuffer 上的引用计数为 0 时将对象释放。

```java
@Override
public boolean release() {
    for (;;) {
        int refCnt = this.refCnt;
        if (refCnt == 0) {
            throw new IllegalReferenceCountException(0, -1);
        }
        if (refCntUpdater.compareAndSet(this, refCnt, refCnt - 1)) {
            if (refCnt == 1) {
                deallocate();
                return true;
            }
            return false;
        }
    }
}
```

Netty 内存泄漏，主要是针对池化的 ByteBuf 。 ByteBuf 对象被 JVM GC 掉之前，没有调用 `release()` 把底下的 `DirectByteBuffer` 或`byte[]` 归还，会导致池越来越大。而非池化的 ByteBuf ，即使像 `DirectByteBuf` 那样可能会用到 `System.gc()` ，但终归会被 release 掉的，不会出大事。因此 Netty 默认会从分配的 ByteBuf 里抽样出大约 1% 的来进行跟踪。

### 源码  

#### ByteBuf  

1. ByteBuf 扩容采用先倍增后步进的方式

##### DirectBuffer vs HeapBuffer  

在执行网络IO或者文件IO时，如果是使用 `DirectBuffer` 就会少一次内存拷贝。**如果是非 `DirectBuffer` ，JDK 会先创建一个 `DirectBuffer` ，再去执行真正的写操作**。这是因为，当我们把一个地址通过 `JNI` 传递给底层的C库的时候，有一个基本的要求，就是这个地址上的内容不能失效。然而，在 `GC` 管理下的对象是会在 `Java` 堆中移动的。也就是说，有可能我把一个地址传给底层的 `write` ，但是这段内存却因为 `GC` 整理内存而失效了。所以我必须要把待发送的数据放到一个 `GC` 管不着的地方。这就是调用 `native` 方法之前，数据一定要在堆外内存的原因。

#### Netty 启动以及链接建立过程  

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/922e67970b6ac7bf78cd43ac61f7aec0.png)

### Epoll 触发  

有两种模式，一是水平触发（LT），二是边缘触发（ET）。

在LT模式下，只要某个fd还有数据没读完，那么下次轮询还会被选出。而在ET模式下，只有fd状态发生改变后，该fd才会被再次选出。ET模式的特殊性，使在ET模式下的一次轮询必须处理完本次轮询出的fd的所有数据，否则该fd将不会在下次轮询中被选出。

- `NioChannel`：是水平触发
- `EpollChannel`：是边缘触发，Netty 为保证数据完整会在特定条件下自己触发 Epoll Event，来读取数据

### [JDK NIO BUG](https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6403933)  

- 正常情况下，`selector.select()` 操作是阻塞的，只有被监听的 `fd` 有读写操作时，才被唤醒
- 但是，在这个 `bug` 中，没有任何 `fd` 有读写请求，但是 `select()` 操作依旧被唤醒
- 很显然，这种情况下，`selectedKeys()` 返回的是个空数组
- 然后按照逻辑执行到 `while(true)` 处，循环执行，导致死循环。

Netty 解决方案：

```java
long currentTimeNanos = System.nanoTime();
for (;;) {
    // 1.定时任务截止事时间快到了，中断本次轮询
    //...
    // 2.轮询过程中发现有任务加入，中断本次轮询
    //...
    // 3.阻塞式select操作
    selector.select(timeoutMillis);
    // 4.解决jdk的nio bug
    long time = System.nanoTime();
    if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) >= currentTimeNanos) {
        selectCnt = 1;
    } else if (SELECTOR_AUTO_REBUILD_THRESHOLD > 0 &&
            selectCnt >= SELECTOR_AUTO_REBUILD_THRESHOLD) {

        rebuildSelector();
        selector = this.selector;
        selector.selectNow();
        selectCnt = 1;
        break;
    }
    currentTimeNanos = time;
    //...
 }
netty` 会在每次进行 `selector.select(timeoutMillis)` 之前记录一下开始时间 `currentTimeNanos` ，在 `select` 之后记录一下结束时间，**判断 `select` 操作是否至少持续了 `timeoutMillis` 秒**。如果持续的时间大于等于 `timeoutMillis` ，说明就是一次有效的轮询，重置 `selectCnt` 标志，否则，表明该阻塞方法并没有阻塞这么长时间，可能触发了 `jdk` 的空轮询 `bug` ，当空轮询的次数超过一个阀值的时候，默认是 `512` ，就开始重建 `selector
```



## Mybatis面试题  

### `#{}`和`${}`的区别是什么？  

`#{}`是预编译处理，`${}`是字符串替换。

Mybatis 在处理 `#{}` 时，会将sql中的 `#{}` 替换为 `?` 号，调用 `PreparedStatement` 的 `set` 方法来赋值；

Mybatis在处理`${}`时，就是把`${}`替换成变量的值。

使用`#{}`可以有效的防止SQL注入，提高系统安全性。

### 通常一个Xml映射文件，都会写一个Dao接口与之对应，请问，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？  

Dao 接口，就是人们常说的 Mapper 接口，接口的全限名，就是映射文件中的 `namespace`的值，接口的方法名，就是映射文件中 `MappedStatement` 的 id 值，接口方法内的参数，就是传递给sql的参数。

Mapper 接口是没有实现类的，当调用接口方法时，`接口全限名+方法名` 拼接字符串作为 key 值，可唯一定位一个MappedStatement。

在Mybatis中，每一个`<select>、<insert>、<update>、<delete>` 标签，都会被解析为一个 `MappedStatement` 对象。

Dao接口里的方法，是 **不能重载** 的，因为是全限名+方法名的保存和寻找策略。

Dao接口的工作原理是 JDK 动态代理， Mybatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行 `MappedStatement` 所代表的sql，然后将sql执行结果返回。



## Mybatis 缓存机制  

Mybatis 的缓存均缓存查询操作结果。按照作用域范围，可以分为：

```
- **一级缓存**： `SqlSession` 级别的缓存
- **二级缓存**： `namespace` 级别的缓存
```

### 一级缓存  

Mybatis 默认开启了一级缓存， 一级缓存有两个级别可以设置：分别是 `SESSION` 或者 `STATEMENT` 默认是 `SESSION` 级别，即在一个 MyBatis会话中执行的所有语句，都会共享这一个缓存。一种是 `STATEMENT` 级别，可以理解为缓存只对当前执行的这一个 `Statement`有效。

> STATEMENT 级别相当于关闭一级缓存

```
<setting name="localCacheScope" value="SESSION"/>
```

#### 基本原理  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2019-04-05-22-04-22.png)

在一级缓存中，当 `sqlSession` 执行写操作（执行插入、更新、删除），清空 `SqlSession`中的一级缓存。

#### 总结  

- MyBatis 一级缓存的生命周期和SqlSession一致。
- MyBatis 一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。
- MyBatis 的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为Statement。

### 二级缓存  

如果多个 SqlSession 之间需要共享缓存，则需要使用到二级缓存。开启二级缓存后，会使用 CachingExecutor 装饰 Executor ，进入一级缓存的查询流程前，先在C achingExecutor 进行二级缓存的查询，具体的工作流程如下所示。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/2019-04-05-22-10-04.png)

二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享，是一个全局的变量。当开启缓存后，数据的查询执行的流程就是 `二级缓存 -> 一级缓存 -> 数据库`。

```
<setting name="cacheEnabled" value="true"/>
```

#### 总结  

- MyBatis 的二级缓存相对于一级缓存来说，实现了 SqlSession 之间缓存数据的共享，同时粒度更加的细，能够到 namespace 级别，通过 Cache 接口实现类不同的组合，对Cache的可控性也更强。
- MyBatis 在多表查询时，极大可能会出现脏数据，有设计上的缺陷，安全使用二级缓存的条件比较苛刻。
- 在分布式环境下，由于默认的 MyBatis Cache 实现都是基于本地的，分布式环境下必然会出现读取到脏数据，需要使用集中式缓存将 MyBatis 的 Cache 接口实现，有一定的开发成本，直接使用 Redis、Memcached 等分布式缓存可能成本更低，安全性也更高。



## Mybatis 动态代理  

### 获取代理类流程  

获取Mapper代理类的时序图如下：

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/fecd42f80994ebfa775ea5e56166249b.png)

重点说下MapperProxy类，声明如下：

```
public class MapperProxy<T> implements InvocationHandler, Serializable
```

获取到 `MapperProxy` 之后，根据调用不同的方法，会将最终的参数传递给 `SqlSession`。



## Spring  

Spring Framework 是一个开源的Java／Java EE全功能栈（full-stack）的应用程序框架，其提供了一个简易的开发方式，这种开发方式，将避免那些可能致使底层代码变得繁杂混乱的大量的属性文件和帮助类。

### Spring中包含的关键特性  

- 强大的基于JavaBeans的采用 **控制反转** （Inversion of Control，IoC）原则的配置管理，使得应用程序的组建更加快捷简易。
- 一个可用于 Java EE 等运行环境的核心 **Bean 工厂**。
- 数据库事务的一般化抽象层，允许声明式（Declarative）事务管理器，简化事务的划分使之与底层无关。
- 内建的针对 JTA 和单个 JDBC 数据源的一般化策略，使 Spring 的事务支持不要求Java EE环境，这与一般的JTA或者EJB CMT相反。
- JDBC 抽象层提供了有针对性的异常等级（不再从SQL异常中提取原始代码），简化了错误处理，大大减少了程序员的编码量。再次利用JDBC时，你无需再写出另一个’终止’（finally）模块。并且面向JDBC的异常与Spring通用数据访问对象（Data Access Object）异常等级相一致。
- 以资源容器，DAO实现和事务策略等形式与 Hibernate，JDO 和 MyBatis、SQL Maps 集成。利用众多的翻转控制方便特性来全面支持，解决了许多典型的 Hibernate 集成问题。所有这些全部遵从 Spring 通用事务处理和通用数据访问对象异常等级规范。
- 灵活的基于核心 Spring 功能的 MVC 网页应用程序框架。开发者通过策略接口将拥有对该框架的高度控制，因而该框架将适应于多种呈现（View）技术，例如 JSP、FreeMarker、Velocity、Thymeleaf 等。值得注意的是，Spring 中间层可以轻易地结合于任何基于 MVC 框架的网页层，例如 Struts、WebWork 或 Tapestry。
- 提供诸如事务管理等服务的AOP框架。



## IOC  

`Ioc—Inversion of Control`，即“控制反转”，不是什么技术，而是一种设计思想。在Java 开发中，**Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制**。如何理解好Ioc呢？理解好Ioc的关键是要明确“谁控制谁，控制什么，为何是反转（有反转就应该有正转了），哪些方面反转了”，那我们来深入分析一下：

- **谁控制谁，控制什么**：传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对象的创建；谁控制谁？当然是IoC 容器控制了对象；控制什么？那就是主要控制了外部资源获取（不只是对象包括比如文件等）。
- **为何是反转，哪些方面反转了**：有反转就有正转，传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；为何是反转？因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。

### IoC能做什么  

**IoC 不是一种技术，只是一种思想，一个重要的面向对象编程的法则，它能指导我们如何设计出松耦合、更优良的程序**。传统应用程序都是由我们在类内部主动创建依赖对象，从而导致类与类之间高耦合，难于测试；有了IoC容器后，把创建和查找依赖对象的控制权交给了容器，由容器进行注入组合对象，所以对象与对象之间是 松散耦合，这样也方便测试，利于功能复用，更重要的是使得程序的整个体系结构变得非常灵活。

### IoC和DI  

`DI—Dependency Injection`，即“依赖注入”：组件之间依赖关系由容器在运行期决定，形象的说，即由容器动态的将某个依赖关系注入到组件之中。依赖注入的目的并非为软件系统带来更多功能，而是为了提升组件重用的频率，并为系统搭建一个灵活、可扩展的平台。通过依赖注入机制，我们只需要通过简单的配置，而无需任何代码就可指定目标需要的资源，完成自身的业务逻辑，而不需要关心具体的资源来自何处，由谁实现。

理解DI的关键是：“谁依赖谁，为什么需要依赖，谁注入谁，注入了什么”，那我们来深入分析一下：

- **谁依赖于谁**：当然是应用程序依赖于IoC容器；
- **为什么需要依赖**：应用程序需要IoC容器来提供对象需要的外部资源；
- **谁注入谁**：很明显是IoC容器注入应用程序某个对象，应用程序依赖的对象；
- **注入了什么**：就是注入某个对象所需要的外部资源（包括对象、资源、常量数据）。

IoC和DI由什么关系呢？其实它们是同一个概念的不同角度描述，由于控制反转概念比较含糊（可能只是理解为容器控制对象这一个层面，很难让人想到谁来维护对象关系），所以2004年大师级人物Martin Fowler又给出了一个新的名字：“依赖注入”，**相对IoC 而言，“依赖注入”明确描述了“被注入对象依赖IoC容器配置依赖对象”**。

### IOC vs Factory  

简单来说，IOC 与 工厂模式 分别代表了 push 与 pull 的机制：

- Pull 机制：类间接依赖于 Factory Method ，而 Factory Method 又依赖于具体类。
- Push 机制：容器可以在一个位置配置所有相关组件，从而促进高维护和松耦合。

**使用 工厂模式 的责任仍然在于类（尽管间接地）来创建新对象，而 依赖注入 将责任外包**。

### 循环依赖  

Spring 为了解决单例的循环依赖问题，使用了 三级缓存 ，递归调用时发现 Bean 还在创建中即为循环依赖

```
/** 一级缓存：用于存放完全初始化好的 bean **/
private final Map<String, Object> singletonObjects = new ConcurrentHashMap<String, Object>(256);

/** 二级缓存：存放原始的 bean 对象（尚未填充属性），用于解决循环依赖 */
private final Map<String, Object> earlySingletonObjects = new HashMap<String, Object>(16);

/** 三级级缓存：存放 bean 工厂对象，用于解决循环依赖 */
private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<String, ObjectFactory<?>>(16);

/**
bean 的获取过程：先从一级获取，失败再从二级、三级里面获取

创建中状态：是指对象已经 new 出来了但是所有的属性均为 null 等待被 init
*/
```

1. A 创建过程中需要 B，于是 A 将自己放到三级缓里面 ，去实例化 B
2. B 实例化的时候发现需要 A，于是 B 先查一级缓存，没有，再查二级缓存，还是没有，再查三级缓存，找到了！
   1. 然后把三级缓存里面的这个 A 放到二级缓存里面，并删除三级缓存里面的 A
   2. B 顺利初始化完毕，将自己放到一级缓存里面（此时B里面的A依然是创建中状态）
3. 然后回来接着创建 A，此时 B 已经创建结束，直接从一级缓存里面拿到 B ，然后完成创建，并将自己放到一级缓存里面
4. 如此一来便解决了循环依赖的问题



## 设计模式  

- 代理模式：AOP
- 单例模式：默认 Bean 为单例
- 工厂模式：BeanFactory
- IOC：依赖倒置 or 依赖注入
- MVC：spring web
- 模版方法模式：JdbcTemplate



## AOP  

### AOP 的存在价值  

在传统 OOP 编程里以对象为核心，整个软件系统由系列相互依赖的对象所组成，而这些对象将被抽象成一个一个的类，并允许使用类继承来管理类与类之间一般到特殊的关系。随着软件规模的增大，应用的逐渐升级，慢慢出现了一些 OOP 很难解决的问题。

我们可以通过分析、抽象出一系列具有一定属性与行为的对象，并通过这些对象之间的协作来形成一个完整的软件功能。由于对象可以继承，因此我们可以把具有相同功能或相同特性的属性抽象到一个层次分明的类结构体系中。随着软件规范的不断扩大，专业化分工越来越系列，以及 OOP 应用实践的不断增多，随之也暴露出了一些 OOP 无法很好解决的问题。

现在假设系统中有 3 段完全相似的代码，这些代码通常会采用“复制”、“粘贴”方式来完成，通过这种“复制”、“粘贴”方式开发出来的软件如图 1 所示。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/3bef1bcb3f17058a37b698ed19f5d269.png)

看到如上图所示的示意图，可能有的读者已经发现了这种做法的不足之处：如果有一天，上图中的深色代码段需要修改，那是不是要打开 3 个地方的代码进行修改？如果不是 3 个地方包含这段代码，而是 100 个地方，甚至是 1000 个地方包含这段代码段，那会是什么后果？

为了解决这个问题，我们通常会采用将如上图所示的深色代码部分定义成一个方法，然后在 3 个代码段中分别调用该方法即可。在这种方式下，软件系统的结构如下图所示。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/ce93a1de7bf20653cea82987d6a9f9a4.png)



# 系统架构

## 系统架构基础  

分布式系统的最大难点，就是各个节点的状态如何同步。CAP 定理是这方面的基本定理，也是理解分布式系统的起点。

1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。

```
Consistency
Availability
Partition tolerance
```

它们的第一个字母分别是 `C`、`A`、`P`。Eric Brewer 说，这三个指标不可能同时做到。这个结论就叫做 `CAP` 定理。

### CAP  

它指出对于一个分布式计算系统来说，不可能同时满足以下三点：

- 一致性（Consistency） （等同于所有节点访问同一份最新的数据副本）
- 可用性（Availability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）
- 分区容错性（Partition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。）

#### 数据一致性模型  

一些分布式系统通过复制数据来提高系统的可靠性和容错性，并且将数据的不同的副本存放在不同的机器，由于维护数据副本的一致性代价高，因此许多系统采用弱一致性来提高性能，一些不同的一致性模型也相继被提出。

- **强一致性**： 要求无论更新操作实在哪一个副本执行，之后所有的读操作都要能获得最新的数据。
- **弱一致性**：用户读到某一操作对系统特定数据的更新需要一段时间，我们称这段时间为“不一致性窗口”。
- **最终一致性**：是弱一致性的一种特例，保证用户最终能够读取到某操作对系统特定数据的更新。

##### 一致性解决方案  

1. 分布式事务：两段提交
2. 分布式锁
3. MQ 消息持久化 重试 幂等
4. Paxos 算法

#### 服务可用性  

可用性，意思是只要收到用户的请求，服务器就必须给出回应。

##### 高可用解决方案  

- **负载均衡**：
- **降级**：当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。
- **熔断**：对于目标服务的请求和调用大量超时或失败，这时应该熔断该服务的所有调用，并且对于后续调用应直接返回，从而快速释放资源，确保在目标服务不可用的这段时间内，所有对它的调用都是立即返回，不会阻塞的。再等到目标服务好转后进行接口恢复。
- **流量控制**：
- **异地多活**：

熔断是减少由于下游服务故障对自己的影响；而降级则是在整个系统的角度上，考虑业务整体流量，保护核心业务稳定。

#### 分区容错性  

大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。

般来说，分区容错无法避免，因此可以认为 CAP 的 `P` 总是成立。CAP 定理告诉我们，剩下的 `C` 和 `A` 无法同时做到。



## 高并发系统设计  

### 总览  

在高并发的情景下进行系统设计，

可以分为以下 6 点：

- 系统拆分
  - 熔断
  - 降级
- 缓存
- MQ
- 分库分表
- 读写分离
- ElasticSearch

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/high-concurrency-system-design.png)

#### 系统拆分  

将一个系统拆分为多个子系统，用 RPC 来搞。然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。

#### 缓存  

大部分的高并发场景，都是读多写少，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟 Redis 轻轻松松单机几万的并发。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。

#### MQ  

可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据库几十次，增删改增删改。那高并发绝对搞挂你的系统，你要是用 Redis 来承载写那肯定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 MySQL 还得用 MySQL 啊。那你咋办？用 MQ 吧，大量的写请求灌入 MQ 里，后边系统消费后慢慢写，控制在 MySQL 承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。

#### 分库分表  

分库分表，可能到了最后数据库层面还是免不了抗高并发的要求，好吧，那么就将一个数据库拆分为多个库，多个库来扛更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高 SQL 跑的性能。

#### 读写分离  

读写分离，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。

#### ElasticSearch  

ES 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 ES 来承载，还有一些全文搜索类的操作，也可以考虑用 ES 来承载。



## 高并发下的流量控制  

这个时候如果不做任何保护措施，服务器就会承受很大的处理压力，请求量很高，服务器负载也很高，并且当请求超过服务器承载极限的时候，系统就会崩溃，导致所有人都不能访问。

为了应用服务的高可用，一个常用的办法是对大流量的请求（秒杀/抢购）进行限流，拦截掉大部分请求，只允许一部分请求真正进入后端服务器，这样就可以防止大量请求造成系统压力过大导致的系统崩溃，从而保护服务正常可用。

`令牌桶(Token Bucket)`、`漏桶(leaky bucket)`和 `计数器` 算法是最常用的三种限流的算法。

### 限流算法  

#### 计数器  

计数器限流算法也是比较常用的，主要用来限制总并发数。比如限流 `qps` 为 `100` ，算法的实现思路就是从第一个请求进来开始计时，在接下去的 `1s` 内，每来一个请求，就把计数加 `1` ，如果累加的数字达到了 `100` ，那么后续的请求就会被全部拒绝。等到 `1s` 结束后，把计数恢复成 `0` ，重新开始计数。

这种实现方式有一个弊端：如果我在单位时间 `1s` 内的前 `10ms` ，已经通过了 `100` 个请求，那后面的 `990ms` ，只能眼巴巴的把请求拒绝，这种现象称为 **突刺现象**。

#### 漏桶  

为了消除 **突刺现象**，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。

不管服务调用方多么不稳定，通过漏桶算法进行限流，每 `10` 毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/cee6a24bae2f1146d8f905a9ede12c23.png)

在算法实现方面，可以 **准备一个队列，用来保存请求，另外通过一个线程池定期从队列中获取请求并执行，可以一次性获取多个并发执行**。

这种算法，在使用过后也存在弊端：**无法应对短时间的突发流量**，同时它的优点也是可以平滑网络上的突发流量，请求可以被整形成稳定的流量。

#### 令牌桶  

从某种意义上讲，**令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用**。

在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。

放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置 `qps` 为 `100` ，那么限流器初始化完成一秒后，桶中就已经有 100 个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的 `100` 个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/cc2bf6c40bcccedb3e6bb2471ef36e53.png)

实现思路：可以 **准备一个队列，用来保存令牌，另外通过一个线程池定期生成令牌放到队列中，每来一个请求，就从队列中获取一个令牌，并继续执行**。

> 漏桶 VS 令牌桶：两者主要区别在于“漏桶算法”能够强行限制数据的传输速率，而“令牌桶算法”在能够限制数据的平均传输速率外，还允许某种程度的突发传输。在“令牌桶算法”中，只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，所以它适合于具有突发特性的流量。

### 集群限流  

#### Redis 请求窗口  

> 采用redis 的计时和计数方式,在规定的时间窗口期,允许通过的最大请求数量

比如为了限制某个资源被每个用户或者商户的访问次数，5s 只能访问 2 次，或者一天只能调用 1000 次，这种需求，单机限流是无法实现的，这时就需要通过集群限流进行实现。

如何实现？为了控制访问次数，肯定需要一个计数器，而且这个计数器只能保存在第三方服务，比如redis。

大概思路：每次有相关操作的时候，就向 `redis` 服务器发送一个 `incr` 命令，比如需要限制某个用户访问 `/index` 接口的次数，只需要拼接用户 id 和接口名生成 `redis` 的 `key` ，每次该用户访问此接口时，只需要对这个 `key` 执行 `incr` 命令，在这个 `key` 带上过期时间，就可以实现指定时间的访问频率。

#### Nginx 限流  

Nginx按请求速率限速模块使用的是漏桶算法，即能够强行保证请求的实时处理速度不会超过设置的阈值。

Nginx官方版本限制IP的连接和并发分别有两个模块：

- `limit_req_zone` 用来限制单位时间内的请求数，即速率限制,采用的漏桶算法 “leaky bucket”。
- `limit_req_conn` 用来限制同一时间连接数，即并发限制。



## 短链接  

### 使用场景(Scenario)  

微博和Twitter都有140字数的限制，如果分享一个长网址，很容易就超出限制，发布出去。短网址服务可以把一个长网址变成短网址，方便在社交网络上传播。

### 需求(Needs)  

很显然，要尽可能的短。长度设计为多少才合适呢？

### 短网址的长度  

当前互联网上的网页总数大概是 45 亿，45亿 超过了 2^{32}232 ，但远远小于64位整数的上限值，那么用一个64位整数足够了。微博的短网址服务用的是长度为 `7` 的字符串，这个字符串可以看做是 62 进制的数，那么最大能表示 62^7627 个网址，远远大于 45 亿。所以长度为 7 就足够了。这个量级远远超过互联网上的 URL 总数了，绝对够用了。现代的 web 服务器（例如Apache, Nginx）大部分都区分 URL 里的大小写了，所以用大小写字母来区分不同的 URL 是没问题的。因此，正确答案：长度不超过7的字符串，由大小写字母加数字共 62 个字母组成。

### 一对一还是一对多映射？  

一个长网址，对应一个短网址，还是可以对应多个短网址？ 这也是个重大选择问题。一般而言，一个长网址，在不同的地点，不同的用户等情况下，生成的短网址应该不一样，这样，在后端数据库中，可以更好的进行数据分析。如果一个长网址与一个短网址一一对应，那么在数据库中，仅有一行数据，无法区分不同的来源，就无法做数据分析了。

以这个7位长度的短网址作为唯一ID，这个ID下可以挂各种信息，比如生成该网址的用户名，所在网站，HTTP头部的 User Agent等信息，收集了这些信息，才有可能在后面做大数据分析，挖掘数据的价值。短网址服务商的一大盈利来源就是这些数据。

正确答案：一对多

### 如何计算短网址  

现在我们设定了短网址是一个长度为7的字符串，如何计算得到这个短网址呢？

将 62^7627 的 ID 进行分段，比如分为 N 段，前 K 位一致。那么剩下的位就可以通过 Redis 来进行生成，防止重复。

### 如何存储  

如果存储短网址和长网址的对应关系？以短网址为 `primary key`, 长网址为`value`, 可以用传统的关系数据库存起来，例如`MySQL,PostgreSQL`，也可以用任意一个分布式 KV 数据库，例如`Redis, LevelDB`。

### 301还是302重定向  

这也是一个有意思的问题。这个问题主要是考察你对301和302的理解，以及浏览器缓存机制的理解。

301是永久重定向，302是临时重定向。短地址一经生成就不会变化，所以用301是符合http语义的。但是如果用了301， `Google`，`百度`等搜索引擎，搜索的时候会直接展示真实地址，那我们就无法统计到短地址被点击的次数了，也无法收集用户的`Cookie`, `User Agent`等信息，这些信息可以用来做很多有意思的大数据分析，也是短网址服务商的主要盈利来源。

所以，正确答案是302重定向。

可以抓包看看mrw.so的短网址是怎么做的，使用 Chrome 浏览器，访问这个URL `http://mrw.so/4UD39p`，是我事先发微博自动生成的短网址。来抓包看看返回的结果是啥，可见新浪微博用的就是302临时重定向。



### 问题场景  

在进行系统设计的过程中，首先问题场景的特点。秒杀系统是十分典型的高并发场景，其特点也十分显著：高并发、低库存、高瞬时流量。再者分析整个系统的输入输出，即大概的 API 网关拥有的功能：查（用户查询商品信息）、改（用户购买商品）。将系统的特点和功能分析完毕后，就可以根据这些信息进行系统设计。一个常规的秒杀系统从前到后，依次有：

```log
 前端页面 -> 代理服务 -> 后端服务 -> 数据库
```

根据这个流程，一般优化设计思路：将 **请求拦截在系统上游，降低下游压力**。在一个并发量大，实际需求小的系统中，应当尽量在前端拦截无效流量，降低下游服务器和数据库的压力，不然很可能造成数据库读写锁冲突，甚至导致死锁，最终请求超时。

整体优化手段包含：**缓存**、**限流**、**削峰（MQ）**、**异步处理**、**降级**、**熔断**、**SET化**、**快速扩容**

### 前端页面  

- 资源静态化：将活动页面上的所有可以静态的元素全部静态化，尽量减少动态元素；通过CDN缓存静态资源，来抗峰值。
- 禁止重复提交：用户提交之后按钮置灰，禁止重复提交
- URL动态化：防止恶意抓取

### 代理服务  

利用负载均衡（例如 Nginx 等）使用多个服务器并发处理请求，减小服务器压力。

### 后端服务  

- 用户限流：在某一时间段内只允许用户提交一次请求，比如可以采取 IP 限流
- 业务拆分
- 利用 MQ 削峰
- 利用缓存应对大量查询请求
- 利用缓存应对写请求（注意数据一致性、持久性问题）：缓存也是可以应对写请求的，可把数据库中的库存数据转移到 Redis 缓存中，所有减库存操作都在 Redis 中进行，然后再通过后台进程把Redis中的用户秒杀请求同步到数据库中。

### 数据库  

- 多数据库：防止数据热点问题
- 优化 SQL 防止死锁



## 分布式

### 一致性  

在分布式系统中，一致性(Consistency，早期也叫 Agreement)是指对于系统中的多个服务节点，给定一系列操作，在协议（往往通过某种共识算法）保障下，试图使得它们对处理结果达成某种程度的一致。

> 一致性并不代表结果正确与否，而是系统对外呈现的状态一致与否，例如，所有节点都达成失败状态也是一种一致。

#### 分布式的挑战  

在实际的计算机集群系统（看似强大的计算机系统，很多地方都比人类世界要脆弱的多）中，存在如下的问题：

1. 节点之间的网络通讯是不可靠的，包括任意延迟和内容故障；
2. 节点的处理可能是错误的，甚至节点自身随时可能宕机；
3. 同步调用会让系统变得不具备可扩展性。

要解决这些挑战，愿意动脑筋的读者可能会很快想出一些不错的思路。为了简化理解，仍然以两个电影院一起卖票的例子。可能有如下的解决思路：

1. 每次要卖一张票前打电话给另外一家电影院，确认下当前票数并没超售；
2. 两家电影院提前约好，奇数小时内一家可以卖票，偶数小时内另外一家可以卖；
3. 成立一个第三方的存票机构，票都放到他那里，每次卖票找他询问；

这些思路大致都是可行的。实际上，这些方法背后的思想，**将可能引发不一致的并行操作进行串行化**，就是现在计算机系统里处理分布式一致性问题的基础思路和唯一秘诀。只是因为计算机系统比较傻，需要考虑得更全面一些；而人们又希望计算机系统能工作的更快更稳定，所以算法需要设计得再精巧一些。

规范的说，理想的分布式系统一致性应该满足：

1. 可终止性（Termination）：一致的结果在有限时间内能完成；
2. 共识性（Consensus）：不同节点最终完成决策的结果应该相同；
3. 合法性（Validity）：决策的结果必须是其它进程提出的提案。

第一点很容易理解，这是计算机系统可以被使用的前提。需要注意，在现实生活中这点并不是总能得到保障的，例如取款机有时候会是 `服务中断` 状态，电话有时候是 `无法连通` 的。

第二点看似容易，但是隐藏了一些潜在信息。算法考虑的是任意的情形，凡事一旦推广到任意情形，就往往有一些惊人的结果。例如现在就剩一张票了，中关村和西单的电影院也分别刚确认过这张票的存在，然后两个电影院同时来了一个顾客要买票，从各自观察看来，自己的顾客都是第一个到的……怎么能达成结果的共识呢？记住我们的唯一秘诀：**核心在于需要把两件事情进行排序，而且这个顺序还得是大家都认可的**。

第三点看似绕口，但是其实比较容易理解，即达成的结果必须是节点执行操作的结果。仍以卖票为例，如果两个影院各自卖出去一千张，那么达成的结果就是还剩八千张，决不能认为票售光了。

#### 强一致性  

##### 线性一致性  

线性一致性或称 **原子一致性** 或 **严格一致性** 指的是程序在执行的历史中在存在可线性化点P的执行模型，这意味着一个操作将在程序的调用和返回之间的某个点P起作用。这里“起作用”的意思是被系统中并发运行的所有其他线程所感知。要求如下：

1. **写后读** 这里写和读是两个操作，如果写操作在完成之后，读才开始，读要能读到最新的数据，而且保证以后也能读操作也都能读到这个最新的数据。
2. **所有操作的时序与真实物理时间一致**，要求即使不相关的两个操作，如果执行有先后顺序，线性一致性要求最终执行的结果也需要满足这个先后顺序。比如，操作序列(写A，读A，写B，读B)，那么不仅，读A，读B能读到最新A值和B值；而且要保证，如果读B读到最新值时，读A一定也能读到最新值，也就是需要保证执行时序与真实时序相同。
3. 如果两个操作是并发的(比如读A没有结束时，写B开始了)，那么这个并发时序不确定，但从最终执行的结果来看，要确保所有线程(进程，节点)看到的执行序列是一致的。

##### 顺序一致性  

相比线性一致性，主要区别在于，**对于物理上有先后顺序的操作，不保证这个时序**。具体而言，对于单个线程，操作的顺序仍然要保留，对于多个线程(进程，节点)，执行的事件的先后顺序与物理时钟顺序不保证。但是要求，从执行结果来看，所有线程(进程，节点)看到的执行序列是一样的。

##### 线性一致性和顺序一致性。  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/consenus_linearizability_sequential.png)

1. 图1 是顺序一致性：从这两个进程的角度来看，顺序应该是这样的 `write(y,2) -> read(x,0) -> write(x,4) -> read(y,2)` ，每个进程内部的读写顺序都是合理的，但是这个顺序与全局时钟下看到的顺序并不一样，`write(x,4)` 先于 `read(x,0)` 执行，但是 read 却没有读到最新值。
2. 图2 是线性一致性：每个读操作都读到了该变量的最新写的结果，同时 **两个进程看到的操作顺序与全局时钟的顺序一样**，都是 `write(y,2) -> write(x,4) -> read(x,4) -> read(y,2)`。
3. 图3 不符合顺序一致性，更加不符合线性一致性，两个进程内部的顺序可能是：`write(x,4) -> read(y,0) -> write(y,2) -> read(x,0)`、或者：`write(y,2) -> read(x,0) -> write(x,4) -> read(y,0)` 显然两个顺序又不能同时被 P1、P2 满足，因此这个顺序是有冲突的，不满足顺序一致性。

##### 因果一致性  

因果一致性，被认为是比 顺序一致性 更弱的一致性，在因果一致性中，只对有因果关系的事件有顺序要求。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/causal_consistency.png)

对于 `P1` 和 `P2` 的操作是没有先后关系的，因此谁先发生都是可以的。

- 从 P3 的视角来看，操作执行序列是 `w(x,7) -> r(x,7) -> w(x,2) -> r(x,2) -> w(x,4)`
- 从 P4 的视角来看，操作执行序列是 `w(x,2) -> w(x,4) -> r(x,4) -> w(x,7) -> r(x,7)`

但是不同进程看到的执行序列不一样，所以不符合顺序一致性。

#### 带约束的一致性  

绝对理想的 **强一致性（Strong Consistency）** 代价很大。除非不发生任何故障，所有节点之间的通信无需任何时间，这个时候其实就等价于一台机器了。实际上，越强的一致性要求往往意味着越弱的性能、越低的可用性。

强一致的系统往往比较难实现。很多时候，人们发现实际需求并没有那么强，可以适当放宽一致性要求，降低系统实现的难度。例如在一定约束下实现所谓 **最终一致性（Eventual Consistency）**，即总会存在一个时刻（而不是立刻），系统达到一致的状态，这对于大部分的 Web 系统来说已经足够了。这一类弱化的一致性，被笼统称为 **弱一致性（Weak Consistency）**。

##### 最终一致性  

最终一致性也被称为 **乐观复制(optimistic replication)**，用户只能读到某次更新后的值，但系统保证数据将最终达到完全一致的状态，只是所需时间不能保障。这个达成一致所需要的时间，我们称为 **窗口时间**。

我们常见的 **异步复制的主从架构实现的是最终一致性** 。它的一个典型常见是用户读取异步从库时，可能读取到较旧的信息，因为该从库尚未完全与主库同步。注意，同步复制的主从架构会出现任一节点宕机导致的单点问题。

### 共识算法  

**共识算法解决的是对某个提案（Proposal），大家达成一致意见的过程**。提案的含义在分布式系统中十分宽泛，如多个事件发生的顺序、某个键对应的值、谁是领导……等等，可以认为任何需要达成一致的信息都是一个提案。

> 实践中，一致性的结果往往还需要客户端的特殊支持，典型地通过访问足够多个服务节点来验证确保获取共识后结果。

#### 拜占庭问题  

拜占庭将军问题描述了一个如下的场景，有一组将军分别指挥一部分军队，每一个将军都不知道其它将军是否是可靠的，也不知道其他将军传递的信息是否可靠，但是它们需要通过投票选择是否要进攻或者撤退。

在这时，无论将军是否可靠，只要所有的将军达成了统一的方案，选择进攻或者撤退其实就是没有任何问题的。上述的情况不会对当前的战局有太多的影响，也不会造成损失，但是如果其中的一个将军告诉其中一部分将军选择进攻、另一部分选择撤退，就会出现非常严重的问题了。

由于将军的队伍中出了一个叛徒或者信息在传递的过程中被拦截，会导致一部分将军会选择进攻，剩下的一部分会选择撤退，它们都认为自己的选择是大多数人的选择，这时就出现了严重的不一致问题。

**拜占庭将军问题是对分布式系统容错的最高要求**，然而这不是日常工作中使用的大多数分布式系统中会面对的问题，我们遇到更多的还是节点故障宕机或者不响应等情况，这就大大简化了系统对容错的要求。

#### 问题挑战  

实际上，如果分布式系统中各个节点都能保证以十分强大的性能（瞬间响应、高吞吐）无故障的运行，则实现共识过程并不复杂，简单通过多播过程投票即可。

很可惜的是，现实中这样完美的系统并不存在，如响应请求往往存在时延、网络会发生中断、节点会发生故障、甚至存在恶意节点故意要破坏系统。

一般地，把故障（不响应）的情况称为 `非拜占庭错误` ，恶意响应的情况称为 `拜占庭错误`（对应节点为拜占庭节点）。

#### 常见算法  

针对非拜占庭错误的情况，一般包括 `Paxos`、`Raft` 及其变种。

对于要能容忍拜占庭错误的情况，一般包括 `PBFT` 系列、 `PoW` 系列算法等。从概率角度，PBFT 系列算法是确定的，一旦达成共识就不可逆转；而 PoW 系列算法则是不确定的，随着时间推移，被推翻的概率越来越小。

#### 理论界限  

搞学术的人都喜欢对问题先确定一个界限，那么，这个问题的最坏界限在哪里呢？很不幸，**一般情况下，分布式系统的共识问题无解**。

当节点之间的通信网络自身不可靠情况下，很显然，无法确保实现共识。但好在，一个设计得当的网络可以在大概率上实现可靠的通信。然而，即便在网络通信可靠情况下，一个可扩展的分布式系统的共识问题的下限是无解。

这个结论，被称为 **FLP 不可能性** 原理，可以看做分布式领域的“测不准原理”。

#### FLP  

FLP 不可能定理是分布式系统领域最重要的定理之一，它给出了一个非常重要的结论：**在网络可靠并且存在节点失效的异步模型系统中，不存在一个可以解决一致性问题的确定性算法**。

这个定理其实也就是告诉我们不要浪费时间去为异步分布式系统设计在任意场景上都能够实现共识的算法，异步系统完全没有办法保证能在有限时间内达成一致。理解这一原理的一个不严谨的例子是：

三个人在不同房间，进行投票（投票结果是 0 或者 1）。三个人彼此可以通过电话进行沟通，但经常会有人时不时地睡着。比如某个时候，`A` 投票 0，`B` 投票 1，`C` 收到了两人的投票，然后 `C` 睡着了。`A` 和 `B` 则永远无法在有限时间内获知最终的结果。如果可以重新投票，则类似情形每次在取得结果前发生。

这岂不是意味着研究一致性问题压根没有意义吗？

先别这么悲观，学术界做研究，考虑的是数学和物理意义上最极端的情形，很多时候现实生活要美好的多。Paxos算法的场景比FLP的系统模型还要松散，除了异步通信，Paxos允许消息丢失（通信不健壮），但Paxos却被认为是最牛的一致性算法，其作者 Lamport 也获得2014年的图灵奖，这又是为什么？

其实仔细回忆Paxos论文会发现， **Paxos 中存在活锁，理论上的活锁会导致 Paxos 算法无法满足 Termination 属性，也就不算一个正确的一致性算法**。Lamport 在自己的论文中也提到 `FLP结果表明，不存在完全满足一致性的异步算法...` ，因此他建议通过 `Leader` 来代替 Paxos 中的 `Proposer` ，而 `Leader` 则通过随机或其他方式来选定（Paxos中假如随机过程会极大降低FLP发生的概率）。也就是说Paxos算法其实也不算理论上完全正确的，只是在工程实现中避免了一些理论上存在的问题。

> 科学告诉你什么是不可能的；工程则告诉你，付出一些代价，我可以把它变成可能。

### 一致性（Consistency）与共识（Consensus）  

我们常说的 **一致性（Consistency）** 在分布式系统中指的是 `副本（Replication）` 问题中对于同一个数据的多个副本，其对外表现的数据一致性，如 `线性一致性` 、`因果一致性`、`最终一致性`等，都是用来描述副本问题中的一致性的。

而 **共识（Consensus）** 则不同，共识问题中所有的节点要最终达成共识，由于最终目标是所有节点都要达成一致，所以根本 **不存在一致性强弱** 之分。

只有当你使用像 `Paxos` 这样的共识算法作为解决副本问题的核心组件时，才会对外展现出不同的一致性级别。但是，即使是在这样的场景下，讨论一个共识算法的一致性也是不合适的，因为 **整个副本系统最终的一致性并不单单取决于共识算法** ，Client 访问所遵循的规范也会有决定性的作用。比如说：即使副本系统使用 **multi-paxos** 在所有副本服务器上同步了日志序号，但如果 Client 被允许从非 Leader 节点获取数据，则整个副本系统仍然不是强一致的。

### CAP  

分布式计算系统不可能同时确保一致性（Consistency）、可用性（Availablity）和分区容忍性（Partition），设计中往往需要弱化对某个特性的保证。

- **一致性（Consistency - 线性一致性）**：任何操作应该都是原子的，发生在后面的事件能看到前面事件发生导致的结果，注意这里指的是强一致性；
- **可用性（Availablity）**：在有限时间内，任何非失败节点都能应答请求；
- **分区容忍性（Partition）**：网络可能发生分区，即节点之间的通信不可保障。

比较直观地理解，当网络可能出现分区时候，系统是无法同时保证一致性和可用性的。要么，节点收到请求后因为没有得到其他人的确认就不应答，要么节点只能应答非一致的结果。

好在大部分时候网络被认为是可靠的，因此系统可以提供一致可靠的服务；当网络不可靠时，系统要么牺牲掉一致性（大部分时候都是如此），要么牺牲掉可用性。

既然 CAP 不可同时满足，则设计系统时候必然要弱化对某个特性的支持。

#### 弱化一致性  

对结果一致性不敏感的应用，可以允许在新版本上线后过一段时间才更新成功，期间不保证一致性。例如网站静态页面内容、实时性较弱的查询类数据库等，CouchDB、Cassandra 等为此设计。

#### 弱化可用性  

对结果一致性很敏感的应用，例如银行取款机，当系统故障时候会拒绝服务。MongoDB、Redis 等为此设计。Paxos、Raft 等算法，主要处理这种情况。

#### 弱化分区容忍性  

现实中，网络分区出现概率减小，但较难避免。某些关系型数据库、ZooKeeper 即为此设计。实践中，网络通过双通道等机制增强可靠性，达到高稳定的网络通信。

### Paxos  

Paxos 其实是一类能够解决分布式一致性问题的协议，它能够让分布式网络中的节点在出现错误时仍然保持一致；Leslie Lamport 提出的 Paxos 可以在没有恶意节点的前提下保证系统中节点的一致性，也是第一个被证明完备的共识算法，目前的完备的共识算法包括 Raft 本质上都是 Paxos 的变种。

#### Basic Paxos  

Basic Paxos 是 Paxos 中最为基础的协议，每一个 Basic Paxos 的协议实例最终都会选择唯一一个结果；使用 Paxos 作为共识算法的分布式系统中，节点都会有三种身份，分别是 `Proposer`、`Acceptor` 和 `Learner`。

Paxos 的运行过程分为两个阶段，分别是准备阶段（Prepare）和接受阶段（Accept），当 Proposer 接收到来自客户端的请求时，就会进入如下流程：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/basic-paxos-phases.png)

在整个共识算法运行的过程中，Proposer 负责提出提案并向 Acceptor 分别发出两次 RPC 请求，Prepare 和 Accept；Acceptor 会根据其持有的信息 `minProposal`、`acceptedProposal` 和 `acceptedValue` 选择接受或者拒绝当前的提案，当某一个提案被过半数的 Acceptor 接受之后，我们就认为当前提案被整个集群接受了。

#### Multi-Paxos  

由于大多数的分布式集群都需要接受一系列的值，如果使用 Basic Paxos 来处理数据流，那么就会导致非常明显的性能损失，而 Multi-Paxos 是前者的加强版，如果集群中的 Leader 是非常稳定的，那么我们往往不需要准备阶段的工作，这样就能够将 RPC 的数量减少一半。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/multi-paxos-example.png)

上述图片中描述的就是稳定阶段 Multi-Paxos 的处理过程，S1 是整个集群的 Leader，当其他的服务器接收到来自客户端的请求时，都会将请求转发给 Leader 进行处理。

当然，Leader 角色的出现自然会带来另一个问题，也就是 Leader 究竟应该如何选举，在 Paxos Made Simple 一文中并没有给出 Multi-Paxos 的具体实现方法和细节，所以不同 Multi-Paxos 的实现上总有各种各样细微的差别。

### Raft  

Raft 其实就是 Multi-Paxos 的一个变种，Raft 通过简化 Multi-Paxos 的模型，实现了一种更容易让人理解的共识算法，它们两者都能够对一系列连续的问题达成一致。

Raft 在 Multi-Paxos 的基础之上做了两个限制，首先是 Raft 中追加日志的操作必须是连续的，而 Multi-Paxos 中追加日志的操作是并发的，但是对于节点内部的状态机来说两者都是有序的，第二就是 Raft 对 Leader 选举的条件做了限制，只有拥有最新、最全日志的节点才能够当选 Leader，但是 Multi-Paxos 由于任意节点都可以写日志，所以在选择 Leader 上也没有什么限制，只是在选择 Leader 之后需要将 Leader 中的日志补全。

在 Raft 中，所有 Follower 的日志都是 Leader 的子集，而 Multi-Paxos 中的日志并不会做这个保证，由于 Raft 对日志追加的方式和选举过程进行了限制，所以在实现上会更加容易和简单。

从理论上来讲，**支持并发日志追加的 Paxos 会比 Raft 有更优秀的性能，不过其理解和实现上还是比较复杂的**，很多人都会说 Paxos 是科学，而 Raft 是工程，当作者需要去实现一个共识算法，会选择使用 Raft 和更简洁的实现，避免因为一些边界条件而带来的复杂问题。

Raft协议将一致性协议的核心内容分拆成为几个关键阶段，以简化流程，提高协议的可理解性。

#### Leader election  

Raft协议的每个副本都会处于三种状态之一：

- Leader：所有请求的处理者，Leader副本接受client的更新请求，本地处理后再同步至多个其他副本
- Follower：请求的被动更新者，从Leader接受更新请求，然后写入本地日志文件
- Candidate：如果 Follower 副本在一段时间内没有收到 Leader 副本的心跳，则判断 Leader 可能已经故障，此时启动选主过程，此时副本会变成 Candidate 状态，直到选主结束。

**时间被分为很多连续的随机长度的 term ， term 有唯一的 id，每个 term 最多只有一个 Leader** 。每个 term 一开始就进行选主：

1. Follower 将自己维护的 `current_term_id` 加 1。
2. 然后将自己的状态转成 `Candidate`
3. 发送 `RequestVoteRPC` 消息(带上 `current_term_id` ) 给 其它所有 Server

本轮选举成功，当收到了 majority 的投票后，状态切成 Leader ，并且定期给其它的所有 Server 发心跳消息（不带 Log 的 `AppendEntriesRPC` ）以告诉对方自己是 `current_term_id` 所标识的 term 的 Leader 。`term id` 作为`Logical clock`，在每个 RPC 消息中都会带上，用于**检测过期**的消息。

- 当一个 Server 收到的 RPC 消息中的 `rpc_term_id` 比本地的 `current_term_id` 更大时，就更新 `current_term_id` 为 `rpc_term_id` ，并且如果当前 state 为 Leader 或者 candidate 时，将自己的状态切成 follower。
- 当 `rpc_term_id` 比本地的 `current_term_id` 更小，则拒绝这个RPC消息。

本轮选举失败，则没有任何一个 candidate 收到了 majority 的 vote 时，没有 Leader 被选出。这种情况下，每个 candidate 等待的投票的过程就超时了，接着 candidates 都会将本地的 `current_term_id` 再加1，再等待 `150ms ~ 300ms` 之后随机发起 `RequestVoteRPC` 进行新一轮的 Leader election，以避免再次选主失败。

#### Log Replication  

当 Leader 被选出来后，就可以接受客户端发来的请求了，每个请求包含一条需要被 `replicated state machines` 执行的命令。 Leader 会把它作为一个 Log Entry append 到日志中，然后给其它的 Server 发 AppendEntriesRPC 请求。当 Leader 确定一个 Log Entry 被 `safely replicated` 了（大多数副本已经将该命令写入日志当中），就 apply 这条 Log Entry 到状态机中然后返回结果给客户端。如果某个 Follower 宕机了或者运行的很慢，或者网络丢包了，则会一直给这个 Follower 发 AppendEntriesRPC 直到日志一致。

当一条日志是 commited 时，Leader 才可以将它应用到状态机中。Raft 保证一条 commited 的 Log Entry 已经持久化了并且会被所有的节点执行。当一个新的 Leader 被选出来时，它的日志和其它的 Follower 的日志可能不一样，这个时候，就需要一个机制来保证日志的一致性。

因此，需要有一种机制来让 Leader 和 Follower 对 Log 达成一致， Leader 会为每个 Follower 维护一个 `nextIndex` ，表示 Leader 给各个 Follower 发送的下一条 Log Entry 在 Log 中的 `index` ，初始化为 Leader 的最后一条 Log Entry 的下一个位置。leader 给 Follower 发送 AppendEntriesRPC 消息，带着 `(term_id, nextIndex-1)`， `term_id` 即 `nextIndex-1` 这个槽位的 Log Entry `的term_id` ，Follower 接收到 AppendEntriesRPC 后，会从自己的 Log 中找是不是存在这样的 Log Entry，如果不存在，就给 Leader 回复拒绝消息，然后 Leader 则将 `nextIndex` 减1，再重复，直到 AppendEntriesRPC 消息被接收。

#### Safety  

Raft 保证被选为新 Leader 的节点拥有所有已提交的 Log Entry。这个保证是在 RequestVoteRPC 阶段做的，candidate 在发送 RequestVoteRPC 时，会带上自己的最后一条日志记录的 `term_id,index` ，其他节点收到消息时，**如果发现自己的日志比 RPC 请求中携带的更新，拒绝投票**。日志比较的原则是，如果本地的最后一条 Log Entry 的 `term id` 更大，则更新，如果 `term id` 一样大，则 index 更大的更大。

#### Log Compaction  

在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响 availability 。Raft 采用对整个系统进行 snapshot 来处理， snapshot 之前的日志都可以丢弃。Snapshot 技术在 Chubby 和 ZooKeeper 系统中都有采用。

Raft使用的方案是：**每个副本独立的对自己的系统状态进行 Snapshot ，并且只能对已经提交的日志记录（已经应用到状态机）进行snapshot**。

### POW  

无论是 Paxos 还是 Raft 其实都只能解决非拜占庭将军容错的一致性问题，不能够应对分布式网络中出现的极端情况，但是这在传统的分布式系统都不是什么问题，无论是分布式数据库还是消息队列集群，它们内部的节点并不会故意的发送错误信息，在类似系统中，最常见的问题就是节点失去响应或者失效，所以它们在这种前提下是有效可行的，也是充分的。

**工作量证明（POW，Proof-of-Work）** 是一个用于阻止拒绝服务攻击和类似垃圾邮件等服务错误问题的协议，它在 1993 年被 Cynthia Dwork 和 Moni Naor 提出，它能够帮助分布式系统达到拜占庭容错。

工作量证明的关键特点就是，分布式系统中的请求服务的节点必须解决一个一般难度但是可行（feasible）的问题，但是验证问题答案的过程对于服务提供者来说却非常容易，也就是一个**不容易解答但是容易验证**的问题。

工作量证明的原理其实非常简单，比特币网络选择的谜题非常好的适应了工作量证明定义中的问题，比较难以寻找同时又易于证明，我们可以简单理解为工作量证明防止错误或者无效请求的原理就是增加客户端请求服务的工作量，而适合难度的谜题又能够保证合法的请求不会受到影响。

由于工作量证明需要消耗大量的算力，同时比特币大约 10min 才会产生一个区块，区块的大小也只有 1MB，仅仅能够包含 3、4000 笔交易，平均下来每秒只能够处理 5~7（个位数）笔交易，所以比特币网络的拥堵状况非常严重。

### 可靠性指标  

很多领域一般都喜欢谈服务可靠性，用几个 9 来说事。这几个 9 其实是粗略代表了概率意义上系统能提供服务的可靠性指标，最初是电信领域提出的概念。

下表给出不同指标下，每年允许服务出现不可用时间的参考值。

| 指标   | 概率可靠性  | 每年允许不可用时间 | 典型场景 |
| ------ | ----------- | ------------------ | -------- |
| 一个九 | 90%         | 1.2 个月           | 不可用   |
| 二个九 | 99%         | 3.6 天             | 普通单点 |
| 三个九 | 99.9%       | 8.6 小时           | 普通企业 |
| 四个九 | 99.99%      | 51.6 分钟          | 高可用   |
| 五个九 | 99.999%     | 5 分钟             | 电信级   |
| 六个九 | 99.9999%    | 31 秒              | 极高要求 |
| 七个九 | 99.99999%   | 3 秒               | N/A      |
| 八个九 | 99.999999%  | 0.3 秒             | N/A      |
| 九个九 | 99.9999999% | 30 毫秒            | N/A      |

一般来说，单点的服务器系统至少应能满足两个九；普通企业信息系统三个九就肯定足够了（大家可以统计下自己企业内因系统维护每年要停多少时间），系统能达到四个九已经是业界领先水平了（参考 AWS）。电信级的应用一般号称能达到五个九，这已经很厉害了，一年里面最多允许五分钟的服务停用。

那么，该如何提升可靠性呢？有两个思路：一是让系统中的单点变得更可靠；二是消灭单点。然而，依靠单点实现的可靠性毕竟是有限的，要想进一步的提升，那就只好消灭单点，通过主从、多活等模式让多个节点集体完成原先单点的工作。这可以**从概率意义上改善服务的可靠性，也是分布式系统的一个重要用途**。



## 分布式缓存  

高并发环境下，例如典型的淘宝双11秒杀，几分钟内上亿的用户涌入淘宝，这个时候如果访问不加拦截，让大量的读写请求涌向数据库，由于磁盘的处理速度与内存显然不在一个量级，服务器马上就要宕机。**从减轻数据库的压力和提高系统响应速度两个角度来考虑，都会在数据库之前加一层缓存**，访问压力越大的，在缓存之前就开始 CDN 拦截图片等访问请求。

并且由于最早的单台机器的内存资源以及承载能力有限，如果大量使用本地缓存，也会使相同的数据被不同的节点存储多份，对内存资源造成较大的浪费，因此，才催生出了分布式缓存。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/36bb3e9d1be0ea97b3e836dc467a9c87.png)

### 应用场景  

1. **页面缓存**：用来缓存Web 页面的内容片段,包括HTML、CSS 和图片等;
2. **应用对象缓存**：缓存系统作为ORM 框架的二级缓存对外提供服务,目的是减轻数据库的负载压力,加速应用访问;解决分布式Web部署的 session 同步问题，状态缓存.缓存包括Session 会话状态及应用横向扩展时的状态数据等,这类数据一般是难以恢复的,对可用性要求较高,多应用于高可用集群。
3. **并行处理**：通常涉及大量中间计算结果需要共享;
4. **云计算领域提供分布式缓存服务**

### 常见问题和挑战  

#### 缓存雪崩  

缓存雪崩我们可以简单的理解为：由于原有缓存失效、新缓存未到之间(**例如：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期**)，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。

#### 缓存穿透  

缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。**这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空**（*相当于进行了两次无用的查询*）。这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。

#### 缓存预热  

缓存预热这个应该是一个比较常见的概念，相信很多小伙伴都应该可以很容易的理解，缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

#### 缓存更新  

除了缓存服务器自带的缓存失效策略之外，我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：

1. 定时去清理过期的缓存；
2. 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。

两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂！具体用哪种方案，大家可以根据自己的应用场景来权衡。

#### 缓存降级  

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

降级的最终目的是 **保证核心服务可用，即使是有损的**。而且有些服务是无法降级的（如加入购物车、结算）。

在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

1. **一般**：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
2. **警告**：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
3. **错误**：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
4. **严重错误**：比如因为特殊原因数据错误了，此时需要紧急人工降级。

#### 缓存与数据库不一致问题  

首先，缓存由于其高并发和高性能的特性，已经在项目中被广泛使用。在读取缓存方面，大家没啥疑问，都是按照下图的流程来进行业务操作。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/995c5ddf11013119937692d6448da2e8.png)

但是在更新缓存方面，对于更新完数据库，是更新缓存呢，还是删除缓存。又或者是先删除缓存，再更新数据库，其实大家存在很大的争议。

从理论上来说，给 **缓存设置过期时间，是保证最终一致性的解决方案**。这种方案下，我们可以对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。

##### 先删除缓存，再更新数据库  

该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库

上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

可以通过：

1. 更新操作数据库后，再次更新缓存来实现
2. 缓存设置过期时间，等待过期时间后，数据恢复



## 分布式锁  

### Redis 锁  

#### 单节点 Redis 锁  

锁的获取：

```
SET resource_name my_random_value NX PX 30000
```

锁释放：

```
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

##### 缺陷  

由于超时时间导致锁被多 Client 同时获取：

1. C1 获取锁 A 成功，但由于 GC 等原因线程挂起，锁 A 过期
2. C2 获取锁 A 成功
3. C1 & C2 同时认为自己加锁成功

异步的主从复制 & Master 宕机，导致锁丢失：

1. C1 获取锁 A 成功，Master 宕机，Slave 未同步到锁 A
2. C2 获取锁 A 成功
3. C1 & C2 同时认为自己加锁成功

#### RedLock  

为了解决 Redis 单点的问题。 Redis 的作者提出了 RedLock 的解决方案。方案非常的巧妙和简洁。 RedLock 的核心思想就是，**同时使用多个 Redis Master 来冗余，且这些节点都是完全的独立的，也不需要对这些节点之间的数据进行同步**。

假设我们有N个Redis节点，N应该是一个大于2的奇数。RedLock的实现步骤:

1. 取得当前时间
2. 使用单节点获取锁的方式，依次获取 N 个节点的 Redis 锁。
3. 如果获取到的锁的数量大于 N/2+1*N*/2+1 个，且获取的时间小于锁的有效时间(lock validity time)就认为获取到了一个有效的锁，锁自动释放时间就是最初的锁释放时间减去之前获取锁所消耗的时间。
4. 如果获取锁的数量小于 N/2+1*N*/2+1 ，或者在锁的有效时间(lock validity time)内没有获取到足够的锁，就认为获取锁失败，这个时候需要向所有节点发送释放锁的消息。

对于释放锁的实现就很简单了，向所有的 Redis 节点发起释放的操作，无论之前是否获取锁成功。

#### 缺陷  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/fencing-tokens.png)

RedLock中，为了防止死锁，锁是具有过期时间的。

- 如果 Client 1 在持有锁的时候，发生了一次很长时间的 FGC 超过了锁的过期时间。锁就被释放了。
- 这个时候 Client 2 又获得了一把锁，提交数据。
- 这个时候 Client 1 从 FGC 中苏醒过来了，又一次提交数据。

这种情况下，数据就发生了错误。RedLock 只是保证了锁的高可用性，并没有保证锁的正确性。

解决方案可以为锁增加一个自增标识，类似于 Kafka 脑裂的处理方式：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/fencing-tokens-solve.png)

同时 RedLock 是严重依赖系统时钟的一致性。如果某个 Redis Master的系统时间发生了错误，造成了它持有的锁提前过期被释放。

> 每一个系统设计都有自己的侧重或者局限。工程也不是完美的。在现实中工程中不存在完美的解决方案。我们应当深入了解其中的原理，了解解决方案的优缺点。明白选用方案的局限性。是否可以接受方案的局限带来的后果。架构本来就是一门平衡的艺术。

### 实现基于数据库的乐观锁  

提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。

```
Connection conn = DriverManager.getConnection(url, user, password);
conn.setAutoCommit(false);
Statement stmt = conn.createStatement();
// step 1
int oldVersion = getOldVersion(stmt);

// step 2
// 用这个数据库连接做其他的逻辑

// step 3 可用预编译语句
int i = stmt.executeUpdate(
        "update optimistic_lock set version = " + (oldVersion + 1) + " where version = " + oldVersion);

// step 4
if (i > 0) {
    conn.commit(); // 更新成功表明数据没有被修改，提交事务。
} else {
    conn.rollback(); // 更新失败，数据被修改，回滚。
}
```

乐观锁的缺点：

- 会带来大数量的无效更新请求、事务回滚，给DB造成不必要的额外压力。
- 无法保证先到先得，后面的请求可能由于并发压力小了反而有可能处理成功。

### 基于 ZooKeeper 的分布式锁  

基于 ZK 的特性，很容易得出使用 ZK 实现分布式锁的落地方案：

1. 使用 ZK 的临时节点和有序节点，每个线程获取锁就是在 ZK 创建一个临时有序的节点，比如在 `/lock/` 目录下。
2. 创建节点成功后，获取 `/lock` 目录下的所有临时节点，再判断当前线程创建的节点是否是所有的节点的序号最小的节点。
3. 如果当前线程创建的节点是所有节点序号最小的节点，则认为获取锁成功。
4. 如果当前线程创建的节点不是所有节点序号最小的节点，则对节点序号的 **前一个节点** 添加一个事件监听。

#### 缺陷  

1. **羊群效应**：当一个节点变化时，会触发大量的 `watches` 事件，导致集群响应变慢。每个节点尽量少的 `watches`，这里就只注册 **前一个节点** 的监听
2. ZK 集群的读写吞吐量不高
3. 网络抖动可能导致 Session 离线，锁被释放



## 分布式事务  

分布式事务的实现主要有以下 5 种方案：

- XA 方案
- TCC 方案
- 可靠消息最终一致性方案
- 最大努力通知方案

### 2PC/XA方案  

所谓的 XA 方案，即：两阶段提交，有一个事务管理器的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先问问各个数据库你准备好了吗？如果每个数据库都回复 ok，那么就正式提交事务，在各个数据库上执行操作；如果任何其中一个数据库回答不 ok，那么就回滚事务。

这种分布式事务方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。

一般来说某个系统内部如果出现跨多个库的这么一个操作，是不合规的。如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库。

### TCC强一致性方案  

TCC 的全称是：`Try`、`Confirm`、`Cancel`。

- **Try 阶段**：这个阶段说的是对各个服务的资源做检测以及对资源进行 **锁定或者预留**。
- **Confirm 阶段**：这个阶段说的是在各个服务中执行实际的操作。
- **Cancel 阶段**：如果任何一个服务的业务方法执行出错，那么这里就需要 **进行补偿**，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）
- 

这种方案说实话几乎很少人使用，但是也有使用的场景。因为这个 **事务回滚实际上是严重依赖于你自己写代码来回滚和补偿** 了，会造成补偿代码巨大，非常之恶心。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/distributed-transaction-TCC.png)

### 可靠消息最终一致性方案  

基于 MQ 来实现事务。比如阿里的 RocketMQ 就支持消息事务。大概的意思就是：

1. A 系统先发送一个 prepared 消息到 MQ，如果这个 prepared 消息发送失败那么就直接取消操作别执行了；
2. 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 MQ 发送确认消息，如果失败就告诉 MQ 回滚消息；
3. 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务；
4. mq 会自动定时轮询所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。
5. 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。

这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你举用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。

### 最大努力通知方案  

这个方案的大致意思就是：

1. 系统 A 本地事务执行完之后，发送个消息到 MQ；
2. 这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口；
3. 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。



## MQ  

消息队列技术(Message Queue) 是分布式应用间交换信息的一种技术。消息队列可驻留在内存或磁盘上, 队列存储消息直到它们被应用程序读走。通过消息队列，应用程序可独立地执行 ———— 它们不需要知道彼此的位置、或在继续执行前不需要等待接收程序接收此消息。在分布式计算环境中，为了集成分布式应用，开发者需要对异构网络环境下的分布式应用提供有效的通信手段。

### MQ使用场景  

1. **异步通信**：有些业务不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。
2. **解耦**：降低工程间的强依赖程度，针对异构系统进行适配。在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。通过消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口，当应用发生变化时，可以独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束
3. **冗余**：有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。
4. **扩展性**：因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。便于分布式扩容
5. **过载保护**：在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量无法提取预知；如果以为了能处理这类瞬间峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃
6. **可恢复性**：系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。 
7. **顺序保证**：在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。 
8. **缓冲**：在任何重要的系统中，都会有需要不同的处理时间的元素。消息队列通过一个缓冲层来帮助任务最高效率的执行，该缓冲有助于控制和优化数据流经过系统的速度。以调节系统响应时间。
9. **数据流处理**：分布式系统产生的海量数据流，如：业务日志、监控数据、用户行为等，针对这些数据流进行实时或批量采集汇总，然后进行大数据分析是当前互联网的必备技术，通过消息队列完成此类数据收集是最好的选择

### MQ缺点  

1. 系统可用性降低：系统引入的外部依赖越多，越容易挂掉。本来你就是 `A` 系统调用 `BCD` 三个系统的接口就好了， `ABCD` 四个系统好好的，没啥问题，你偏加个 `MQ` 进来，万一 `MQ` `挂了咋整，MQ` 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用。
2. 系统复杂度提高：硬生生加个 `MQ` 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。
3. 一致性问题： `A` 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 `BCD` 三个系统那里， `BD` 两个系统写库成功了，结果 `C` 系统写库失败了，咋整？你这数据就不一致了。

### MQ常用协议  

- **AMQP协议** AMQP即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同开发语言等条件的限制。

  > 优点：可靠、通用

- **MQTT协议** MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协议，有可能成为物联网的重要组成部分。该协议支持所有平台，几乎可以把所有联网物品和外部连接起来，被用来当做传感器和致动器（比如通过Twitter让房屋联网）的通信协议。 

  > 优点：格式简洁、占用带宽小、移动端通信、PUSH、嵌入式系统

- **STOMP协议** STOMP（Streaming Text Orientated Message Protocol）是流文本定向消息协议，是一种为MOM(Message Oriented Middleware，面向消息的中间件)设计的简单文本协议。STOMP提供一个可互操作的连接格式，允许客户端与任意STOMP消息代理（Broker）进行交互。 

  > 优点：命令模式（非topic/queue模式）

- **XMPP协议** XMPP（可扩展消息处理现场协议，Extensible Messaging and Presence Protocol）是基于可扩展标记语言（XML）的协议，多用于即时消息（IM）以及在线现场探测。适用于服务器之间的准即时操作。核心是基于XML流传输，这个协议可能最终允许因特网用户向因特网上的其他任何人发送即时消息，即使其操作系统和浏览器不同。

  > 优点：通用公开、兼容性强、可扩展、安全性高，但XML编码格式占用带宽大

- **其他基于TCP/IP自定义的协议**：有些特殊框架（如：redis、kafka、zeroMq等）根据自身需要未严格遵循MQ规范，而是基于TCP\IP自行封装了一套协议，通过网络socket接口进行传输，实现了MQ的功能。

### MQ的通讯模式  

1. **点对点通讯**：点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。
2. **多点广播**：MQ适用于不同类型的应用。其中重要的，也是正在发展中的是"多点广播"应用，即能够将消息发送到多个目标站点(Destination List)。可以使用一条MQ指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。MQ不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，MQ将消息的一个复制版本和该系统上接收者的名单发送到目标MQ系统。目标MQ系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。
3. **发布/订阅(Publish/Subscribe)模式**：发布/订阅功能使消息的分发可以突破目的队列地理指向的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅功能使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。在MQ家族产品中，MQ Event Broker是专门用于使用发布/订阅技术进行数据通讯的产品，它支持基于队列和直接基于TCP/IP两种方式的发布和订阅。
4. **集群(Cluster)**：为了简化点对点通讯模式中的系统配置，MQ提供 Cluster 的解决方案。集群类似于一个 域(Domain) ，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用 Cluster 通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性

### 消息投递保证  

- `At most once`：消息可能会丢，但绝不会重复投递
- `At least one`：消息绝不会丢，但可能会重复投递
- `Exactly once`：每条消息肯定会被投递一次且仅投递一次，很多时候这是用户所想要的。



## [Zookeeper](https://draveness.me/zookeeper-chubby)  

> ZK 不是解决分布式问题的银弹

### 分布式应用  

分布式应用可以在给定时间（同时）在网络中的多个系统上运行，通过协调它们以快速有效的方式完成特定任务。通常来说，**对于复杂而耗时的任务，非分布式应用（运行在单个系统中）需要几个小时才能完成，而分布式应用通过使用所有系统涉及的计算能力可以在几分钟内完成**。

通过将分布式应用配置为在更多系统上运行，可以进一步减少完成任务的时间。分布式应用正在运行的一组系统称为 **集群**，而在集群中运行的每台机器被称为 **节点**。

#### 分布式应用的优点  

- 可靠性：单个或几个系统的故障不会使整个系统出现故障。
- 可扩展性：可以在需要时增加性能，通过添加更多机器，在应用程序配置中进行微小的更改，而不会有停机时间。
- 透明性：隐藏系统的复杂性，并将其显示为单个实体/应用程序。

#### 分布式应用的挑战  

- 竞争条件：两个或多个机器尝试执行特定任务，实际上只需在任意给定时间由单个机器完成。例如，共享资源只能在任意给定时间由单个机器修改。
- 死锁：两个或多个操作等待彼此无限期完成。
- 不一致：数据的部分失败。

### ZooKeeper基础  

Apache ZooKeeper是由集群（节点组）使用的一种服务，用于在自身之间协调，并通过稳健的同步技术维护共享数据。ZooKeeper本身是一个分布式应用程序，为写入分布式应用程序提供服务。

ZooKeeper 的好处：

- 简单的分布式协调过程
- 同步：服务器进程之间的相互排斥和协作。
- 有序性
- 序列化：根据特定规则对数据进行编码(Jute)。
- 可靠性
- 原子性：数据转移完全成功或完全失败，但没有事务是部分的。

#### 架构  

一个 ZooKeeper 集群通常由一组机器组成，一般 3 台以上就可以组成一个可用的 ZooKeeper 集群了。组成 `ZooKeeper` 集群的每台机器都会在内存中维护当前的服务器状态，并且每台机器之间都会互相保持通信。 ZooKeeper 本身就是一个 **复制和分布式** 应用程序，其目的作为服务运行，类似于我们运行 DNS 或任何其他集中式服务的方式。

> ZK 集群 **半数以上存活** 即可用

ZooKeeper 的客户端程序会选择和集群中的任意一台服务器创建一个 TCP 连接，而且一旦客户端和服务器断开连接，客户端就会自动连接到集群中的其他服务器。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/cde28984c2c32a5068b2b31d5ba2040f.png)

| 部分              | 描述                                                         |
| ----------------- | ------------------------------------------------------------ |
| Client（客户端）  | 客户端是我们的分布式应用集群中的一个节点，从服务器访问信息。对于特定的时间间隔，每个客户端向服务器发送消息以使服务器知道客户端是活跃的。类似地，当客户端连接时，服务器发送确认码。如果连接的服务器没有响应，客户端会自动将消息重定向到另一个服务器。 |
| Server（服务器）  | 服务器，我们的ZooKeeper总体中的一个节点，为客户端提供所有的服务。向客户端发送确认码以告知服务器是活跃的。 |
| ZooKeeper Service | ZooKeeper服务器组。形成 Service 所需的最小节点数为3。        |
| Leader            | 服务器节点，如果任何连接的节点失败，则执行自动恢复。Leader在服务启动时被选举。 |
| Follower          | 用于接受客户端请求并向客户端返回结果，在选主过程中参与投票   |
| Observer          | 接受客户端连接，将写请求转发给leader，但 observer **不参与** 投票过程，只同步 leader 的状态， observer 的目的是为了扩展系统，提高读取速度 |

#### 数据模型  

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/944a3ed0ab807a87b5c562c58a31ea2b.png)

到znode是一个标准的文件系统，层次结构很像一棵树。 需要注意的一些要点如下：

- 根节点有一个名为 `/zoo` 的子节点，它又有三个 `znode` 。
- ZooKeeper 树中的每个 `znode` 都由一个路径标识，路径元素由`/`分隔。
- 这些节点被称为数据寄存器，因为它们可以存储数据。 因此，一个 znode 可以有子节点以及与之相关的数据。 这与文件系统可以把文件作为路径很类似。

znode 中的数据通常以字节格式存储，**每个 znode 中的最大数据大小不超过1 MB**。 ZooKeeper 是为协调而设计的，几乎所有形式的协调数据都比较小， 因此，对数据大小的限制是强制的。

与文件系统中的文件一样， `znode` 维护一个 `stat` 结构，其中包含数据更改的 **版本号** 以及随更改相关的时间戳而更改的 **访问控制列表（ACL）**。 只要 znode 的数据发生变化，版本号就会增加。 ZooKeeper 使用版本号以及相关的时间戳来验证它的核心内缓存。 znode 版本号还允许客户端通过 ZooKeeper API 更新或删除特定的 znode。 如果指定的版本号与 znode 的当前版本不匹配，则操作失败。 但是，执行 znode 更新或删除操作时，可以通过指定 0 作为版本号来覆盖。

#### Znode  

- **persistent**：即使在创建该特定znode的客户端断开连接后，持久节点仍然存在。默认情况下，除非另有说明，否则所有znode都是持久的。
- **ephemeral**：客户端活跃时，临时节点就是有效的。当客户端与 ZooKeeper 集合断开连接时，临时节点会自动删除。因此，只有临时节点不允许有子节点。如果临时节点被删除，则下一个合适的节点将填充其位置。临时节点在 leader 选举中起着重要作用。
- **sequential**：顺序节点可以是持久的或临时的。当一个新的 znode 被创建为一个顺序节点时，ZooKeeper 通过将 **10位** 的序列号附加到原始名称来设置 znode 的路径。例如，如果将具有路径 `/myapp` 的znode创建为顺序节点，则ZooKeeper会将路径更改为 `/myapp0000000001` ，并将下一个序列号设置为`0000000002`。如果两个顺序节点是同时创建的，那么 ZooKeeper **不会对每个znode使用相同的数字**。顺序节点在锁定和同步中起重要作用。

#### Sessions  

会话对于 ZooKeeper 的操作非常重要。会话中的请求按 FIFO 顺序执行。一旦客户端连接到服务器，将建立会话并向客户端分配 **会话ID** 。

客户端 **以特定的时间间隔发送心跳** 以保持会话有效。如果 ZooKeeper 集合在超过服务器开启时指定的期间（会话超时）都没有从客户端接收到心跳，则它会判定客户端死机。

会话超时通常以毫秒为单位。当会话由于任何原因结束时，在该会话期间创建的临时节点也会被删除。

#### Watcher  

`ZooKeeper` 的设计是一种可伸缩的、健壮的集中式服务。在客户端访问此类服务时，常见的设计模式是通过轮询或拉式（pull）模型。当在大型和复杂的分布式系统中实现时，拉模型常常会受到可伸缩性问题的影响。为了解决这个问题，ZooKeeper设计了一种机制，**客户端可以从 ZooKeeper 服务中获取通知。客户端接收到这个消息通知之后，需要主动到服务端获取最新的数据**。

客户可以使用 `ZooKeeper` 服务注册与 `znode` 相关的任何更改。 这种注册被称为在 `ZooKeeper` 术语中的 `znode` 上设置 `watch`。 监视允许客户以任何方式更改 `znode` 时收到通知。 **`Watcher` 是一次性操作**，这意味着它只触发一个通知。 要继续接收通知，客户必须在收到每个事件通知后重新注册一个监视。

监视触发：

- 对 znode 数据的任何更改，例如使用 `setData` 操作将新数据写入 znode 的数据字段时。
- 对 znode 的子节点的任何更改。 例如，一个 znode 的子节点被删除。
- 正在创建或删除的 znode ，如果将新的 znode 添加到路径中或现有的 znode 被删除，则可能发生这种情况。

同样，ZooKeeper 针对监视和通知声明以下保证：

- ZooKeeper 确保监视始终以先进先出（FIFO）方式排序，并且通知总是按顺序发送
- 在对同一个 znode 进行任何其他更改之前，监视会将通知发送给客户端
- 监视事件的顺序是按照 ZooKeeper 服务的更新顺序排列的

### Zookeeper 工作流程  

一旦 ZooKeeper 集合启动，它将等待客户端连接。客户端将连接到 ZooKeeper 集合中的一个节点。它可以是 leader 或 follower 节点。一旦客户端被连接，节点将向特定客户端分配 `会话ID` 并向该客户端发送确认。如果客户端没有收到确认，它将尝试连接 ZooKeeper 集合中的另一个节点。 一旦连接到节点，客户端将以有规律的间隔向节点发送 **心跳**，以确保连接不会丢失。

- **如果客户端想要读取特定的znode**，它将会向具有znode路径的节点发送读取请求，并且节点通过从其自己的数据库获取来返回所请求的znode。为此，在ZooKeeper集合中读取速度很快。
- **如果客户端想要将数据存储在ZooKeeper集合中**，则会将 znode 路径和数据发送到服务器。**连接的服务器将该请求转发给 leader，然后leader将向所有的follower重新发出写入请求。如果只有大部分节点成功响应，而写入请求成功，则成功返回代码将被发送到客户端**。 否则，写入请求失败。绝大多数节点被称为 Quorum 。

#### ZooKeeper Service 节点数量的影响  

- 如果我们有 **单个节点**，则当该节点故障时，ZooKeeper Service 将故障。即“单点故障”，不建议在生产环境中使用。
- 如果我们有 **两个节点** 而一个节点故障，我们没有占多数，ZooKeeper Service 故障，因为两个中的一个不是多数。
- 如果我们有 **三个节点** 而一个节点故障，那么我们有大多数，因此，这是 **最低要求**。ZooKeeper集合在实际生产环境中必须至少有三个节点。
- 如果我们有 **四个节点** 而两个节点故障，它将再次故障。类似于有三个节点，额外节点不用于任何目的，因此，最好添加奇数的节点，例如 3，5，7。

我们知道写入过程比 ZooKeeper 集合中的读取过程要耗时，因为 **所有节点都需要在数据库中写入相同的数据**。因此，对于平衡的环境拥有较少数量（例如3，5，7）的节点比拥有大量的节点要好。

### ZAB 协议  

ZAB 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。

- 读取时：客户端连接 zk 的任一节点，节点直接拿出自己对应的数据返回，这时该节点扮演 Observer 角色；
- 写入时：客户端的任一提交都会由 Leader 去广播给所有的节点，有半数以上的节点写入成功即视为写入成功；

ZAB 的所有动作都是节点们通过协议同步的。在 ZAB 协议的事务编号 `Zxid` 设计中， `Zxid` 是一个 64 位的数字，其中低 32 位是一个简单的单调递增的计数器，针对客户端每一个事务请求，计数器加 1；而高 32 位则代表 Leader 周期 epoch 的编号，每个当选产生一个新的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务的 ZXID ，并从中读取 epoch 值，然后加 1，以此作为新的 epoch，并将低 32 位从 0 开始计数。

epoch 可以理解为当前集群所处的年代或者周期，每个 leader 就像皇帝，都有自己的年号，所以每次改朝换代，leader 变更之后，都会在前一个年代的基础上加 1。这样就算旧的 leader 崩溃恢复之后，也没有人听他的了，因为 follower 只听从当前年代的 leader 的命令。

ZAB 协议有两种模式，**崩溃恢复（选主+数据同步）和消息广播（事务操作）**。任何时候都需要保证只有一个主进程负责进行事务操作，而如果主进程崩溃了，就需要迅速选举出一个新的主进程。主进程的选举机制与事务操作机制是紧密相关的。

#### 消息广播  

在 zookeeper 集群中，数据副本的传递策略就是采用消息广播模式。 zookeeper 中数据副本的同步方式与二段提交相似。二段提交要求协调者必须等到所有的参与者全部反馈 ACK 确认消息后，再发送 commit 消息。要求所有的参与者要么全部成功，要么全部失败，因此二段提交会产生严重的阻塞问题。 Zab 协议中 Leader 等待半数以上的Follower成功反馈即可，不需要收到全部Follower反馈。消息广播具体步骤：

1. 客户端发起一个写操作请求。
2. Leader 服务器将客户端的请求转化为事务 Proposal 提案，同时为每个 Proposal 分配一个全局的ID，即 zxid。
3. Leader 服务器为每个 Follower 服务器分配一个单独的队列，然后将需要广播的 Proposal 依次放到队列中取，并且根据 FIFO 策略进行消息发送。
4. Follower 接收到 Proposal 后，会首先将其以事务日志的方式写入本地磁盘中，写入成功后向 Leader 反馈一个 Ack 响应消息。
5. Leader 接收到超过半数以上 Follower 的 Ack 响应消息后，即认为消息发送成功，可以发送 commit 消息。
6. Leader 向所有 Follower 广播 commit 消息，同时自身也会完成事务提交。Follower 接收到 commit 消息后，会将上一条事务提交。

#### 崩溃恢复  

##### 数据同步  

主从架构下，leader 崩溃，为了保证数据一致性，会在选出新leader后进入恢复阶段，新 leader 具有所有已经提交的提议，因此它会保证让 followers 同步已经提交的提议，丢弃未提交的提议（以 leader 的记录为准）

##### 选举  

下面任何一种情况，都会触发 Leader 选举：

- 启动时，集群服务器刚启动
- 运行时，Leader 崩溃

服务器的状态流转：

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/641361c1efdb212bdba9b74168d6334b.png)

Leader 选举过程，本质就是 **广播优先级消息** 的过程，选出 **数据最新的服务节点**，选出优先级最高的服务节点，基本步骤：

- 各个服务器节点，广播自己的优先级标识 `(sid，zxid)`
- 服务器节点收到其他广播消息后，跟自己的优先级（zxid）对比，自己优先级低，则变更当前节点投票的优先级`(sid，zxid)` ，并广播变更后的结果
- 当任意一个服务器节点收到的投票数，超过了法定数量(`quorum`)，则，升级为 Leader，并广播结果。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/7ca755dfe9b16f9c130f5de492549a86.png)

> - 由于网络延时，节点得不到足够多广播信息时，会做出错误的投票判断，纠正过程更耗时
> - 选举过程中，服务器节点会等待一定时间，再广播投票信息，时间间隔一般设定为 200 ms
> - 上面 Leader 选举，采取事件触发 Push 方式 广播消息，称为 快速 Leader 选举，因为之前的 Leader 选举，采用 Pull 方式，每隔 1s 拉取一次。

### 应用场景  

#### 发布订阅  

通过 Zookeeper 进行数据的发布与订阅其实可以说是它提供的最基本功能，它能够允许多个客户端同时订阅某一个节点的变更并在变更发生时执行我们预先设置好的回调函数，在运行时改变服务的配置和行为

#### 命名服务  

除了实现服务配置数据的发布与订阅功能，Zookeeper 还能帮助分布式系统实现命名服务，在每一个分布式系统中，客户端应用都有根据指定名字获取资源、服务器地址的需求，在这时就要求整个集群中的全部服务有着唯一的名字。

在大型分布式系统中，有两件事情非常常见，一是不同服务之间的可能拥有相同的名字，另一个是同一个服务可能会在集群中部署很多的节点，Zookeeper 就可以通过文件系统和顺序节点解决这两个问题。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/72025ab7142520ce9e59193eb956b900.png)

#### 协调分布式事务  

Zookeeper 的另一个作用就是担任分布式事务中的协调者角色，在之前介绍 分布式事务 的文章中我们曾经介绍过分布式事务本质上都是通过 2PC 来实现的，在两阶段提交中就需要一个协调者负责协调分布式事务的执行。

所有的事务参与者会向当前节点中写入提交或者终止，一旦当前的节点改变了事务的状态，其他节点就会得到通知，如果出现一个写入终止的节点，所有的节点就会回滚对分布式事务进行回滚。

#### 分布式锁  

在数据库中，锁的概念其实是非常重要的，常见的关系型数据库就会对排他锁和共享锁进行支持，而 `Zookeeper` 提供的 API 也可以让我们非常简单的实现分布式锁。

作为分布式协调服务，Zookeeper 的应用场景非常广泛，不仅能够用于服务配置的下发、命名服务、协调分布式事务以及分布式锁，还能够用来实现微服务治理中的服务注册以及发现等功能，这些其实都源于 Zookeeper 能够提供高可用的分布式协调服务，能够为客户端提供分布式一致性的支持。

### ZooKeeper 的缺陷  

#### zookeeper 不是为高可用性设计的  

1. 由于要跨机房容灾，很多系统实际上是需要跨机房部署的。出于性价比的考虑我们通常会让多个机房同时工作，而不会搭建N倍的冗余。也就是说单个机房肯定撑不住全流量（你能设想谷歌在全球只剩下一个机房在干活吗）。由于 zookeeper 集群只能有一个 master，因此一旦机房之间连接出现故障，zookeeper master 就只能照顾一个机房，其他机房运行的业务模块由于没有 master 都只能停掉。于是所有流量集中到有 master 的那个机房，于是系统 crash。
2. 即使是在同一个机房里面，由于网段的不同，在调整机房交换机的时候偶尔也会发生网段隔离的情况。实际上机房每个月基本上都会发生短暂的网络隔离之类的子网段调整。在那个时刻 zookeeper 将处于不可用状态。如果整个业务系统基于 zookeeper （比如要求每个业务请求都先去 zookeeper 获取业务系统的master地址），则系统的可用性将非常脆弱。
3. 由于 zookeeper 对于网络隔离的极度敏感，导致 zookeeper 对于网络的任何风吹草动都会做出激烈反应。这使得 zookeeper 的‘不可用’时间比较多，我们不能让 zookeeper 的‘不可用’，变成系统的不可用。

#### zookeeper 的选举过程速度很慢  

1. 这是一个很难从理论分析上看到的弱点，但是你一旦遇到就会痛不欲生。
2. 前面我们已经说过，网络实际上常常是会出现隔离等不完整状态的，而 zookeeper 对那种情况非常敏感。一旦出现网络隔离， zookeeper 就要发起选举流程。
3. zookeeper 的选举流程通常耗时 30 到 120 秒，期间 zookeeper 由于没有master，都是不可用的。
4. 对于网络里面偶尔出现的，比如半秒一秒的网络隔离，zookeeper 会由于选举过程，而把不可用时间放大几十倍。

#### zookeeper 的性能是有限的  

1. 典型的 zookeeper 的 tps(transaction peer secondes) 大概是一万多，无法覆盖系统内部每天动辄几十亿次的调用。因此每次请求都去 zookeeper 获取业务系统 master 信息是不可能的。
2. 因此 zookeeper 的 client 必须自己缓存业务系统的 master 地址。
3. 因此 zookeeper 提供的‘强一致性’实际上是不可用的。如果我们需要强一致性，还需要其他机制来进行保障：比如用自动化脚本把业务系统的 old master 给 kill 掉，但是那会有很多陷阱。

#### zookeeper 无法进行有效的权限控制  

1. zookeeper 的权限控制非常薄弱
2. 在大型的复杂系统里面，使用 zookeeper 必须自己再额外的开发一套权限控制系统，通过那套权限控制系统再访问 zookeeper
3. 额外的权限控制系统不但增加了系统复杂性和维护成本，而且降低了系统的总体性能

#### 即使有了 zookeeper 也很难避免业务系统的数据不一致  

1. 前面已经讨论过了，由于 zookeeper 的性能限制，我们无法让每次系统内部调用都走 zookeeper ，因此总有某些时刻，业务系统会存在两个 master（业务系统 client 那边缓存的业务系统 master 信息是定时从 zookeeper 更新的，因此会有更新不同步的问题）。
2. 如果要在业务系统 client 的 master 信息不一致的情况下，仍要保持系统的数据一致性的方法是 *先 kill 掉老 master ，再在 zookeeper 上更新 master 信息*。但是在是否要 kill current master 这个问题上，程序是无法完全自动决定的（因为网络隔离的时候zookeeper已经不可用了，自动脚本没有全局信息，不管怎么做都可能是错的，什么都不做也可能是错的。当网络故障的时候，只有运维人员才有全局信息，程序是无法接电话得知其他机房的情况的）。因此系统无法自动的保障数据一致性，必须要人工介入。而人工介入的典型时间是半个小时以上，我们不能让系统这么长时间不可用。因此我们必须在某个方向上进行妥协，最常见的妥协方式是放弃 ‘强一致性’，而接受‘最终一致性’。
3. 如果我们需要人工介入才能保证‘可靠的强一致性’，那么 zookeeper 的价值就大打折扣。

#### Zookeeper 并不保证读取的是最新数据  

ZooKeeper 并不保证在每个实例中，两个不同的客户端将具有相同的 ZooKeeper 数据的视图。由于诸如网络延迟的因素，一个客户端可以在另一客户端被通知该改变之前执行更新，考虑两个客户端A和B的场景。如果客户端A将 `/a` 的值从 `0` 设置为 `1` ，客户端B读取 `/a`，客户端 B 可以读取旧值 0，这取决于它连接到的服务器。如果客户端A 和客户端B 读取相同的值很重要，则客户端B应该在执行读取之前从 ZooKeeper API 方法调用 `sync()` 方法。

对于 Zookeeper 来说，它实现了A可用性（**非高可用**）、P分区容错性、C中的写入强一致性，丧失的是C中的读取一致性。

#### 我们能做什么  

1. 我们或者选择人工介入的强一致性，或者选择程序自动化进行的弱一致性。需要进行取舍。
2. 最终一致性甚至未必是程序来做的，有时候人工修正数据反而在灵活、可靠、低成本上有优势。这需要权衡。
3. 不要迷信zookeeper，有时候不妨考虑一下主备数据库。数据库自带权限控制，用起来比zookeeper方便多了。
4. zookeeper 比较有价值的东西也许是内容变化的时候，可以阻塞回调的方式通知所有在线的 client 实时更新信息，但这个功能用处不大。

### FAQ  

这段时间来，也在和公司里的一些同学交流使用zk的心得，整理了一些常见的zookeeper问题。这个页面的目标是解答一些zk常见的使用问题，同时也让大家明确zk不能干什么。页面会一直更新。

#### 客户端对 ServerList 的轮询机制是什么  

随机，客户端在初始化( `new ZooKeeper(String connectString, int sessionTimeout, Watcher watcher)` )的过程中，将所有 `Server` 保存在一个 `List` 中，然后随机打散，形成一个环。之后从 0 号位开始一个一个使用。两个注意点：

1. Server地址能够重复配置，这样能够弥补客户端无法设置Server权重的缺陷，但是也会加大风险。（比如: `192.168.1.1:2181,192.168.1.1:2181,192.168.1.2:2181`).
2. 如果客户端在进行 `Server` 切换过程中耗时过长，那么将会收到 `SESSION_EXPIRED` . 这也是上面第1点中的加大风险之处。

#### 客户端如何正确处理 CONNECTIONLOSS (连接断开) 和 SESSIONEXPIRED (Session 过期)两类连接异常  

在 ZooKeeper 中，服务器和客户端之间维持的是一个 **长连接**，在 `SESSION_TIMEOUT` 时间内，服务器会确定客户端是否正常连接(客户端会定时向服务器发送 `heart_beat` ),服务器重置下次 `SESSION_TIMEOUT` 时间。因此，在正常情况下， `Session` 一直有效，并且 **`zk` 集群所有机器上都保存这个 `Session` 信息**。在出现问题情况下，客户端与服务器之间连接断了（客户端所连接的那台zk机器挂了，或是其它原因的网络闪断），这个时候客户端会主动在地址列表（初始化的时候传入构造方法的那个参数 `connectString` ）中选择新的地址进行连接。

好了，上面基本就是服务器与客户端之间维持长连接的过程了。在这个过程中，用户可能会看到两类异常 `CONNECTIONLOSS` (连接断开) 和 `SESSIONEXPIRED` (Session 过期)。

- `CONNECTIONLOSS` ：应用在进行操作A时，发生了 `CONNECTIONLOSS` ，此时用户不需要关心我的会话是否可用，应用所要做的就是等待客户端帮我们自动连接上新的 `zk` 机器，一旦成功连接上新的 `zk` 机器后，确认刚刚的操作A是否执行成功了。
- `SESSIONEXPIRED` ：这个通常是zk客户端与服务器的连接断了，试图连接上新的 `zk` 机器，这个过程如果耗时过长，超过 `SESSION_TIMEOUT` 后还没有成功连接上服务器，那么服务器认为这个 `session` 已经结束了（服务器无法确认是因为其它异常原因还是客户端主动结束会话），开始清除和这个会话有关的信息，包括这个会话创建的临时节点和注册的 `Watcher` 。在这之后，客户端重新连接上了服务器在，但是很不幸，服务器会告诉客户端 `SESSIONEXPIRED` 。此时客户端要做的事情就看应用的复杂情况了，总之，要重新实例 `zookeeper` 对象，重新操作所有临时数据（包括临时节点和注册 `Watcher` ）。

#### 一个客户端修改了某个节点的数据，其它客户端能够马上获取到这个最新数据吗  

`ZooKeeper` **不能确保任何客户端能够获取（即 `Read Request` ）到一样的数据**，除非客户端自己要求：方法是客户端在获取数据之前调用`org.apache.zookeeper.AsyncCallback.VoidCallback, java.lang.Object) sync`.

通常情况下（这里所说的通常情况满足：1. 对获取的数据是否是最新版本不敏感，2. 一个客户端修改了数据，其它客户端需要不需要立即能够获取最新），可以不关心这点。

在其它情况下，最清晰的场景是这样：ZK 客户端 A 对 `/my_test` 的内容从 `v1->v2`, 但是 ZK 客户端 B 对 `/my_test` 的内容获取，依然得到的是 `v1`. 请注意，这个是实际存在的现象，当然延时很短。解决的方法是客户端B先调用 `sync()`, 再调用 `getData()`.

#### ZK为什么不提供一个永久性的Watcher注册机制  

不支持用持久Watcher的原因很简单，ZK无法保证性能。

#### 使用watch需要注意的几点  

1. `Watches` 通知是一次性的，必须重复注册.
2. 发生 `CONNECTIONLOSS` 之后，只要在 `session_timeout` 之内再次连接上（即不发生 `SESSIONEXPIRED` ），那么这个连接注册的 `watches` 依然在。
3. 节点数据的版本变化会触发 `NodeDataChanged` ，注意，这里特意说明了是版本变化。存在这样的情况，只要成功执行了 `setData()`方法，无论内容是否和之前一致，都会触发 `NodeDataChanged` 。
4. 对某个节点注册了 `watch` ，但是节点被删除了，那么注册在这个节点上的 `watches` 都会被移除。
5. 同一个 zk 客户端对某一个节点注册相同的 `watch` ，只会收到一次通知。
6. `Watcher` 对象只会保存在客户端，不会传递到服务端。

#### 我能否收到每次节点变化的通知  

**如果节点数据的更新频率很高的话，不能**。

原因在于：当一次数据修改，通知客户端，客户端再次注册 `watch` ，在这个过程中，可能数据已经发生了许多次数据修改，因此，千万不要做这样的测试：“数据被修改了n次，一定会收到n次通知"来测试 `server` 是否正常工作。

#### 能为临时节点创建子节点吗  

不能。

#### 是否可以拒绝单个IP对ZK的访问,操作  

ZK 本身不提供这样的功能，它仅仅提供了对单个 IP 的连接数的限制。你可以通过修改 iptables 来实现对单个 ip 的限制。

#### 在[`getChildren(String path, boolean watch)`]注册对节点子节点的变化，那么子节点的子节点变化能通知吗  

不能

#### 创建的临时节点什么时候会被删除，是连接一断就删除吗？延时是多少？  

连接断了之后，ZK 不会马上移除临时数据，只有当 `SESSIONEXPIRED` 之后，才会把这个会话建立的临时数据移除。因此，用户需要谨慎设置 `Session_TimeOut`

#### zookeeper是否支持动态进行机器扩容？如果目前不支持，那么要如何扩容呢？ 

3.4.3版本的zookeeper，还不支持这个功能，在3.5.0版本开始，支持动态加机器了。

#### ZooKeeper集群中个服务器之间是怎样通信的？  

Leader服务器会和每一个 `Follower/Observer` 服务器都建立TCP连接，同时为每个 `F/O`都创建一个叫做 `LearnerHandler` 的实体。LearnerHandler 主要负责 Leader 和 F/O 之间的网络通讯，包括数据同步，请求转发和 `Proposal` 提议的投票等。Leader 服务器保存了所有 F/O 的 `LearnerHandler` 。

#### zookeeper是否会自动进行日志清理？如果进行日志清理？  

zk自己不会进行日志清理，需要运维人员进行日志清理



## Kafka  

### 术语  

- **Broker**：Kafka 集群包含一个或多个服务器，这种服务器被称为 `broker` 。
- **Topic**：每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。（物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个 broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）。
- **Partition**： `Partition` 是物理上的概念，每个 `Topic` 包含一个或多个 `Partition` 。
- **Producer**：负责发布消息到 Kafka broker。
- **Consumer**：消息消费者，向 Kafka broker 读取消息的客户端。
- **Consumer Group**：每个 `Consumer` 属于一个特定的 `Consumer Group`（可为每个 Consumer 指定 group name，若不指定 group name 则属于默认的 group）。

### 拓扑结构  

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/9a9bab37c896c086e2fee7b3e15a9ae3.png)

如上图所示，一个典型的 `Kafka` 集群中包含若干 `Producer` （可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干 `broker` （Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干 `Consumer Group` ，以及一个 `Zookeeper` 集群。 `Kafka` 通过 `Zookeeper` 管理集群配置，选举 `leader` ，以及在 `Consumer Group` 发生变化时进行 rebalance。 `Producer` 使用 push 模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。

### Topic & Partition  

**Topic 在逻辑上可以被认为是一个 queue** ，每条消费都必须指定它的 `Topic` ，可以简单理解为必须指明把这条消息放进哪个 `queue` 里。为了使得 Kafka 的吞吐率可以线性提高，**物理上把 `Topic` 分成一个或多个 `Partition`** ，每个 `Partition` 在物理上对应一个文件夹，该文件夹下存储这个 `Partition` 的所有消息和索引文件。若创建 `topic1` 和 `topic2` 两个 `topic` ，且分别有 13 个和 19 个分区，则整个集群上会相应会生成共 32 个文件夹（本文所用集群共8个节点，此处 `topic1` 和 `topic2` `replication-factor` 均为1）。

> Partition 都是通过 顺序读写，所以效率很高

> replication-factor 配置 partition 副本数。配置副本之后,每个 partition 都有一个唯一的 leader ，有 0 个或多个 follower 。所有的读写操作都在 leader 上完成，followers 从 leader 消费消息来复制 message，就跟普通的 consumer 消费消息一样。一般情况下 partition 的数量大于等于 broker 的数量，并且所有 partition 的 leader 均匀分布在 broker 上。

对于传统的 MQ 而言，一般会删除已经被消费的消息，而 Kafka 集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此 Kafka 提供两种策略删除旧数据。一是基于时间，二是基于 Partition 文件大小。

### Producer 消息路由  

Producer 发送消息到 broker 时，会根据 Paritition 机制选择将其存储到哪一个 Partition 。如果 Partition 机制设置合理，所有消息可以均匀分布到不同的 Partition 里，这样就实现了负载均衡。如果一个 Topic 对应一个文件，那这个文件所在的机器I/O将会成为这个 Topic 的性能瓶颈，而有了 Partition 后，不同的消息可以并行写入不同 broker 的不同 Partition 里，极大的提高了吞吐率。

可以在 `$KAFKA_HOME/config/server.properties` 中通过配置项 `num.partitions` 来指定新建 `Topic` 的默认 `Partition` 数量，也可在创建 `Topic` 时通过参数指定，同时也可以在 Topic 创建之后通过 Kafka 提供的工具修改。

- 指定了 patition，则直接使用
- 未指定 patition 但指定 key，通过对 key 进行 hash 选出一个 patition
- patition 和 key 都未指定，使用轮询选出一个 patition

### Consumer Group  

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/e54deac5512215cfc6801890bb83d792.png)

这是 Kafka 用来实现一个 Topic 消息的广播（发给所有的 Consumer ）和单播（发给某一个 Consumer ）的手段。一个 Topic 可以对应多个 Consumer Group 。如果需要实现广播，只要每个 Consumer 有一个独立的 Group 就可以了。要实现单播只要所有的 Consumer 在同一个 Group 里。用 Consumer Group 还可以将 Consumer 进行自由的分组而不需要多次发送消息到不同的 Topic 。

### Consumer 个数与 Parition 数有什么关系？  

**topic 下的一个分区只能被同一个 consumer group 下的一个 consumer 线程来消费**，但反之并不成立，即一个 consumer 线程可以消费多个分区的数据。比如 Kafka 提供的 `ConsoleConsumer` ，默认就只是一个线程来消费所有分区的数据。

> 即分区数决定了同组消费者个数的上限

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/5290a719713da5ce4e83422ded5bdf0c.png)

所以，如果你的分区数是 N ，那么最好线程数也保持为 N ，这样通常能够达到最大的吞吐量。超过 N 的配置只是浪费系统资源，因为多出的线程不会被分配到任何分区。

- 如果消费线程大于 patition 数量，则有些线程将收不到消息
- 如果 patition 数量大于消费线程数，则有些线程多收到多个 patition 的消息
- 如果一个线程消费多个 patition，则无法保证你收到的消息的顺序，而一个 patition 内的消息是有序的

### Push vs. Pull　　  

作为一个消息系统，Kafka 遵循了传统的方式，选择由 Producer 向 broker `push` 消息并由 Consumer 从 broker `pull` 消息。事实上，push 模式和 pull 模式各有优劣。

- Push模式 很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成 Consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。
- Pull模式 可以根据Consumer的消费能力以适当的速率消费消息。

对于 Kafka 而言，Pull模式 更合适。Pull模式 可简化 broker 的设计，Consumer 可自主控制消费消息的速率，同时 Consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。

### 高可用性  

`Kafka 0.8` 以前，是没有 HA 机制的，就是任何一个 `broker` 宕机了，那个 `broker` 上的 `partition` 就废了，没法写也没法读，没有什么高可用性可言。

比如说，我们假设创建了一个 `topic` ，指定其 `partition` 数量是 `3` 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 `topic` 的 `1/3` 的数据就丢了，因此这个是做不到高可用的。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/ab965081f1e5ff28386d90ba18a17d6d.png)

`Kafka 0.8` 以后，提供了 `HA` 机制，就是 `replica` **副本机制**。每个 `partition` 的数据都会同步到其它机器上，形成自己的多个 `replica` 副本。所有 `replica` 会选举一个 `leader`出来，那么生产和消费都跟这个 `leader` 打交道，然后其他 `replica` 就是 `follower` 。写的时候， `leader` 会负责把数据同步到所有 `follower` 上去，读的时候就直接读 `leader`上的数据即可。 `Kafka` 会均匀地将一个 `partition` 的所有 `replica` 分布在不同的机器上，这样才可以提高容错性。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/a0de8d416add777aef97683192fd15db.png)

这么搞，就有所谓的高可用性了，因为如果某个 `broker` 宕机了，没事儿，那个 `broker` 上面的 `partition` 在其他机器上都有副本的，如果这上面有某个 `partition` 的 `leader` ，那么此时会从 `follower` 中 **重新选举** 一个新的 `leader` 出来，大家继续读写那个新的 `leader` 即可。这就有所谓的高可用性了。

- **写数据** 的时候，生产者就写 `leader` ，然后 `leader` 将数据落地写本地磁盘，接着其他 `follower` 自己主动从 `leader` 来 `pull` 数据。一旦所有 `follower` 同步好数据了，就会发送 `ack` 给 `leader` ， **`leader` 收到所有 `follower` 的 `ack` 之后，就会返回写成功的消息给生产者**。（当然，这只是其中一种模式，还可以适当调整这个行为）
- **消费** 的时候，只会从 `leader` 去读，但是 **只有当一个消息已经被所有 `follower` 都同步成功返回 `ack` 的时候，这个消息才会被消费者读到**。

### 消息幂等性  

`Kafka` 实际上有个 `offset` 的概念，就是每个消息写进去，都有一个 `offset` ，代表消息的序号，然后 **`consumer` 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 `offset` 提交一下**，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 `offset` 来继续消费吧”。

但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接 `kill` 进程了，再重启。这会导致 `consumer` 有些消息处理了，但是没来得及提交 `offset` ，尴尬了。重启之后，**少数消息会再次消费一次**。

幂等性，通俗点说，**一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错**。其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性？其实还是得 **结合业务来思考**，这里给几个思路：

- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
- 比如你是写 Redis ，那没问题了，反正每次都是 set，天然幂等性。
- 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

### 消息丢失  

#### 消费端弄丢了数据  

唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边 **自动提交了 `offset`** ，让 `Kafka` 以为你已经消费好了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。

`Kafka` 会自动提交 `offset` ，那么只要 **关闭自动提交** `offset`，在处理完之后自己手动提交 `offset` ，就可以保证数据不会丢。但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 `offset` ，结果自己挂了，此时肯定会重复消费一次，自己 **保证幂等性** 就好了。

#### Kafka 弄丢了数据  

这块比较常见的一个场景，就是 `Kafka` 某个 `broker` 宕机，然后重新选举 `partition` 的 `leader` 。大家想想，要是此时其他的 `follower` 刚好还有些数据没有同步，结果此时 `leader` 挂了，然后选举某个 `follower` 成 `leader` 之后，不就少了一些数据？这就丢了一些数据啊。

此时一般是要求起码设置如下 4 个参数：

- 给 `topic` 设置 `replication.factor` 参数：这个值必须大于 1，要求每个 `partition` 必须有 **至少** 2 个副本。
- 在 `Kafka` 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是 **要求一个 `leader` 至少感知到有至少一个 `follower` 还跟自己保持联系**，没掉队，这样才能确保 `leader` 挂了还有一个 `follower` 吧。
- 在 `producer` 端设置 `acks=all`：这个是要求每条数据，**必须是写入所有 `replica` 之后，才能认为是写成功了**。
- 在 `producer` 端设置 `retries=MAX`（很大很大很大的一个值，无限次重试的意思）：这个是要求 **一旦写入失败，就无限重试**，卡在这里了。

这样配置之后，至少在 Kafka `broker` 端就可以保证在 `leader` 所在 `broker` 发生故障，进行 `leader` 切换时，数据不会丢失。

#### 生产者会不会弄丢数据？  

如果按照上述的思路设置了 `acks=all`，一定不会丢，要求是，你的 `leader` 接收到消息，所有的 `follower` 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者可以自动不断的重试，重试无限次。

### 消息的顺序性  

比如说我们建了一个 `topic` ，有三个 `partition` 。生产者在写的时候，其实可以指定一个 `key` ，比如说我们指定了某个订单 `id` 作为 `key` ，那么这个订单相关的数据，一定会被分发到同一个 `partition` 中去，而且这个 `partition` 中的数据一定是有顺序的。

消费者从 `partition` 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 `ok`的，没有错乱。接着，我们在消费者里可能会搞 **多个线程来并发处理消息**。而多个线程并发跑的话，顺序可能就乱掉了。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/7d529fbf2f856582c2eb3ee787ede5fd.png)

解决方案：

- 一个 `topic` ，一个 `partition` ，一个 `consumer` ，内部单线程消费，单线程吞吐量太低，一般不会用这个。
- 写 `N` 个内存 `queue` ，具有相同 `key` 的数据都到同一个内存 `queue` ；然后对于 N 个线程，每个线程分别消费一个内存 `queue` 即可，这样就能保证顺序性。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/09d68167fcb34b075259add9b81809cd.png)

### Kafka 如何进行扩容的？  

假如集群有 3 个 broker，一共有 4 个 TP，每个 3 副本，均匀分布。现在要扩容一台机器，新 broker 加入集群后需要通过工具进行 TP 的迁移。一共迁移 3 个 TP 的副本到新 broker 上。等迁移结束之后，会重新进行 Leader balance。

从微观的角度看，TP 从一台 broker 迁移到另一个 broker 的流程是怎么样的呢？咱们来看下 TP3 第三个副本，从 broker1 迁移到 broker4 的过程，如下图所示，broker4 作为 TP3 的 follower，从 broker1 上最早的 `offset` 进行获取数据，直到赶上最新的 `offset` 为止，新副本被放入 ISR 中，并移除 broker1 上的副本，迁移过程完毕。

但在现有的扩容流程中存有如下问题：数据迁移从 TP3 的最初的 `offset` 开始拷贝数据，这会导致大量读磁盘，消耗大量的 I/O 资源，导致磁盘繁忙，从而造成 produce 操作延迟增长，产生抖动。所以整体迁移流程不够平滑。我们看下实际的监控到的数据。从中可以看到数据迁移中， `broker1` 上磁盘读量增大，磁盘 util 持续打满，produce 极其不稳定。

针对这个问题，我们回到 Kafka 迁移的流程上看，理论上 Kafka 是一个缓存系统，不需要永久存储数据，很有可能费了很多工作迁移过来的数据根本就不会被使用，甚至马上就会被删除了。从这个角度上看，那么迁移数据时，为什么一定要从 partition 最初 `offset` 开始迁移数据呢？细想想，好像不需要这样。

所以，解决这个问题的思路就比较简单了，在迁移 TP 时，**直接从 partition 最新的 offset 开始数据迁移**，但是要同步保持一段时间，主要是确保所有 consumer 都已经跟得上了。

### Leader 选举过程  

#### 控制器的选举  

在Kafka集群中会有一个或多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态等工作。比如当某个分区的 Leader 副本出现故障时，由控制器负责为该分区选举新的 Leader 副本。再比如当检测到某个分区的 ISR(In-Sync Replicas) 集合发生变化时，由控制器负责通知所有 broker 更新其元数据信息。

Kafka Controller 的选举是依赖 Zookeeper 来实现的，在 Kafka 集群中哪个 broker 能够成功创建 `/controller` 这个临时（EPHEMERAL）节点他就可以成为 Kafka Controller。Kafka Controller 的出现是处于性能考虑，当 Kafka 集群规模很大，partition 达到成千上万时，当 broker 宕机时，造成集群内大量的调整，会造成大量 Watch 事件被触发，Zookeeper负载会过重。

##### Controller 脑裂  

kafka 中只有一个控制器 controller 负责分区的 leader 选举，同步 broker 的新增或删除消息，但有时由于网络问题，可能同时有两个 broker 认为自己是 controller ，这时候其他的 broker 就会发生脑裂。

解决方案：每当新的 controller 产生的时候就会在 ZK 中生成一个全新的、数值更大的 controller epoch 的标识，并同步给其他的 broker 进行保存，这样当第二个 controller 发送指令时，其他的 broker 就会自动忽略。

#### 分区 Leader 的选举  

分区 Leader 副本的选举由 Kafka Controller 负责具体实施。当创建分区（创建主题或增加分区都有创建分区的动作）或分区上线（比如分区中原先的 Leader 副本下线，此时分区需要选举一个新的 Leader 上线来对外提供服务）的时候都需要执行 Leader 的选举动作。

#### 消费者相关的选举  

组协调器 GroupCoordinator 需要为消费组内的消费者选举出一个消费组的 Leader，这个选举的算法也很简单，分两种情况分析。如果消费组内还没有 Leader，那么第一个加入消费组的消费者即为消费组的 Leader。如果某一时刻 Leader 消费者由于某些原因退出了消费组，那么会重新选举一个新的 Leader。

### 负载均衡  

#### Producers 负载均衡  

对于同一个 topic 的不同 partition，Kafka 会尽力将这些 partition 分布到不同的 broker 服务器上，这种均衡策略实际上是基于 ZooKeeper 实现的。在一个 broker 启动时，会首先完成 broker 的注册过程，并注册一些诸如 “有哪些可订阅的 topic” 之类的元数据信息。producers 启动后也要到 ZooKeeper 下注册，创建一个临时节点来监听 broker 服务器列表的变化。由于在 ZooKeeper 下 broker 创建的也是临时节点，当 brokers 发生变化时，producers 可以得到相关的通知，从改变自己的 broker list。其它的诸如 topic 的变化以及 broker 和 topic 的关系变化，也是通过 ZooKeeper 的这种 Watcher 监听实现的。

在生产中，必须指定 topic；但是对于 partition，有两种指定方式：

- 明确指定 `partition(0-N)`，则数据被发送到指定 partition；
- 设置为 `RD_KAFKA_PARTITION_UA` ，则 Kafka 会回调 `partitioner` 进行均衡选取， `partitioner` 方法需要自己实现。可以轮询或者传入 key 进行 hash。未实现则采用默认的随机方法 `rd_kafka_msg_partitioner_random` 随机选择。

#### Consumer 负载均衡  

Kafka 保证同一 consumer group 中只有一个 consumer 可消费某条消息，实际上，Kafka 保证的是稳定状态下每一个 consumer 实例只会消费某一个或多个特定的数据，而某个 partition 的数据只会被某一个特定的 consumer 实例所消费。这样设计的劣势是无法让同一个 consumer group 里的 consumer 均匀消费数据，优势是每个 consumer 不用都跟大量的 broker 通信，减少通信开销，同时也降低了分配难度，实现也更简单。另外，因为同一个 partition 里的数据是有序的，这种设计可以保证每个 partition 里的数据也是有序被消费。

##### consumer 数量不等于 partition 数量  

如果某 consumer group 中 consumer 数量少于 partition 数量，则至少有一个 consumer 会消费多个 partition 的数据；如果 consumer 的数量与 partition 数量相同，则正好一个 consumer 消费一个 partition 的数据，而如果 consumer 的数量多于 partition 的数量时，会有部分 consumer 无法消费该 topic 下任何一条消息。

##### 借助 ZooKeeper 实现负载均衡  

关于负载均衡，对于某些低级别的 API，consumer 消费时必须指定 topic 和 partition，这显然不是一种友好的均衡策略。基于高级别的 API，consumer 消费时只需制定 topic，借助 ZooKeeper 可以根据 partition 的数量和 consumer 的数量做到均衡的动态配置。

consumers 在启动时会到 ZooKeeper 下以自己的 `conusmer-id` 创建临时节点 `/consumer/[group-id]/ids/[conusmer-id]`，并对 `/consumer/[group-id]/ids` 注册监听事件，当消费者发生变化时，同一 group 的其余消费者会得到通知。当然，消费者还要监听 broker 列表的变化。kafka 通常会将 partition 进行排序后，根据消费者列表，进行轮流的分配。



## RPC  

远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。

### 应用发展流程  

#### 单一应用架构  

当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。

#### 垂直应用架构  

当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。

#### 分布式服务架构  

当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。

#### 流动计算架构  

当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)是关键。



## [Dubbo](https://zhuanlan.zhihu.com/p/45846108)  

### 领域模型  

在 Dubbo 的核心领域模型中：

- `Protocol` 是服务域，它是 Invoker 暴露和引用的主功能入口，它负责 Invoker 的生命周期管理。
- `Invoker` 是实体域，它是 Dubbo 的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起 invoke 调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。
- `Invocation` 是会话域，它持有调用过程中的变量，比如方法名，参数等。

### 基本设计原则  

- 采用 `Microkernel + Plugin` 模式，Microkernel 只负责组装 Plugin，Dubbo 自身的功能也是通过扩展点实现的，也就是 Dubbo 的所有功能点都可被用户自定义扩展所替换。
- 采用 URL 作为配置信息的统一格式，所有扩展点都通过传递 URL 携带配置信息。

### Dubbo 服务暴露过程  

[官方文档–服务导出](https://dubbo.incubator.apache.org/zh-cn/docs/source_code_guide/export-service.html)

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/fce799af888ea1e2b757476b03d4ded7.png)

#### Dubbo 结构  

- 第一层：service 层，接口层，给服务提供者和消费者来实现的
- 第二层：config 层，配置层，主要是对 dubbo 进行各种配置的
- 第三层：proxy 层，服务代理层，无论是 consumer 还是 provider，dubbo 都会给你生成代理，代理之间进行网络通信
- 第四层：registry 层，服务注册层，负责服务的注册与发现
- 第五层：cluster 层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务
- 第六层：monitor 层，监控层，对 rpc 接口的调用次数和调用时间进行监控
- 第七层：protocal 层，远程调用层，封装 rpc 调用
- 第八层：exchange 层，信息交换层，封装请求响应模式，同步转异步
- 第九层：transport 层，网络传输层，抽象 mina 和 netty 为统一接口
- 第十层：serialize 层，数据序列化层

### 工作流程  

- 第一步：provider 向注册中心去注册
- 第二步：consumer 从注册中心订阅服务，注册中心会通知 consumer 注册好的服务
- 第三步：consumer 调用 provider
- 第四步：consumer 和 provider 都异步通知监控中心

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/075a4cbace1c6874c04ae34c6b91c7ad.png)

### 注册中心挂了可以继续通信吗？  

可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到 **本地缓存**，所以注册中心挂了可以继续通信。

### Dubbo 支持哪些序列化协议？说一下 Hessian 的数据结构？PB 知道吗？为什么 PB 的效率是最高的？  

#### Dubbo 支持不同的通信协议  

- **dubbo 协议**：默认就是走 dubbo 协议，**单一长连接**，进行的是 NIO 异步通信，基于 hessian 作为序列化协议。使用的场景是：传输数据量小（每次请求在 100kb 以内），但是并发量很高。
- **rmi 协议**：走 Java 二进制序列化，**多个短连接**，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。
- **hessian 协议**：走 hessian 序列化协议，**多个短连接**，适用于提供者数量比消费者数量还多的情况，适用于文件的传输，一般较少用。
- **http 协议**：走 json 序列化
- **webservice**：走 SOAP 文本序列化

#### Dubbo 支持的序列化协议  

`dubbo` 支持 `hession` 、 Java 二进制序列化、`json`、`SOAP` 文本序列化多种序列化协议。但是 **`hessian` 是其默认的序列化协议**。

#### 为什么 PB 的效率是最高的？  

其实 PB 之所以性能如此好，主要得益于两个：

- 它使用 `proto` 编译器，自动进行序列化和反序列化，速度非常快，应该比 XML 和 JSON 快上了 `20~100` 倍；
- 它的数据压缩效果好，就是说它序列化后的数据量体积小。因为体积小，传输起来带宽和速度上会有优化。

### dubbo 负载均衡策略和集群容错策略都有哪些？动态代理策略呢？  

#### dubbo 负载均衡策略  

##### random loadbalance  

默认情况下，dubbo 是 `random load balance` ，即 **随机** 调用实现负载均衡，可以对 `provider` 不同实例 **设置不同的权重**，会按照权重来负载均衡，权重越大分配流量越高，一般就用这个默认的就可以了。

##### roundrobin loadbalance  

这个的话默认就是均匀地将流量打到各个机器上去，但是如果各个机器的性能不一样，容易导致性能差的机器负载过高。所以此时需要调整权重，让性能差的机器承载权重小一些，流量少一些。

##### leastactive loadbalance  

这个就是自动感知一下，如果某个机器性能越差，那么接收的请求越少，越不活跃，此时就会给 **不活跃的性能差的机器更少的请求**。

##### consistanthash loadbalance  

一致性 Hash 算法，相同参数的请求一定分发到一个 `provider` 上去， `provider` 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。**如果你需要的不是随机负载均衡**，是要一类请求都到一个节点，那就走这个一致性 `Hash` 策略。

#### dubbo 集群容错策略  

##### failover cluster 模式  

失败自动切换，自动重试其他机器，默认就是这个，常见于读操作。（失败重试其它机器）

##### failfast cluster模式  

一次调用失败就立即失败，常见于写操作。（调用失败就立即失败）

##### failsafe cluster 模式  

出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。

##### failback cluster 模式  

失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。

##### forking cluster 模式  

**并行调用** 多个 `provider` ，只要一个成功就立即返回。

##### broadcacst cluster  

逐个调用所有的 `provider。`

#### dubbo动态代理策略  

默认使用 `javassist` 动态字节码生成，创建代理类。但是可以通过 spi 扩展机制配置自己的动态代理策略。

### dubbo 的 spi 思想是什么？  

`spi` ，简单来说，就是 `service provider interface`，说白了是什么意思呢，比如你有个接口，现在这个接口有 3 个实现类，那么在系统运行的时候对这个接口到底选择哪个实现类呢？这就需要 `spi` 了，需要根据指定的配置或者是默认的配置，去找到对应的实现类加载进来，然后用这个实现类的实例对象。

`dubbo` 也用了 `spi` 思想，不过没有用 `jdk` 的 `spi` 机制，是自己实现的一套 `spi` 机制。

```
Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
```

`Protocol` 接口，在系统运行的时候， `dubbo` 会判断一下应该选用这个 `Protocol` 接口的哪个实现类来实例化对象来使用。

它会去找一个你配置的 `Protocol` ，将你配置的 `Protocol` 实现类，加载到 `jvm` 中来，然后实例化对象，就用你的那个 `Protocol` 实现类就可以了。

#### 与 Java SPI 对比  

1. JDK 标准的 SPI 会一次性实例化扩展点所有实现，如果有扩展实现初始化很耗时，但如果没用上也加载，会很浪费资源。
2. 增加了对扩展点 IoC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点。
3. 如果扩展点加载失败，连扩展点的名称都拿不到了。比如：JDK 标准的 ScriptEngine，通过 getName() 获取脚本类型的名称，但如果 RubyScriptEngine 因为所依赖的 jruby.jar 不存在，导致 RubyScriptEngine 类加载失败，这个失败原因被吃掉了，和 ruby 对应不起来，当用户执行 ruby 脚本时，会报不支持 ruby，而不是真正失败的原因。

### 如何基于 Dubbo 进行服务治理、服务降级、失败重试以及超时重试？  

#### 服务治理  

##### 1. 调用链路自动生成  

一个大型的分布式系统，或者说是用现在流行的微服务架构来说吧，**分布式系统由大量的服务组成**。那么这些服务之间互相是如何调用的？调用链路是啥？说实话，几乎到后面没人搞的清楚了，因为服务实在太多了，可能几百个甚至几千个服务。

那就需要基于 dubbo 做的分布式系统中，对各个服务之间的调用自动记录下来，然后自动将 **各个服务之间的依赖关系和调用链路生成出来**，做成一张图，显示出来，大家才可以看到对吧。

![image](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/c48a88cbce65d737293a41250ea58d72.png)

##### 2. 服务访问压力以及时长统计  

需要自动统计 **各个接口和服务之间的调用次数以及访问延时**，而且要分成两个级别。

- 一个级别是接口粒度，就是每个服务的每个接口每天被调用多少次，`TP50/TP90/TP99`，三个档次的请求延时分别是多少；
- 第二个级别是从源头入口开始，一个完整的请求链路经过几十个服务之后，完成一次请求，每天全链路走多少次，全链路请求延时的 `TP50/TP90/TP99`，分别是多少。

这些东西都搞定了之后，后面才可以来看当前系统的压力主要在哪里，如何来扩容和优化啊。

##### 3. 其它  

- 服务分层（避免循环依赖）
- 调用链路失败监控和报警
- 服务鉴权
- 每个服务的可用性的监控（接口调用成功率？几个 9？99.99%，99.9%，99%）

#### 服务降级  

比如说服务 A 调用服务 B，结果服务 B 挂掉了，服务 A 重试几次调用服务 B，还是不行，那么直接降级，走一个备用的逻辑，给用户返回响应。

举个栗子，我们有接口 `HelloService`。`HelloServiceImpl` 有该接口的具体实现。

```
public interface HelloService {
   void sayHello();
}

public class HelloServiceImpl implements HelloService {
    public void sayHello() {
        System.out.println("hello world......");
    }
}
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"
    xsi:schemaLocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">

    <dubbo:application name="dubbo-provider" />
    <dubbo:registry address="zookeeper://127.0.0.1:2181" />
    <dubbo:protocol name="dubbo" port="20880" />
    <dubbo:service interface="com.zhss.service.HelloService" ref="helloServiceImpl" timeout="10000" />
    <bean id="helloServiceImpl" class="com.zhss.service.HelloServiceImpl" />

</beans>

<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"
    xsi:schemaLocation="http://www.springframework.org/schema/beans        http://www.springframework.org/schema/beans/spring-beans.xsd        http://code.alibabatech.com/schema/dubbo        http://code.alibabatech.com/schema/dubbo/dubbo.xsd">

    <dubbo:application name="dubbo-consumer"  />

    <dubbo:registry address="zookeeper://127.0.0.1:2181" />

    <dubbo:reference id="fooService" interface="com.test.service.FooService"  timeout="10000" check="false" mock="return null">
    </dubbo:reference>

</beans>
```

我们调用接口失败的时候，可以通过 `mock` 统一返回 `null` 。

mock 的值也可以修改为 true，然后再跟接口同一个路径下实现一个 Mock 类，命名规则是 “接口名称+`Mock`” 后缀。然后在 Mock 类里实现自己的降级逻辑。

```
public class HelloServiceMock implements HelloService {
    public void sayHello() {
        // 降级逻辑
    }
}
```

#### 失败重试和超时重试  

所谓失败重试，就是 `consumer` 调用 `provider` 要是失败了，比如抛异常了，此时应该是可以重试的，或者调用超时了也可以重试。配置如下：

```xml
<dubbo:reference id="xxxx" interface="xx" check="true" async="false" retries="3" timeout="2000"/>
```



#大数据

##基础算法

### Bloom filter  

### 适用范围  

实现数据字典，进行数据的判重，或者集合求交集

#### 基本原理  

　　对于原理来说很简单，**Bit-Map + K个独立 Hash 函数**。将 Hash 函数对应的值的位数组置`1`，**查找时如果发现所有 Hash 函数对应位都是`1`说明存在**。很明显这个过程并不保证查找的结果是 100% 正确的。同时也不支持删除一个已经插入的关键字，因为该关键字对应的位会牵动到其他的关键字。所以一个简单的改进就是 **Counting Bloom filter**，用一个 Counter 数组代替位数组，就可以支持删除了。

![Bloom_Filter](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/Bloom_Filter.png)

对于元素个数： n*n* ，错误率（假阳率）： P*P* 。我们可以计算：

- Bit-Map 大小： m\ge -\frac{n\times ln^P}{(ln^2)^2}*m*≥−(*l**n*2)2*n*×*l**n**P*
- Hash 函数个数： k=log_2^\frac{1}{P}*k*=*l**o**g*2*P*1

> 参数在线计算工具：[Bloom Filter Calculator](https://hur.st/bloomfilter)

举个例子我们假设 P=0.01*P*=0.01 ， n=4000*n*=4000 ，则此时 m 应大概是 9.5\times n=380009.5×*n*=38000 bit， k=7*k*=7

注意这里 m 与 n 的单位不同，m是 `bit` 为单位，而n则是以元素个数为单位(准确的说是不同元素的个数)。通常单个元素的长度都是有很多 `bit` 的。所以使用bloom filter内存上通常都是节省的。

#### 扩展  

　　Bloom filter 将集合中的元素映射到位数组中，用 k 个映射位是否全1表示元素在不在这个集合中。`Counting bloom filter（CBF）`将 **位数组中的每一位扩展为一个 Counter**，从而支持了元素的删除操作。`Spectral Bloom Filter（SBF）`将其与集合元素的出现次数关联。**`SBF`采用 Counter 中的最小值来近似表示元素的出现频率**。

#### 问题实例  

给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？

答：根据这个问题我们来计算下内存的占用，`4G=2^32`大概是40亿*8大概是 340亿，n=50亿，如果按出错率 0.01 算需要的大概是 475 亿个bit。现在可用的是 340 亿，相差并不多，这样可能会使出错率上升些。另外如果这些url ip是一一对应的，就可以转换成ip，则大大简单了。

------

### Hashing  

#### 适用范围  

快速查找，删除的基本数据结构，通常需要总数据量可以放入内存

#### 基本原理  

　- hash函数选择，针对字符串，整数，排列，具体相应的hash方法。

- 碰撞处理，一种是open hashing，也称为拉链法；另一种就是closed hashing，也称开地址法。

#### 扩展  

　　d-left hashing中 的 d 是多个的意思，我们先简化这个问题，看一看 `2-left hashing`。2-left hashing指的是将一个哈希表分成长度相等的两半，分别叫做 `T1` 和 `T2` ，给 `T1` 和 `T2` 分别配备一个哈希函数， `h1` 和 `h2` 。**在存储一个新的key时，同时用两个哈希函数进行计算，得出两个地址 `h1[key]`和 `h2[key]`**。这时需要检查 T1 中的 `h1[key]` 位置和 T2 中的 `h2[key]` 位置，哪一个位置已经存储的（有碰撞的）key比较多，然后 **将新key存储在负载少的位置**。如果两边一样多，比如两个位置都为空或者都存储了一个key，就把新key存储在左边的T1子表中，2-left也由此而来。**在查找一个key时，必须进行两次hash，同时查找两个位置**。 但是这种方法只能使用在静态集合上，一旦集合发生变化，就需要进行重新计算。

#### 问题实例：  

海量日志数据，提取出某日访问百度次数最多的那个IP。

答：IP的数目还是有限的，最多2^32个，所以可以考虑使用hash将 ip 直接存入内存，然后进行统计。

------

### bit-map  

#### 适用范围  

可进行数据的快速查找，判重，删除，一般来说数据范围是int的10倍以下

#### 基本原理  

使用bit数组来表示某些元素是否存在，比如8位电话号码。例如bit数组 `001101001001101001` 代表实际数组 `[2,3,5,8]` 。新加入一个元素，只需要将已有的bit数组和新加入的数字做按位或 `or` 计算。bitmap中 `1` 的数量就是集合的基数值。

bitmap 有一个很明显的优势是可以轻松合并多个统计结果，只需要对多个结果求异或就可以。也可以大大减少存储内存，可以做个简单的计算，如果要统计1亿个数据的基数值，大约需要内存： 100000000/8/1024/1024 \approx≈ 12100000000/8/1024/1024≈≈12 M 如果用 32bit 的 int 代表每个统计数据，大约需要内存： 32*100000000/8/1024/1024 \approx≈ 38132∗100000000/8/1024/1024≈≈381 M

bitmap 对于内存的节约量是显而易见的，但还是不够。统计一个对象的基数值需要`12M`，如果统计 `10000` 个对象，就需要将近 `120G` 了，同样不能广泛用于大数据场景。

#### 扩展  

bloom filter可以看做是对bit-map的扩展

#### 问题实例  

- 已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。 答：8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。
- 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。 答：将bit-map扩展一下，用2bit表示一个数即可，0表示未出现，1表示出现一次，2表示出现2次及以上。或者我们不用2bit来进行表示，我们用两个bit-map即可模拟实现这个2bit-map。

------

### HyperLogLog  

[算法演示](http://content.research.neustar.biz/blog/hll.html)

上面我们计算过用 bitmap 存储 1亿 个统计数据大概需要 `12M` 内存；而在 HLL 中，只需要不到 `1K` 内存就能做到；redis中实现的 `HyperLogLog` ，只需要 `12K` 内存，在标准误差 `0.81%` 的前提下，能够统计 2^{64}264 个数据。首先容我感叹一下数学的强大和魅力，那么概率算法是怎样做到如此节省内存的，又是怎样控制误差的呢？

HLL中实际存储的是一个长度为 `m` 的大数组 `S` ，将待统计的数据集合划分成 m 组，每组根据算法记录一个统计值存入数组中。数组的大小 m 由算法实现方自己确定，redis中这个数组的大小是 `16834`，m 越大，基数统计的误差越小，但需要的内存空间也越大。

1. 通过hash函数计算输入值对应的比特串
2. 比特串的低 t(t=log_2^m)t*t*(*t*=*l**o**g*2*m*)*t* 位对应的数字用来找到数组 `S` 中对应的位置 `i`
3. t+1*t*+1 位开始找到第一个 `1` 出现的位置 `k`，将 `k` 记入数组 S_i*S**i* 位置
4. 基于数组 `S` 记录的所有数据的统计值，计算整体的基数值，计算公式可以简单表示为：\hat{n}=f(S)*n*^=*f*(*S*)

#### 原理  

举一个我们最熟悉的抛硬币例子，出现正反面的概率都是 `1/2` ，一直抛硬币直到出现正面，记录下投掷次数 `k` ，将这种抛硬币多次直到出现正面的过程记为一次伯努利过程，对于 `n` 次伯努利过程，我们会得到nn个出现正面的投掷次数值 k_1*k*1 , k_2*k*2 …… k_n*k**n* ，其中最大值记为 k_{max}*k**m**a**x* ，那么可以得到下面结论：

- n 次伯努利过程的投掷次数都不大于 k_{max}*k**m**a**x*
- n 次伯努利过程，至少有一次投掷次数等于 k_{max}*k**m**a**x*  回到基数统计的问题，我们需要统计一组数据中不重复元素的个数，集合中每个元素的经过hash函数后可以表示成 0 和 1 构成的二进制数串，一个二进制串可以类比为一次抛硬币实验，1 是抛到正面，0 是反面。二进制串中从低位开始第一个 1 出现的位置可以理解为抛硬币试验中第一次出现正面的抛掷次数 `k` ，那么基于上面的结论，我们可以通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验，同样可以可以通过第一个 1 出现位置的最大值 k_{max}*k**m**a**x* 来预估总共有多少个不同的数字（整体基数）。

这种通过局部信息预估整体数据流特性的方法似乎有些超出我们的基本认知，需要用概率和统计的方法才能推导和验证这种关联关系。HyperLogLog 核心在于观察集合中每个数字对应的比特串，通过统计和记录比特串中最大的出现 1 的位置来估计集合整体的基数，可以大大减少内存耗费。

------

### Simhash  

SimHash算法可计算文本间的相似度，实现文本去重。

1. 首先，对原始内容分词，并且计算每个词的权重；
2. 对每个词哈希成一个整数，并且把这个整数对应的二进制序列中的 0 变成 -1，1 还是 1，得到一个 1 和 -1 组成的向量；
3. 把每个词哈希后的向量乘以词的权重，得到一个新的加权向量；
4. 把每个词的加权向量相加，得到一个最终向量，这个向量中每个元素有正有负；
5. 把最终这个向量中元素为正的替换成 1，为负的替换成 0，这个向量变成一个二进制位序列，也就是最终变成了一个整数。

Simhash 为每一个内容生成一个整数指纹，其中的关键是把每个词哈希成一个整数，这一步常常采用 Jenkins 算法。这里简单示意的整数只有 8 个二进制位，实际上可能需要 64 个二进制位的整数，甚至范围更大。

得到每个内容的 Simhash 指纹后，可以两两计算 **汉明距离**，比较二进制位不同个数，其实就是计算两个指纹的异或，异或结果中如果包含 3 个以下的 1，则认为两条内容重复。

------

### 堆  

#### 适用范围  

海量数据前n大，并且n比较小，堆可以放入内存

#### 基本原理  

最大堆求前n小，最小堆求前n大。适合大数据量，求前n小，n的大小比较小的情况，这样可以扫描一遍即可得到所有的前n元素，效率很高。

#### 扩展  

双堆，一个最大堆与一个最小堆结合，可以用来维护中位数。

#### 问题实例：  

- 100w个数中找最大的前100个数。 答：用一个100个元素大小的最小堆即可。

------

### 双层桶划分  

#### 适用范围  

第k大，中位数，不重复或重复的数字

#### 基本原理  

因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。可以通过多次缩小，双层只是一个例子。

> 其实本质上就是【分而治之】的思想，重在分的技巧上！

#### 扩展  

当有时候需要用一个小范围的数据来构造一个大数据，也是可以利用这种思想，相比之下不同的，只是其中的逆过程。

#### 问题实例  

- 2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。 答：有点像鸽巢原理，整数个数为 2^32 ,也就是，我们可以将这 `2^32` 个数，划分为 `2^8` 个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用 bitmap 就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。
- 5亿个 int 找它们的中位数。 答一：这个例子比上面那个更明显。首先我们将 int 划分为 2^16个 区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。 答二：实际上，如果不是 int 是 int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将 int64 分成 2^24 个区域，然后确定区域的第几大数，在将该区域分成 2^20 个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有 2^20 ，就可以直接利用 direct addr table 进行统计了。

------

### 数据库索引  

#### 适用范围  

大数据量的增删改查

#### 基本原理  

利用数据的设计实现方法，对海量数据的增删改查进行处理。

------

### 倒排索引(Inverted index)  

![874963-20190127184959667-1135956344](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/874963-20190127184959667-1135956344.png)

#### 适用范围  

搜索引擎，关键字查询

#### 基本原理  

用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。

以英文为例，下面是要被索引的文本：

```
T0 = "it is what it is"
T1 = "what is it"
T2 = "it is a banana"
```

我们就能得到下面的反向文件索引：

```
"a": {2} "banana": {2} "is": {0, 1, 2} "it": {0, 1, 2} "what": {0, 1}
```

检索的条件"what”,“is"和"it"将对应集合的交集。

正向索引开发出来用来存储每个文档的单词的列表。正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。在正向索引中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而反向索引则是单词指向了包含它的文档，很容易看到这个反向的关系。

#### 扩展  

#### 问题实例  

文档检索系统，查询那些文件包含了某单词，比如常见的学术论文的关键字搜索。

------

### K 路归并  

#### 适用范围  

大数据的排序，去重。

#### 基本原理  

一般来说外排序分为两个步骤：预处理和合并排序。

1. 按照内存大小，将大文件分成若干长度为 l 的子文件（l 应小于内存的可使用容量），然后将各个子文件依次读入内存，使用适当的内部排序算法对其进行排序（排好序的子文件统称为“归并段”或者“顺段”），将排好序的归并段重新写入外存，为下一个子文件排序腾出内存空间；
2. 对得到的顺段进行合并，直至得到整个有序的文件为止。

#### 问题实例  

- 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16个字节，内存限制大小是1M。返回频数最高的100个词。

------

### 败/胜者树  

对于外部排序算法来说，其直接影响算法效率的因素为读写外存的次数，即次数越多，算法效率越低。若想提高算法的效率，即减少算法运行过程中读写外存的次数，可以增加 k 路平衡归并中的 k 值。但是如果毫无限度地增加 k 值，虽然会减少读写外存数据的次数，但会增加内部归并的时间，得不偿失。

为了避免在增加 k 值的过程中影响内部归并的效率，在进行 k-路归并时可以使用 **败者树** 来实现，该方法在增加 k 值时不会影响其内部归并的效率。

#### 基本原理  

**败/胜者树实际上是保存部分数据的比较结果**，以减少新增数据的比较次数，以减少IO。对于无序表 `{49，38，65，97，76，13，27，49}` 创建的完全二叉树如图所示，构建此树的目的是选出无序表中的最小值。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/winner_tree.svg)

这是一棵 **胜者树** 。因为树中每个非终端结点（除叶子结点之外的其它结点）中的值都表示的是左右孩子相比较后的较小值（谁最小即为胜者）。例如叶子结点 49 和 38 相对比，由于 38 更小，所以其双亲结点中的值保留的是胜者 38。然后用 38 去继续同上层去比较，一直比较到树的根结点。

> 胜者树和败者树的区别就是：胜者树中的非终端结点中存储的是胜利的一方；而败者树中的非终端结点存储的是失败的一方。而在比较过程中，都是拿胜者去比较。

对于 10 个临时文件，采用 5-路平衡归并时，若每次从 5 个文件中想得到一个最小值就需要比较 4 次。而采用败者树，只需要进行 2 次比较。以上仅仅是得到一个最小值记录，如要得到整个临时文件，其耗费的时间就会相差很大。

------

### 置换选择排序  

除了增加 k-路归并排序中的 k 值来提高外部排序效率的方法，还有另外一条路可走，即减少初始归并段的个数：**置换选择排序** 是为在较小的空间内，得到更大的有序段。相比于按照内存容量大小对初始文件进行等分，大大减少了初始归并段的数量，从而提高了外部排序的整体效率。

> 通过置换选择排序算法得到的初始归并段，其长度并不会受内存容量的限制，且通过证明得知使用该方法所获得的归并段的平均长度为内存工作区大小的两倍。

例如已知初始文件中总共有 24 个记录，假设内存工作区最多可容纳 6 个记录，按照之前的选择排序算法最少也只能分为 4 个初始归并段。而如果使用置换—选择排序，可以实现将 24 个记录分为 3 个初始归并段：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/swap_select.png)

置换—选择排序算法的具体操作过程为：

1. 首先从初始文件中输入 6 个记录到内存工作区中；
2. 从内存工作区中选出关键字最小的记录，将其记为 `MINIMAX` 记录；
3. 然后将 `MINIMAX` 记录输出到归并段文件中；
4. 此时内存工作区中还剩余 5 个记录，若初始文件不为空，则从初始文件中输入下一个记录到内存工作区中；
5. 从内存工作区中的所有比 `MINIMAX` 值大的记录中选出值最小的关键字的记录，作为新的 `MINIMAX` 记录；
6. 重复过程 3—5，直至在内存工作区中选不出新的 `MINIMAX` 记录为止，由此就得到了一个初始归并段；
7. 重复 2—6，直至内存工作为空，由此就可以得到全部的初始归并段。

------

### 最佳归并树  

无论是通过等分还是置换-选择排序得到的归并段，如何设置它们的归并顺序，可以使得对外存的访问次数降到最低？现有通过置换选择排序算法所得到的 9 个初始归并段，其长度分别为：`9，30，12，18，3，17，2，6，24`。在对其采用 3-路平衡归并的方式时可能出现如图所示的情况：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/best_merge_tree_1.png)

> 图中的叶子结点表示初始归并段，各自包含记录的长度用结点的权重来表示；非终端结点表示归并后的临时文件。

假设在进行平衡归并时，操作每个记录都需要单独进行一次对外存的读写，那么图中的归并过程需要对外存进行读或者写的次数为：

(9+30+12+18+3+17+2+6+24)\times 2 \times 2 = 484(9+30+12+18+3+17+2+6+24)×2×2=484

> 图中涉及到了两次归并，对外存的读和写各进行 2 次

从计算结果上看，对于图中的 3 叉树来讲，其操作外存的次数恰好是树的带权路径长度的 2 倍。所以，对于如何减少访问外存的次数的问题，就等同于考虑如何使 k 路归并所构成的 k 叉树的带权路径长度最短。

若想使树的带权路径长度最短，就是构造**赫夫曼树**。若对上述 9 个初始归并段构造一棵赫夫曼树作为归并树，如图所示：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/best_merge_tree_2.png)

归并过程中需要对外存进行IO的次数为：

(2\times3+3\times3+6\times3+9\times2+12\times2+17\times2+18\times2+24\times2+30)\times2=446(2×3+3×3+6×3+9×2+12×2+17×2+18×2+24×2+30)×2=446

通过以构建赫夫曼树的方式构建归并树，使其对读写外存的次数降至最低（k-路平衡归并，需要选取合适的 k 值，构建赫夫曼树作为归并树），所以称此归并树为 **最佳归并树** 。

------

### Trie树  

#### 适用范围  

数据量大，重复多，但是数据种类小可以放入内存

- 字符串的快速检索
- 字符串排序
- 最长公共前缀
- 自动匹配前缀显示后缀

#### 基本原理  

Trie树的创建要考虑的是父节点如何保存孩子节点，主要有链表和数组两种方式

- 链表：空间占用少，查找效率低
- 数组：空间占用多，查找效率高
- Hash：

#### 扩展  

##### 压缩Trie Patricia Tree  

![800px-Patricia_trie](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/800px-Patricia_trie.png)

基数树（也叫基数特里树或压缩前缀树）是一种数据结构，是一种更节省空间的Trie（前缀树），其中作为唯一子节点的每个节点都与其父节点合并，**边既可以表示为元素序列又可以表示为单个元素**。

基数树的查找方式也与常规树不同（常规的树查找一开始就对整个键进行比较，直到不相同为止），基数树查找时节点时，对于节点上的键都按块进行逐块比较，其中该节点中块的长度是基数r； 当 r*r* 为2时，基数树为二进制的（即该节点的键的长度为1比特位），能最大程度地减小树的深度来最小化稀疏性（最大限度地合并键中没有分叉的节点）。 当 r≥4*r*≥4 且为2的整数次幂时，基数树是 r*r* 元基数树，能以潜在的稀疏性为代价降低基数树的深度。

##### 后缀Trie  

压缩的后缀字典树

- 查找某个字符串s1是否在另外一个字符串s2中
- 指定字符串s1在字符串s2中重复的次数
- 两个字符串S1，S2的最长公共部分
- 最长回文串

##### 双数组字典树 Double-Array Trie  

双数组Trie (Double-Array Trie)结构由日本人JUN-ICHI AOE于1989年提出的，是 **Trie结构的压缩形式**，仅用两个线性数组来表示Trie树，该结构有效结合了数字搜索树(Digital Search Tree)检索时间高效的特点和链式表示的Trie空间结构紧凑的特点。双数组Trie的本质是一个确定有限状态自动机（DFA），每个节点代表自动机的一个状态，根据变量不同，进行状态转移，当到达结束状态或无法转移时，完成一次查询操作。**在双数组所有键中包含的字符之间的联系都是通过简单的数学加法运算表示，不仅提高了检索速度，而且省去了链式结构中使用的大量指针，节省了存储空间**。

> DAT的生成如上说的只能对 **排序** 好的单词进行构建

双数组Trie树归根结底还是属于Trie树，所以免不了有一颗树的构造过程。不过这棵树并没有保存下来，而是边构造树边维护双数组以表示整棵树。

```
//i 为状态值 c为当前字符 parent(i) 为i的前置状态
base[i]=base[parent(i)+c]
check[i]=base[parent(i)]

base[i]<0 即为结束
```

#### 问题实例  

- 有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。
- 1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？
- 寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。

------

### map-reduce  

#### 适用范围  

数据量大，但是数据种类小可以放入内存

#### 基本原理及要点  

将数据交给不同的机器去处理，数据划分，结果归约。

#### 问题实例  

- The canonical example application of MapReduce is a process to count the appearances ofeach different word in a set of documents:
- 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。
- 一共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如何找到N^2个数的中数(median)？

### 经典问题分析  

#### 如何从大量的 URL 中找出相同的 URL？  

给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。

解答思路：

- 分而治之，进行哈希取余；
- 对每个子文件进行 HashSet 统计。

#### 如何从大量数据中找出高频词？  

有一个 1GB 大小的文件，文件里每一行是一个词，每个词的大小不超过 16B，内存大小限制是 1MB，要求返回频数最高的 100 个词(Top 100)。

解答思路：

- 分而治之，进行哈希取余；
- 使用 HashMap 统计频数；
- 求解最大的 TopN 个，用小顶堆；求解最小的 TopN 个，用大顶堆。

#### 如何在大量的数据中找出不重复的整数？  

在 2.5 亿个整数中找出不重复的整数。注意：内存不足以容纳这 2.5 亿个整数。

解题思路：位图法

#### 如何在大量的数据中判断一个数是否存在？  

给定 40 亿个不重复的没排过序的 unsigned int 型整数，然后再给定一个数，如何快速判断这个数是否在这 40 亿个整数当中？

解题思路：位图法

#### 如何查询最热门的查询串？  

搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询串的长度不超过 255 字节。

假设目前有 1000w 个记录（这些查询串的重复度比较高，虽然总数是 1000w，但如果除去重复后，则不超过 300w 个）。请统计最热门的 10 个查询串，要求使用的内存不能超过 1G。（一个查询串的重复度越高，说明查询它的用户越多，也就越热门。）

解题思路：HashMap、前缀树+小顶堆

#### 如何统计不同电话号码的个数？  

已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。

解题思路：位图法（将电话号码作为整型）

#### 如何从 5 亿个数中找出中位数？  

从 5 亿个数中找出中位数。数据排序后，位置在最中间的数就是中位数。当样本数为奇数时，中位数为 第 `(N+1)/2` 个数；当样本数为偶数时，中位数为 第 `N/2` 个数与第 `1+N/2` 个数的均值。

解题思路：双堆法、分治法

#### 如何按照 query 的频度排序？  

有 10 个文件，每个文件大小为 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求按照 query 的频度排序。

解题思路：外排序

#### 如何找出排名前 500 的数？  

有 20 个数组，每个数组有 500 个元素，并且有序排列。如何在这 `20*500` 个数中找出前 `500` 的数？

解题思路：败者树





## HDFS

### HDFS 相关概念  

HDFS要实现有以下优势：

- 兼容廉价硬件设备
- 流数据读写
- 大数据集
- 简单的文件模型
- 强大的跨平台兼容性

HDFS 在满足上述优势的同时，也不可避免的有一些自身的局限性，主要包括以下几个方面：

- 不适合低延时的数据访问
- 无法高效的存储大量小文件
- 不支持多用户写入及任意修改文件

#### 块  

HDFS 同计算机系统一样，有一个存储块的概念，默认大小为 64M，一个文件被分成多个块存储。块的大小远远大于计算机文件系统，可以减小寻址开销。其优势有：

- 支持大规模文件存储：以块为单位进行存储，一个大文件可被分割为多个块，并分发到不同节点，因此单个节点的存储容量不会限制存储文件的上限
- 简化系统设计：首先简化了存储管理，因为文件块大小固定，这样很容易计算节点可存储文件块的数量；其次，方便了元数据管理，元数据不与文件块存储，可由其他系统负责管理元数据。
- 适合数据备份：每个文件块都可冗余存储到多个节点，大大提高了系统的容错性和可用性。

#### 名称节点（NameNode）和数据节点（DataNode）  

| NameNode                                  | DataNode                          |
| ----------------------------------------- | --------------------------------- |
| 存储元数据                                | 存储文件内容                      |
| 元数据存储在内存                          | 文件内容存储在磁盘                |
| 保存文件、block、 DataNode 之间的映射关系 | 维护block、本地文件系统的映射关系 |

##### 名称节点（NameNode）数据结构  

在 HDFS 中，名称节点复杂管理分布式文件系统的命名空间（NameSpace），保存两大核心数据结构：**FSImage** 和 **EditLog**。名称节点中还记录了每个文件中各个块所在的数据节点的位置信息。

**FSImage 文件用于维护文件系统树以及文件树中所有文件和文件夹的元数据**。FSImage 文件中包含文件系统所有目录和文件 `inode` 的序列化形式，每个 `inode` 是一个文件或目录的元数据表示，包含：文件复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。

FSImage 中并没有记录块存储在哪个数据节点。而是由名称节点把这些映射保存在内存中，当数据节点加入 HDFS 集群时，数据节点会报告自己所包含的数据块给名称节点，并定期执行告知，以确保名称节点的映射关系是正确的。

**EditLog 记录了所有针对文件的创建、删除、重命名等操作**。

NameNode 将对文件系统的改动追加保存到本地文件系统上的一个日志文件（EditLog）。当一个 NameNode 启动时，它首先从一个映像文件（FSImage）中读取 HDFS 的状态，接着应用日志文件中的 EditLog 操作。然后它将新的HDFS状态写入（FSImage）中，并使用一个空的 EditLog 文件开始正常操作。因为NameNode只有在启动阶段才合并 FSImage 和 EditLog ，所以久而久之日志文件可能会变得非常庞大，特别是对大型的集群。日志文件太大的另一个副作用是下一次 NameNode 启动会花很长时间。

Secondary NameNode 定期合并 FSImage 和 EditLog 日志，将 EditLog 日志文件大小控制在一个限度下。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hdfs_secondary_name_node_sync_editlog.png)

##### 名称节点的启动  

1. 名称节点启动后，会将 FSImage 文件中的内容加载到内存，之后再执行 EditLog 文件中的各项操作，使得内存中的元数据与实际数据一致。
2. 一旦内存中管理文件系统元数据的映射，则会创建一个新的 FSImage 文件和一个空白的 EditLog 文件。
3. 名称节点启动后， HDFS 中的更新操作会重新写入 EditLog，因为 FSImage 文件一般很大，所以不直接向 FSImage 文件中写入数据，但是 EditLog 每次启动后都是空白的。每次执行完写操作，且在向客户端发送成功消息之前，EditLog 文件都需要同步更新。

##### 数据节点  

数据节点是 HDFS 的工作节点，负责数据的存储和读取，会根据客户端或者名称节点的调度来进行数据的存储和检索，并定期向名称节点发送自己所存储的块信息。每个数据节点中的数据都会被保存在各自节点的本地 Linux 文件系统中。

### HDFS 体系结构  

HDFS 采取主从模型，一个 HDFS 集群包含一个 NameNode 和若干个 DataNode 。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hdfs_arthticher.png)

#### 命名空间  

HDFS 的命名空间包含块映射、以及相关属性，存储在 FSImage 中。在 HDFS 1.0 体系结构中，整个 HDFS 集群中只有一个命名空间，并且只有唯一一个名称节点，该节点对这个命名空间进行管理。在 HDFS 2.0 中提出了 **联邦 （Federation）** 的概念。

##### Federation  

Federation 的设计就是为了解决 HDFS 1.0 中的单一 NameNode 的问题，采用 Federation 的最主要原因是设计实现简单。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hdfs-federation.png)

> block pool 存储在 DataNode 上，并通过 BPOfferService 提供服务

Federation 的核心思想是将一个大的 `namespace` 划分多个子 `namespace` ，并且每个 `namespace` 分别由单独的 NameNode 负责，这些 NameNode 之间互相独立，不会影响，不需要做任何协调工作（其实跟拆集群有一些相似），**集群的所有 DataNode 会被多个 NameNode 共享**。

其中，每个子 `namespace` 和 DataNode 之间会由数据块管理层作为中介建立映射关系，数据块管理层由若干 **数据块池（Pool）** 构成，每个数据块只会唯一属于某个固定的数据块池，而一个子 `namespace` 可以对应多个数据块池。每个 DataNode 需要向集群中所有的 NameNode 注册，且周期性地向所有 NameNode 发送心跳和块报告，并执行来自所有 NameNode 的命令。

- 一个 block pool 由属于同一个 namespace 的数据块组成，每个 DataNode 可能会存储集群中所有 block pool 的数据块；
- 每个 block pool 内部自治，也就是说各自管理各自的 block，不会与其他 block pool 交流，如果一个 NameNode 挂掉了，不会影响其他 NameNode;
- **某个 NameNode 上的 namespace 和它对应的 block pool 一起被称为 namespace volume，它是管理的基本单位**。当一个 NameNode/namespace 被删除后，其所有 DataNode 上对应的 block pool 也会被删除，当集群升级时，每个 namespace volume 可以作为一个基本单元进行升级。

#### HA  

在 Hadoop 1.0 时代，Hadoop 的两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，这其中以 NameNode 的单点问题尤为严重。因为 NameNode 保存了整个 HDFS 的元数据信息，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。

所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hdfs_ha.png)

NameNode 的高可用架构主要分为下面几个部分：

- **Active NameNode 和 Standby NameNode**：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。
- **主备切换控制器 ZKFailoverController**：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。
- **Zookeeper 集群**：为主备切换控制器提供主备选举支持。
- **共享存储系统**：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。**主 NameNode 和 备份 NameNode 通过共享存储系统实现元数据同步**。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。
- **DataNode 节点**：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。**DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息**。

NameNode 主备切换主要由 ZKFailoverController、HealthMonitor 和 ActiveStandbyElector 这 3 个组件来协同实现：

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hdfs_failover.png)

##### HDFS 脑裂问题  

在实际中，NameNode 可能会出现这种情况，**NameNode 在垃圾回收（GC）时，可能会在长时间内整个系统无响应，因此，也就无法向 ZK 写入心跳信息，这样的话可能会导致临时节点掉线，备 NameNode 会切换到 Active 状态**。这种情况，可能会导致整个集群会有同时有两个 NameNode，这就是脑裂问题。

脑裂问题的解决方案是隔离（Fencing），主要是在以下三处采用隔离措施：

- 第三方共享存储：任一时刻，只有一个 NN 可以写入
- DataNode：需要保证只有一个 NN 发出与管理数据副本有关的删除命令
- Client：需要保证同一时刻只有一个 NN 能够对 Client 的请求发出正确的响应

##### 共享存储  

上述 HA 方案还有一个明显缺点，那就是第三方存储节点有可能失效，目前社区已经把由 Clouderea 公司实现的基于 QJM 的方案作为默认的共享存储实现。`QJM（Quorum Journal Manager）`本质上是利用 `Paxos` 协议来实现的，QJM 在 `2F+1` 个 JournalNode 上存储 NameNode 的 EditLog ，每次写入操作都通过 `Paxos` 保证写入的一致性，它最多可以允许有 `F` 个 JournalNode 节点同时故障。

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hdfs-ha-qjm.png)

Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog 。还有一点需要注意的是，在 2.0 中不再有 SNN 这个角色了，NameNode 在启动后，会先加载 `FSImage` 文件和共享目录上的 EditLog Segment 文件，之后 NameNode 会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，正式进入 Standby 模式，其中：

- EditLogTailer 线程的作用是定时从 JournalNode 集群上同步 EditLog
- StandbyCheckpointer 线程的作用其实是为了替代 Hadoop 1.x 版本之中的 Secondary NameNode 的功能，StandbyCheckpointer 线程会在 Standby NameNode 节点上定期进行 Checkpoint，将 Checkpoint 之后的 FSImage 文件上传到 Active NameNode 节点

#### 通信协议  

- 客户端与 NameNode 通过 TCP 连接，并使用客户端协议进行通信
- NameNode 和 DataNode 之间使用数据节点协议通信
- 客户端与 DataNode 之间通过 RPC 进行交互

#### 局限性  

- 命名空间的限制（Hadoop 2.0 已解决）
- 性能瓶颈：受限于单节点吞吐量
- 隔离问题：单个 NameSpace 无法对不同应用程序进行隔离（Hadoop 2.0 已解决）
- 可用性：单个 NameNode 故障无法快速切换（Hadoop 2.0 已解决）

### HDFS 存储原理  

#### 冗余数据保存  

HDFS 采用多副本方式对数据进行冗余存储，通常一个数据库的多个副本会被分布到不同的数据节点。这样多副本具有以下几个优点：

1. 加速数据传输
2. 容易检查数据错误
3. 保证数据可靠性

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hdfs_block_save.png)

#### 数据存取策略  

HDFS 使用的是传统的分级文件体系，因此，用户可以像使用普通文件系统一样，创建、删除目录和文件，在目录之间移动、重命名文件，但不支持修改。

##### 存储类型  

- DISK：普通磁盘
- SSD：SSD盘
- RAM_DISK：内存盘
- ARCHIVE：归档/压缩，不是实际的磁盘类型，而是数据被压缩存储。

##### 存储策略  

存储策略允许不同的文件存储在不同的存储类型上。目前有以下策略：

- **Hot**：存储和计算都热。 如果是热快，那么复制的目标也是DISK（普通的磁盘）。
- **Cold**：用于有限计算的存储。 数据不再使用，或者需要归档的数据被移动到冷存储。如果数据块是冷的，则复制使用ARCHIVE.
- **Warm**：半冷半热。warm块的复制内容，部分放置在DISK，其它的在ARCHIVE.
- **All_SSD**：所有数据存储在SSD.
- **One_SSD**：一个复制在SSD，其它的在DISK.
- **Lazy_Persist**：只针对只有一个复制的数据块，它们被放在RAM_DISK,之后会被写入DISK。

当创建文件/目录的时候，并未为它们设定了存储策略。 但可以通过`hdfs storagepolicies` 命令来管理。文件/路径的存储策略按照如下规则解析：

- 如果有设定特定的策略，那么就是那个策略
- 如果没有设定，就返回上级目录的存储策略。如果是没有策略的根目录，那么返回默认的存储策略（Hot)。

##### 存储时 DataNode 选择  

默认情况下，Hadoop 机架感知是没有启用的，需要在NameNode机器的`hadoop-site.xml`里配置一个选项。

当没有配置机架信息时，所有的机器 Hadoop 都默认在同一个默认的机架下，名为 `/default-rack`，这种情况下，任何一台 DataNode 机器，不管物理上是否属于同一个机架，都会被认为是在同一个机架下，此时，就很容易出现之前提到的增添机架间网络负载的情况。在没有机架信息的情况下， NameNode 默认将所有的 `slaves` 机器全部默认为在 `/default-rack` 下，此时写 `block` 时，三个 DataNode 机器的选择完全是随机的。

当配置了机架感知信息以后，hadoop在选择三个datanode时，就会进行相应的判断。

##### 数据读取策略  

- HDFS 提供 API 可以确定一个数据节点所属机架ID，客户端也可以调用 API 获取自己的机架ID
- 从名称节点获取数据块不同副本的存放位置列表，列表中包含副本所在的数据节点
- 客户端调用 API 获取数据节点所属的机架ID，如果与客户端机架ID 相同则优先选择，否则就随机读取

#### 数据错误与恢复  

##### NameNode 出错  

HDFS 有备份机制，定时将 FSImage 和 EditLog 备份到 SecondaryNameNode 。当 NameNode 出错，就可以根据 SecondaryNameNode 中的数据进行恢复。

##### DataNode 出错  

当 DataNode 发生网络问题或机器故障时，这些 DataNode 会被标记为 “宕机”，节点上的数据均被标记为 “不可读”， NameNode 不会再对它发送任何数据请求。这时，由于部分 DataNode 不可用，会导致一些数据块的副本数量小于冗余因子。在这种情况下，NameNode 会启动冗余复制，为数据块生成新的副本。

##### 数据出错  

当文件被创建时，客户端都会对每个文件块进行信息摘要，并将其存储在同路径的隐藏文件里。客户端在读取数据时，会首先获取信息摘要，并对数据块进行 MD5 和 SHA1 校验。如果数据错误，则会向 NameNode 报告错误，NameNode 定时检查并重新复制该数据块。

### HDFS 数据读写过程  

#### 写数据过程  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hdfs_write_file_process.png)

具体过程如下：

1. Client 调用 `DistributedFileSystem` 对象的 `create` 方法，创建一个文件输出流（FSDataOutputStream）对象；
2. 通过 `DistributedFileSystem` 对象与集群的 NameNode 进行一次 RPC 远程调用，在 HDFS 的 Namespace 中创建一个文件条目（Entry），此时该条目没有任何的 Block，NameNode 会返回该数据每个块需要拷贝的 DataNode 地址信息；
3. 通过 `FSDataOutputStream` 对象，开始向 DataNode 写入数据，数据首先被写入 `FSDataOutputStream` 对象内部的数据队列中，数据队列由 `DataStreamer` 使用，它通过选择合适的 DataNode 列表来存储副本，从而要求 NameNode 分配新的 block；
4. `DataStreamer` 将数据包以流式传输的方式传输到分配的第一个 DataNode 中，该数据流将数据包存储到第一个 DataNode 中并将其转发到第二个 DataNode 中，接着第二个 DataNode 节点会将数据包转发到第三个 DataNode 节点；
5. DataNode 确认数据传输完成，最后由第一个 DataNode 通知 client 数据写入成功；
6. 完成向文件写入数据，Client 在文件输出流（`FSDataOutputStream`）对象上调用 close 方法，完成文件写入；
7. 调用 `DistributedFileSystem` 对象的 `complete` 方法，通知 NameNode 文件写入成功，NameNode 会将相关结果记录到 `editlog` 中。

> 注意：client运行 write 操作后，写完的 block 才是可见的，正在写的 block 对 client 是不可见的，仅仅有调用 sync 方法。client才确保该文件的写操作已经全部完毕。当 client 调用 close 方法时，会默认调用 sync 方法。是否须要手动调用取决你依据程序须要在数据健壮性和吞吐率之间的权衡。

##### 读数据过程  

![img](Java%E5%85%A8%E6%80%BB%E7%BB%93.assets/hdfs_read_file_process.png)

1. Client 通过 `DistributedFileSystem` 对象与集群的 NameNode 进行一次 RPC 远程调用，获取文件 `block` 位置信息；
2. NameNode 返回存储的每个块的 DataNode 列表；
3. Client 将连接到列表中最近的 DataNode；
4. Client 开始从 DataNode 并行读取数据；
5. 一旦 Client 获得了所有必须的 `block`，它就会将这些 `block` 组合起来形成一个文件。